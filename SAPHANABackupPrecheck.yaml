AWSTemplateFormatVersion: '2010-09-09'
Description: >
  Deploys five SSM Automation documents for AWS Backup SAP HANA Pre-Check.

Parameters:
  SID:
    Type: String
    Description: "SAP HANA System ID"
    AllowedPattern: "[A-Z][A-Z0-9]{2}"
    ConstraintDescription: "Must be a valid SAP System ID: 3 characters, starting with a letter."

Resources:

  SAPBackupPreCheckPart1:
    Type: AWS::SSM::Document
    Properties:
      DocumentType: Automation
      Name: !Sub 'SAPBackupPreCheck-${AWS::StackName}-${SID}-Part1'
      Content:
        schemaVersion: '0.3'
        description: AWS Backup SAP HANA Pre-Check Automation (Part 1)
        parameters:
          InstanceId:
            type: String
            description: EC2 instance ID running SAP HANA
          RunHSIScript:
            type: String
            description: Would you like to use the HANA Support Info tool? (yes/no)
            allowedValues:
              - 'yes'
              - 'no'
          SID:
            type: String
            description: SAP HANA system ID
          S3BucketForLogs:
            type: String
            description: S3 bucket for logs (optional)
            default: ''
          S3UploaderLink:
            type: String
            description: AWS Support upload link (optional)
            default: ''
          Timestamp:
            type: String
            default: '{{ automation:EXECUTION_ID }}'
          SecretArn:
            type: String
            description: ARN of secret in Secrets Manager
          HANASupportInfoBucket:
            type: String
            description: S3 bucket containing HANASupportInfo.sh script (optional)
            default: ''
          HANASupportInfoPath:
            type: String
            description: File path where HANASupportInfo.sh script is located or should be downloaded to
            default: HANASupportInfo.sh
          HANASupportInfoS3Key:
            type: String
            description: Object key of the script within the S3 bucket
            default: HANASupportInfo.sh
        mainSteps:
          - name: RetrieveCredentials
            action: aws:runCommand
            nextStep: PrepareEnvironment
            inputs:
              DocumentName: AWS-RunShellScript
              InstanceIds: ['{{ InstanceId }}']
              Parameters:
                commands:
                  - |
                    #!/bin/bash
                    mkdir -p /tmp/hana_health
                    secret_arn="{{ SecretArn }}"
                    
                    secret_value=$(aws secretsmanager get-secret-value --secret-id "$secret_arn" --query 'SecretString' --output text)
                    
                    hana_username=$(echo "$secret_value" | sed -n 's/.*"username":"\([^"]*\)".*/\1/p')
                    hana_password=$(echo "$secret_value" | sed -n 's/.*"password":"\([^"]*\)".*/\1/p')

                    if [ -z "$hana_username" ] || [ -z "$hana_password" ]; then
                        echo "Failed to retrieve SAP HANA credentials from Secrets Manager"
                        exit 1
                    fi

                    echo "Successfully retrieved SAP HANA credentials"
                    echo "export HANA_USERNAME=$hana_username" >> /tmp/hana_env.sh
                    echo "export HANA_PASSWORD=$hana_password" >> /tmp/hana_env.sh
          - name: PrepareEnvironment
            action: aws:runCommand
            nextStep: BranchRunHSIScript
            onFailure: step:BranchRunHSIScript
            inputs:
              DocumentName: AWS-RunShellScript
              InstanceIds: ['{{ InstanceId }}']
              Parameters:
                commands:
                  - |
                    #!/usr/bin/env bash
                    set -euo pipefail

                    # bootstrap dirs
                    mkdir -p /tmp/hana_health
                    HEALTH_DIR=/tmp/hana_health
                    ARCHIVE_DIR="$HEALTH_DIR/archives"
                    mkdir -p "$ARCHIVE_DIR"

                    # archive+rotate old logs
                    timestamp=$(date '+%Y%m%d_%H%M%S')
                    find "$HEALTH_DIR" -maxdepth 1 -type f \( -name '*.log' -o -name '*.txt' \) \
                        -exec tar czf "$ARCHIVE_DIR/prepare_env_${timestamp}.tar.gz" {} + 2>/dev/null
                    find "$HEALTH_DIR" -maxdepth 1 -type f \( -name '*.log' -o -name '*.txt' \) -delete
                    find "$ARCHIVE_DIR" -type f -mtime +7 -delete
                    while [ "$(du -sm "$ARCHIVE_DIR" | cut -f1)" -gt 50 ]; do
                        ls -t "$ARCHIVE_DIR"/*.tar.gz | tail -n1 | xargs rm -f
                    done

                    # init log & result
                    LOG_FILE="$HEALTH_DIR/prepare_env.log"
                    RESULTS_FILE="$HEALTH_DIR/prepare_env.txt"
                    : > "$LOG_FILE"  ;  : > "$RESULTS_FILE"

                    # logging functions
                    log(){ echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" | tee -a "$LOG_FILE" ; }
                    log_success(){ echo "✓ $1" | tee -a "$LOG_FILE" "$RESULTS_FILE" ; }
                    log_warning(){ echo "⚠ $1" | tee -a "$LOG_FILE" "$RESULTS_FILE" ; }
                    log_error(){ echo "✗ $1" | tee -a "$LOG_FILE" "$RESULTS_FILE" ; }

                    # detect SID/instance
                    detect_sap_instance(){
                        SID="${SID:-{{ SID }}}"
                        INSTANCE_NUM=$(ls -d /usr/sap/$SID/HDB[0-9][0-9] 2>/dev/null \
                        | grep -Po 'HDB\K[0-9]+' | head -1 || echo "00")
                        SIDADM="${SID,,}adm"
                        export SID INSTANCE_NUM SIDADM HOSTNAME="$(hostname)"
                    }
                    detect_sap_instance
                    log "Detected SID=$SID, INSTANCE_NUM=$INSTANCE_NUM, SIDADM=$SIDADM"

                    # write core exports
                    {
                        echo "export SID='$SID'"
                        echo "export INSTANCE_NUM='$INSTANCE_NUM'"
                        echo "export SIDADM='$SIDADM'"
                        echo "export HOSTNAME='$(hostname)'"
                        echo "export ERROR_COUNT=0"
                        echo "export WARNING_COUNT=0"
                        echo "export MISSING_COUNT=0"
                    } >> "$HEALTH_DIR/env_vars.sh"

                    # now detect HANA version
                    log "Detecting HANA version..."
                    get_hana_version(){
                        local cmd="/usr/sap/$SID/HDB$INSTANCE_NUM/exe/hdbsql"
                        [ -x "$cmd" ] && su - "$SIDADM" -c "$cmd -v" 2>/dev/null | head -1
                    }
                    if raw=$({ get_hana_version; } 2>/dev/null); then
                        HANA_VERSION_FULL=$(echo "$raw" \
                        | grep -Po '(?<=HDB version )\d+\.\d+\.\d+\.\d+' \
                        || echo "0.0.0.0")
                        HANA_SPS=$(echo "$HANA_VERSION_FULL" | cut -d. -f3 || echo "0")
                        HANA_SPS_PADDED=$(printf "%03d" "$HANA_SPS" 2>/dev/null || echo "000")

                        echo "export HANA_VERSION_FULL='$HANA_VERSION_FULL'" >> "$HEALTH_DIR/env_vars.sh"
                        echo "export HANA_SPS_PADDED='$HANA_SPS_PADDED'" >> "$HEALTH_DIR/env_vars.sh"

                        log_success "Detected HANA version: $HANA_VERSION_FULL (SPS $HANA_SPS_PADDED)"
                    else
                        echo "export HANA_VERSION_FULL='0.0.0.0'" >> "$HEALTH_DIR/env_vars.sh"
                        echo "export HANA_SPS_PADDED='999'"      >> "$HEALTH_DIR/env_vars.sh"
                        log_warning "Unable to detect HANA version; defaulting to 0.0.0.0 / SPS 999"
                    fi

                    # ─── Retrieve HANA credentials ────────────────────────────
                    # First check if AWS CLI is available
                    if ! command -v aws &>/dev/null; then
                      log_error "AWS CLI not found - cannot retrieve credentials from Secrets Manager"
                      echo "✗ ERROR: AWS CLI not installed." >> "$RESULTS_FILE"
                      exit 1  # Fail early if AWS CLI isn't available
                    else
                      # AWS CLI is available, try to get the secret
                      SecretArn="{{ SecretArn }}"
                      log "Retrieving HANA credentials from Secrets Manager ARN=$SecretArn"
                      
                      # Try to get the full secret first to avoid multiple calls
                      SECRET_JSON=$(aws secretsmanager get-secret-value \
                        --secret-id "$SecretArn" \
                        --query "SecretString" \
                        --output text 2>/tmp/hana_health/secret_error.log)
                      
                      if [ $? -ne 0 ] || [ -z "$SECRET_JSON" ]; then
                        log_error "Failed to get secret value"
                        if [ -f /tmp/hana_health/secret_error.log ]; then
                          log "Error details: $(cat /tmp/hana_health/secret_error.log)"
                        fi
                        echo "✗ ERROR: Cannot retrieve HANA credentials." >> "$RESULTS_FILE"
                        exit 1
                      fi
                      
                      # Extract username and password
                      HANA_USERNAME=$(echo "$SECRET_JSON" | grep -o '"username":"[^"]*' | grep -o '[^"]*$')
                      HANA_PASSWORD=$(echo "$SECRET_JSON" | grep -o '"password":"[^"]*' | grep -o '[^"]*$')
                      
                      if [ -z "$HANA_USERNAME" ] || [ -z "$HANA_PASSWORD" ]; then
                        log_error "Failed to parse credentials from secret JSON"
                        echo "✗ ERROR: Bad secret JSON format." >> "$RESULTS_FILE"
                        exit 1
                      fi

                      # Export credentials to environment
                      export HANA_USERNAME HANA_PASSWORD
                      
                      # Also write credentials to env_vars.sh for support team access
                      {
                          echo "export HANA_USERNAME='$HANA_USERNAME'"
                          echo "export HANA_PASSWORD='$HANA_PASSWORD'"
                      } >> "$HEALTH_DIR/env_vars.sh"
                      
                      log_success "HANA credentials retrieved and saved"
                    fi

                    log_success "Environment setup completed"

          - name: BranchRunHSIScript
            action: aws:branch
            inputs:
              Choices:
                - NextStep: RunHANASupportInfo
                  Variable: '{{ RunHSIScript }}'
                  StringEquals: 'yes'
                - NextStep: SkipHSI
                  Variable: '{{ RunHSIScript }}'
                  StringEquals: 'no'
              Default: RunHANASupportInfo
          - name: SkipHSI
            action: aws:runCommand
            nextStep: QuickPrerequisitesCheck 
            isEnd: false
            inputs:
              DocumentName: AWS-RunShellScript
              InstanceIds:
                - '{{ InstanceId }}'
              Parameters:
                commands:
                  - echo "HSI script skipped."
          - name: RunHANASupportInfo
            action: aws:runCommand
            nextStep: QuickPrerequisitesCheck 
            onFailure: Continue
            inputs:
              DocumentName: AWS-RunShellScript
              InstanceIds: ['{{ InstanceId }}']
              Parameters:
                commands:
                  - |
                    #!/usr/bin/env bash
                    set -uo pipefail                      
                    # no -e; we'll handle exit codes
                    LOG_DIR=/tmp/hana_health
                    mkdir -p "$LOG_DIR"
                    exec > >(tee -a "$LOG_DIR/hana_support_wrapper.log") 2>&1
                    set -x                                
                    # trace every command

                    SID="$(echo "{{ SID }}" | tr -d '\\r\\n' | tr '[:lower:]' '[:upper:]')"
                    RUN_ID="$(date +%Y%m%d%H%M%S)"
                    OUTDIR="$LOG_DIR/HSI_${SID}_${RUN_ID}"
                    mkdir -p "$OUTDIR"

                    # Download helper script to a writable dir
                    HSI="$LOG_DIR/HANASupportInfo.sh"
                    aws s3 cp "s3://{{ HANASupportInfoBucket }}/{{ HANASupportInfoS3Key }}" "$HSI"
                    chmod +x "$HSI"

                    # Always run as root (tool complains under <sid>adm)
                    RUN_AS="root"
                    echo "Executing HANASupportInfo.sh as $RUN_AS"

                    EXIT_CODE=1

                    # Preferred route ? feed SID with EXPECT (TTY emulation)
                    if command -v expect &>/dev/null; then
                      EXPECT_FILE="$LOG_DIR/run_hsi_$RUN_ID.exp"
                      cat > "$EXPECT_FILE" <<EOT
                    set timeout -1
                    log_file -a "$OUTDIR/HSI_stdout.log"
                    spawn sudo -u "$RUN_AS" "$HSI" -f 14
                    expect "Please type in the SID*"  { send "$SID\\r" }
                    expect "Continue (y/n)?"         { send "y\\r" }
                    expect eof
                    EOT
                      chmod +x "$EXPECT_FILE"
                      expect "$EXPECT_FILE" || EXIT_CODE=$?
                    fi

                    # Fallback ? pipe SID with echo if EXPECT failed / absent
                    if [[ $EXIT_CODE -ne 0 ]]; then
                      echo "EXPECT path failed or not present ? using echo | sudo"
                      printf "%s\\n" "$SID" | sudo -u "$RUN_AS" "$HSI" -f 14 >"$OUTDIR/HSI_stdout.log" 2>&1 || EXIT_CODE=$?
                    fi

                    echo "HANASupportInfo exit code: $EXIT_CODE (ignored ? we validate by ZIP)"

                    # Locate the generated ZIP (last 20_min, pattern matches SID)
                    HSI_ZIP=$(find /var/tmp -maxdepth 1 -mmin -20 -type f -name "HSI_${SID}_*.zip" | head -1)

                    if [[ -z "$HSI_ZIP" ]]; then
                        echo "Support ZIP not found ? failing the step" >&2
                        exit 1
                    fi

                    echo "ZIP created at $HSI_ZIP"
                    echo "export HANA_SUPPORT_OUTPUT_ZIP=\\"$HSI_ZIP\\"" >> "$LOG_DIR/env_vars.sh"
                    exit 0
          - name: QuickPrerequisitesCheck
            action: aws:runCommand
            nextStep: CheckEnvironmentandOSVersioning
            onFailure: step:CheckEnvironmentandOSVersioning
            inputs:
              DocumentName: AWS-RunShellScript
              InstanceIds: ['{{ InstanceId }}']
              Parameters:
                commands:
                  - |
                    #!/bin/bash
                    source /tmp/hana_health/env_vars.sh 2>/dev/null || true
                    setup_log_files "quick_prereqs"
                    log "Running quick prerequisites check"
                    echo "AWS Backup for SAP HANA Quick Prerequisites Check Results" > "$RESULTS_FILE" # Renamed slightly

                    # Strip leading zeros from INSTANCE_NUM if it exists
                    if [ -n "${INSTANCE_NUM:-}" ]; then
                        # Remove leading zeros using printf
                        INSTANCE_NUM=$(printf "%d" "${INSTANCE_NUM}" 2>/dev/null || echo "0")
                        log "Normalized INSTANCE_NUM to $INSTANCE_NUM for integer comparisons"
                    fi

                    # Python version check with simplified command structure
                    if python3 --version >/dev/null 2>&1; then
                        PYTHON_VERSION=$(python3 --version 2>/dev/null | grep -Po '(?<=Python )3.\d')
                    elif python --version >/dev/null 2>&1; then
                        PYTHON_VERSION=$(python --version 2>/dev/null | grep -Po '(?<=Python )3.\d')
                    else
                        PYTHON_VERSION=""
                    fi
                    
                    echo "Python Version: ${PYTHON_VERSION:-Not found}" >> "$RESULTS_FILE"
                    if [ -n "$PYTHON_VERSION" ]; then
                        if [[ "$PYTHON_VERSION" =~ 3\.[6-9] ]] || [[ "$PYTHON_VERSION" =~ 3\.[1-9][0-9] ]]; then
                            echo "? Python version meets requirements" >> "$RESULTS_FILE"
                            log_success "Python version meets requirements: $PYTHON_VERSION"
                        else
                            echo "? ERROR: Python version too old - requires 3.6+" >> "$RESULTS_FILE"
                            log_error "Python version too old: $PYTHON_VERSION - requires 3.6+"
                            if rpm -qa | grep -q "python36"; then
                                echo "Python 3.6 is installed but not the default version" >> "$RESULTS_FILE"
                                # echo "Recommendation:" >> "$RESULTS_FILE" # Removed
                                echo "- Run: sudo update-alternatives --install /usr/local/bin/python3 python3 /usr/bin/python3.6 2" >> "$RESULTS_FILE"
                                echo "- Then: sudo update-alternatives --config python3" >> "$RESULTS_FILE"
                            else
                                echo "Recommendation: Install Python 3.6+" >> "$RESULTS_FILE"
                            fi
                            ((ERROR_COUNT++))
                        fi
                    else
                        echo "? ERROR: Python 3.x not found" >> "$RESULTS_FILE"
                        log_error "Python 3.x not found"
                        ((ERROR_COUNT++))
                    fi

                    if [ -n "{{ SecretArn }}" ]; then
                        SECRET_VALUE=$(aws secretsmanager get-secret-value --secret-id "{{ SecretArn }}" --region "$REGION" --query 'SecretString' --output text 2>/dev/null)
                        if [ $? -eq 0 ] && [ -n "$SECRET_VALUE" ]; then
                            if echo "$SECRET_VALUE" | grep -q 'password.*[$&<>;`|]'; then
                                echo "? WARNING: Password contains special characters which may cause issues ($ & < > ; \` |)" >> "$RESULTS_FILE"
                                log_warning "Password contains special characters which may cause issues"
                            else
                                echo "? Password does not contain problematic special characters" >> "$RESULTS_FILE"
                                log_success "Password does not contain problematic special characters"
                            fi
                        else
                            echo "Unable to check password - secret access failed" >> "$RESULTS_FILE"
                            log_warning "Unable to check password - secret access failed"
                        fi
                    else
                        echo "Secret ARN not provided - skipping password special char check" >> "$RESULTS_FILE"
                        log_warning "Secret ARN not provided - skipping password special char check"
                    fi

                    if command -v aws &>/dev/null; then
                        REGISTRATION=$(aws ssm-sap list-applications --region "$REGION" 2>/dev/null | grep -i "$SID" || echo "")
                        REG_COUNT=$(echo "$REGISTRATION" | grep -c "$SID" || echo "0")
                        if [ "$REG_COUNT" -gt 1 ]; then
                            echo "? WARNING: Multiple registrations found for SID $SID ($REG_COUNT found). Check AWS Backup console." >> "$RESULTS_FILE"
                            log_warning "Multiple registrations found for SID $SID ($REG_COUNT found)"
                        elif [ "$REG_COUNT" -eq 1 ]; then
                            echo "? Single registration found for SID $SID" >> "$RESULTS_FILE"
                            log_success "Single registration found for SID $SID"
                        else
                            echo "No registrations found for SID $SID" >> "$RESULTS_FILE"
                            log_warning "No registrations found for SID $SID"
                        fi
                    else
                        echo "AWS CLI not available - skipping multiple registration check" >> "$RESULTS_FILE"
                        log_warning "AWS CLI not available - skipping multiple registration check"
                    fi

                    rpm_info=$(/usr/bin/rpm -qi amazon-ssm-agent 2>&1)
                    if [ $? -eq 0 ]; then
                        echo "$rpm_info" | grep -E "^(Name|Version|Release|Install Date)" >> "$RESULTS_FILE"
                        log_success "SSM Agent package found"
                    else
                        echo "? SSM Agent package not found" >> "$RESULTS_FILE"
                        log_error "SSM Agent package not found"
                        ((ERROR_COUNT++))
                    fi

                    service_status=$(sudo /usr/bin/systemctl status --no-pager --full amazon-ssm-agent.service 2>&1)
                    if echo "$service_status" | grep -q "Active: active (running)"; then
                        echo "? SSM Agent service is running" >> "$RESULTS_FILE"
                        # echo "$service_status" | grep -E "Active:|CGroup:" >> "$RESULTS_FILE" # Removed detail
                        log_success "SSM Agent service is running"
                    else
                        echo "? SSM Agent service is not running" >> "$RESULTS_FILE"
                        # echo "$service_status" | grep -E "Active:|Failed:" >> "$RESULTS_FILE" # Removed detail
                        log_error "SSM Agent service is not running"
                        ((ERROR_COUNT++))
                    fi

                    write_summary # This function already adds a "Summary:" header

                    # Force ERROR_COUNT to be a clean integer
                    ERROR_COUNT=$(printf "%d" "${ERROR_COUNT:-0}" 2>/dev/null || echo "0")
                    
                    if [ "$ERROR_COUNT" -gt 0 ]; then 
                        log_error "Quick prerequisites check failed with $ERROR_COUNT errors"
                        exit 0 # Exit 0 to allow subsequent steps even on failure within this check
                    else
                        log_success "Quick prerequisites check completed successfully"
                        exit 0
                    fi
          - name: CheckEnvironmentandOSVersioning
            action: aws:runCommand
            isEnd: false
            nextStep: InvokePart2
            onFailure: Continue
            inputs:
              DocumentName: AWS-RunShellScript
              InstanceIds: ['{{ InstanceId }}']
              Parameters:
                commands:
                  - |
                    #!/bin/bash
                    # SAP HANA Health Check Script
                    # This script performs various health checks for SAP HANA environments

                    # Create directory for temp files and logs
                    mkdir -p /tmp/hana_health

                    # Initialize environment variables file if it doesn't exist
                    if [ ! -f /tmp/hana_health/env_vars.sh ]; then
                    echo "#!/bin/bash" > /tmp/hana_health/env_vars.sh
                    echo "# Environment variables for HANA health check" >> /tmp/hana_health/env_vars.sh
                    chmod +x /tmp/hana_health/env_vars.sh
                    fi

                    # Source environment variables if file exists
                    if [ -f /tmp/hana_health/env_vars.sh ]; then
                    source /tmp/hana_health/env_vars.sh
                    fi

                    # Initialize counters
                    ERROR_COUNT=0
                    WARNING_COUNT=0
                    SUCCESS_COUNT=0

                    # Initialize SID if not set
                    if [ -z "${SID:-}" ]; then
                    # Try to get SID from environment
                    SID=$(echo "$HOSTNAME" | grep -o '^[^-]*' | tr '[:lower:]' '[:upper:]')
                    # If still empty, use generic value
                    SID=${SID:-HDB}
                    echo "export SID=\"$SID\"" >> /tmp/hana_health/env_vars.sh
                    fi

                    # Set derived variables
                    SIDADM=$(echo "$SID" | tr '[:upper:]' '[:lower:]')adm
                    SAPSYSTEMNAME=${SAPSYSTEMNAME:-$SID}
                    TINSTANCE=${TINSTANCE:-02}
                    echo "export SIDADM=\"$SIDADM\"" >> /tmp/hana_health/env_vars.sh
                    echo "export SAPSYSTEMNAME=\"$SAPSYSTEMNAME\"" >> /tmp/hana_health/env_vars.sh
                    echo "export TINSTANCE=\"$TINSTANCE\"" >> /tmp/hana_health/env_vars.sh

                    # ─── Logging functions ───────────────────────────────────────
                    LOG_FILE="/tmp/hana_health/health_check.log"
                    RESULTS_FILE="/tmp/hana_health/current_results.txt"

                    # Setup log files for each check
                    setup_log_files() {
                    local CHECK_NAME="$1"
                    LOG_FILE="/tmp/hana_health/${CHECK_NAME}_check.log"
                    RESULTS_FILE="/tmp/hana_health/${CHECK_NAME}_results.txt"

                    echo "# SAP HANA Health Check - $CHECK_NAME" > "$LOG_FILE"
                    echo "# $(date)" >> "$LOG_FILE"

                    echo "# SAP HANA Health Check - $CHECK_NAME" > "$RESULTS_FILE"
                    echo "# $(date)" >> "$RESULTS_FILE"
                    echo "---------------------------------------------" >> "$RESULTS_FILE"
                    }

                    log() {
                    local MESSAGE="$1"
                    local TIMESTAMP=$(date +"%Y-%m-%d %H:%M:%S")
                    echo "$TIMESTAMP - $MESSAGE" >> "$LOG_FILE"
                    echo "$TIMESTAMP - $MESSAGE"
                    }

                    log_success() {
                    local MESSAGE="$1"
                    local TIMESTAMP=$(date +"%Y-%m-%d %H:%M:%S")
                    echo "$TIMESTAMP - SUCCESS: $MESSAGE" >> "$LOG_FILE"
                    echo "$TIMESTAMP - SUCCESS: $MESSAGE"
                    ((SUCCESS_COUNT++))
                    }

                    log_warning() {
                    local MESSAGE="$1"
                    local TIMESTAMP=$(date +"%Y-%m-%d %H:%M:%S")
                    echo "$TIMESTAMP - WARN: $MESSAGE" >> "$LOG_FILE"
                    echo "$TIMESTAMP - WARN: $MESSAGE"
                    ((WARNING_COUNT++))
                    }

                    log_error() {
                    local MESSAGE="$1"
                    local TIMESTAMP=$(date +"%Y-%m-%d %H:%M:%S")
                    echo "$TIMESTAMP - ERROR: $MESSAGE" >> "$LOG_FILE"
                    echo "$TIMESTAMP - ERROR: $MESSAGE"
                    ((ERROR_COUNT++))
                    }

                    write_summary() {
                    echo "---------------------------------------------" >> "$RESULTS_FILE"
                    echo "SUMMARY:" >> "$RESULTS_FILE"
                    echo "- Success: $SUCCESS_COUNT" >> "$RESULTS_FILE"
                    echo "- Warnings: $WARNING_COUNT" >> "$RESULTS_FILE"
                    echo "- Errors: $ERROR_COUNT" >> "$RESULTS_FILE"
                    echo "---------------------------------------------" >> "$RESULTS_FILE"
                    }

                    # ─── Main Script ───────────────────────────────────────────
                    mkdir -p /tmp/hana_health
                    setup_log_files "CHKenvOS"
                    echo "Environment and OS Check Results" > "$RESULTS_FILE" # Title

                    # Basic system information checks (hostname, OS, etc.)
                    HOSTNAME_SHORT=$(hostname -s 2>/dev/null || hostname)
                    HOSTNAME_FQDN=$(hostname -f 2>/dev/null || hostname)
                    IP_ADDRESS=$(hostname -I 2>/dev/null | awk '{print $1}' || ip route get 1 | awk '{print $7}')

                    {
                    echo "- Short name: $HOSTNAME_SHORT"
                    echo "- FQDN: $HOSTNAME_FQDN"
                    echo "- IP Address: $IP_ADDRESS"
                    } >> "$RESULTS_FILE"

                    if grep -q "$HOSTNAME_SHORT" /etc/hosts; then
                    log_success "Hostname found in /etc/hosts"
                    echo "- Hostname found in /etc/hosts: Yes" >> "$RESULTS_FILE"
                    else
                    log_warning "Hostname not found in /etc/hosts"
                    echo "- Hostname found in /etc/hosts: No (recommend adding)" >> "$RESULTS_FILE"
                    fi

                    # OS detection
                    if [ -f /etc/os-release ]; then
                    source /etc/os-release
                    OS_NAME=$NAME
                    OS_VERSION=$VERSION
                    OS_ID=$ID
                    OS_VERSION_ID=$VERSION_ID
                    elif [ -f /etc/SuSE-release ]; then
                    OS_NAME="SUSE Linux"
                    OS_VERSION=$(cat /etc/SuSE-release | tr '\n' ' ')
                    OS_ID="sles"
                    OS_VERSION_ID=$(grep VERSION /etc/SuSE-release | awk '{print $3}')
                    elif [ -f /etc/redhat-release ]; then
                    OS_NAME="Red Hat Enterprise Linux"
                    OS_VERSION=$(cat /etc/redhat-release)
                    OS_ID="rhel"
                    OS_VERSION_ID=$(cat /etc/redhat-release | grep -o '[0-9]\.[0-9]' | head -1)
                    else
                    OS_NAME="Unknown"
                    OS_VERSION="Unknown"
                    OS_ID="unknown"
                    OS_VERSION_ID="unknown"
                    log_warning "Could not determine OS type"
                    fi

                    echo "export OS_TYPE=\"$OS_ID\"" >> /tmp/hana_health/env_vars.sh

                    {
                    echo "- OS Name: $OS_NAME"
                    echo "- OS Version: $OS_VERSION"
                    echo "- OS ID: $OS_ID"
                    echo "- OS Version ID: $OS_VERSION_ID"
                    } >> "$RESULTS_FILE"

                    # OS compatibility check
                    if [[ "$OS_ID" == "sles" || "$OS_ID" == "suse" ]]; then
                    SUSE_MIN_VERSION="12.3"
                    if awk "BEGIN {exit !($OS_VERSION_ID >= $SUSE_MIN_VERSION)}"; then
                        log_success "SUSE Linux version $OS_VERSION_ID is compatible"
                        echo "- SUSE Compatibility: Compatible (min: $SUSE_MIN_VERSION)" >> "$RESULTS_FILE"
                    else
                        log_warning "SUSE Linux version $OS_VERSION_ID may not be fully compatible (min: $SUSE_MIN_VERSION)"
                        echo "- SUSE Compatibility: Potentially incompatible (min: $SUSE_MIN_VERSION)" >> "$RESULTS_FILE"
                    fi
                    elif [[ "$OS_ID" == "rhel" ]]; then
                    RHEL_MIN_VERSION="7.4"
                    if awk "BEGIN {exit !($OS_VERSION_ID >= $RHEL_MIN_VERSION)}"; then
                        log_success "RHEL version $OS_VERSION_ID is compatible"
                        echo "- RHEL Compatibility: Compatible (min: $RHEL_MIN_VERSION)" >> "$RESULTS_FILE"
                    else
                        log_warning "RHEL version $OS_VERSION_ID may not be fully compatible (min: $RHEL_MIN_VERSION)"
                        echo "- RHEL Compatibility: Potentially incompatible (min: $RHEL_MIN_VERSION)" >> "$RESULTS_FILE"
                    fi
                    else
                    log_warning "OS is neither SUSE nor RHEL, compatibility cannot be determined"
                    echo "- OS Compatibility: Unknown (supported: SUSE, RHEL)" >> "$RESULTS_FILE"
                    fi

                    # SID admin user check
                    if id "$SIDADM" >/dev/null 2>&1; then
                    log_success "User $SIDADM exists"
                    SIDADM_HOME=$(eval echo ~$SIDADM)
                    {
                        echo "- User $SIDADM exists: Yes"
                        echo "- Home directory: $SIDADM_HOME"
                        
                        if [ -f "$SIDADM_HOME/.bashrc" ]; then
                        echo "- .bashrc file: Found"
                        else
                        echo "- .bashrc file: Not found"
                        fi
                        
                        if [ -f "$SIDADM_HOME/.bash_profile" ]; then
                        echo "- .bash_profile file: Found"
                        else
                        echo "- .bash_profile file: Not found"
                        fi
                    } >> "$RESULTS_FILE"
                    else
                    log_error "User $SIDADM does not exist"
                    echo "- User $SIDADM exists: No (ERROR)" >> "$RESULTS_FILE"
                    fi

                    # ─── HANA Version Detection - MUCH SIMPLER APPROACH ─────────────────
                    get_hana_version() {
                    log "Checking HANA database version..."

                    if ! id "$SIDADM" >/dev/null 2>&1; then
                        log_warning "User $SIDADM doesn't exist, can't check HANA version"
                        return 1
                    fi

                    # Use the HDB version command to get version - direct and simple approach
                    HANA_VERSION=$(su - "$SIDADM" -c "HDB version" 2>/dev/null | awk '/version:/ { print $2 }' | cut -c 1-11)
                    HANA_VERSION_FULL=$(su - "$SIDADM" -c "HDB version | grep version: | cut -c24-" 2>/dev/null)

                    if [ -n "$HANA_VERSION" ]; then
                        log_success "Successfully retrieved HANA version: $HANA_VERSION"
                        
                        # Keep this simple extraction for compatibility with the rest of the script
                        # Extract version components for SPS check
                        HANA_MAJOR=$(echo "$HANA_VERSION" | cut -d. -f1)
                        HANA_MINOR=$(echo "$HANA_VERSION" | cut -d. -f2)
                        HANA_SPS=$(echo "$HANA_VERSION" | cut -d. -f3)
                        HANA_SPS_PADDED=$(printf "%03d" "$HANA_SPS")
                        
                        # Save to environment file
                        echo "export HANA_VERSION_FULL=\"$HANA_VERSION\"" >> /tmp/hana_health/env_vars.sh
                        echo "export HANA_SPS_PADDED=\"$HANA_SPS_PADDED\"" >> /tmp/hana_health/env_vars.sh
                        echo "export HANA_MAJOR=\"$HANA_MAJOR\"" >> /tmp/hana_health/env_vars.sh
                        echo "export HANA_MINOR=\"$HANA_MINOR\"" >> /tmp/hana_health/env_vars.sh
                        echo "export HANA_SPS=\"$HANA_SPS\"" >> /tmp/hana_health/env_vars.sh
                        
                        return 0
                    else
                        log_warning "Could not determine HANA version with 'HDB version'"
                        return 1
                    fi
                    }

                    # ─── HANA Client Version Check ─────────────────────────────────────
                    get_hana_client_version() {
                    log "Checking HANA client version..."

                    # Check for DB client version
                    SHARED_PATH="/hana/shared/$SID"
                    if [ -e "$SHARED_PATH/exe/linuxx86_64/hdb/hdbsql" ]; then
                        HANA_CLIENT_DB=$("$SHARED_PATH/exe/linuxx86_64/hdb/hdbsql" -v 2>/dev/null | awk '/version/ { print $3 }' | cut -c 1-17)
                        log_success "Found HANA Client (DB) version: $HANA_CLIENT_DB"
                        echo "export HANA_CLIENT_DB=\"$HANA_CLIENT_DB\"" >> /tmp/hana_health/env_vars.sh
                        echo "- HANA Client (DB) Version: $HANA_CLIENT_DB" >> "$RESULTS_FILE"
                    else
                        log_warning "HANA Client (DB) not found at $SHARED_PATH/exe/linuxx86_64/hdb/hdbsql"
                        echo "- HANA Client (DB): Not found" >> "$RESULTS_FILE"
                    fi

                    # Check for standalone client version
                    if [ -e "$SHARED_PATH/hdbclient/hdbsql" ]; then
                        HANA_CLIENT_STANDALONE=$("$SHARED_PATH/hdbclient/hdbsql" -v 2>/dev/null | awk '/version/ { print $3 }' | cut -c 1-17)
                        log_success "Found HANA Client (standalone) version: $HANA_CLIENT_STANDALONE"
                        echo "export HANA_CLIENT_STANDALONE=\"$HANA_CLIENT_STANDALONE\"" >> /tmp/hana_health/env_vars.sh
                        echo "- HANA Client (standalone) Version: $HANA_CLIENT_STANDALONE" >> "$RESULTS_FILE"
                    else
                        log_warning "HANA Client (standalone) not found at $SHARED_PATH/hdbclient/hdbsql"
                        echo "- HANA Client (standalone): Not found" >> "$RESULTS_FILE"
                    fi
                    }

                    # Try to get HANA version
                    get_hana_version

                    # If the simple approach failed, fall back to default values or environment variables
                    if [ -z "$HANA_VERSION" ]; then
                    # Fall back to environment variable if we couldn't get version from HDB version
                    if [ -n "${HANA_VERSION_FULL:-}" ] && [ -n "${HANA_SPS_PADDED:-}" ]; then
                        log "Using environment variables for HANA version: ${HANA_VERSION_FULL}"
                    else
                        log_warning "Could not determine HANA version. Assuming SPS below 56 for hdbcli check."
                        HANA_VERSION_FULL="0.0.0.0"
                        HANA_SPS_PADDED="000"
                        echo "export HANA_VERSION_FULL=\"$HANA_VERSION_FULL\"" >> /tmp/hana_health/env_vars.sh
                        echo "export HANA_SPS_PADDED=\"$HANA_SPS_PADDED\"" >> /tmp/hana_health/env_vars.sh
                    fi
                    fi

                    # Add HANA version to results file
                    echo "- HANA Version: ${HANA_VERSION:-${HANA_VERSION_FULL:-Unknown}} (SPS: ${HANA_SPS_PADDED:-Unknown})" >> "$RESULTS_FILE"

                    # Try to get HANA client version
                    get_hana_client_version

                    # Check for hdbcli Python library - EXACTLY AS IN ORIGINAL
                    log "Checking if hdbcli Python library is installed (recommended for HANA < SPS 56)."
                    TARGET_SPS_PADDED="056"

                    if [[ "${HANA_SPS_PADDED:-000}" < "$TARGET_SPS_PADDED" ]]; then
                    log "HANA SPS ${HANA_SPS_PADDED:-000} is below target $TARGET_SPS_PADDED. Checking for hdbcli Python library."
                    PYTHON_EXE=""
                    if command -v python3 &>/dev/null; then
                        PYTHON_EXE="python3"
                    elif command -v python &>/dev/null; then
                        if python --version 2>&1 | grep -q "Python 3"; then
                            PYTHON_EXE="python"
                        fi
                    fi

                    if [ -z "$PYTHON_EXE" ]; then
                        log_warning "Python 3 executable not found. Cannot verify hdbcli installation."
                        echo "- hdbcli Check: SKIPPED (Python 3 not found)" >> "$RESULTS_FILE"
                    else
                        log "Using Python executable: $PYTHON_EXE to check for hdbcli."
                        # Check if hdbcli can be imported
                        if sudo $PYTHON_EXE -c "import hdbcli" &>/dev/null; then
                            log_success "hdbcli Python library is installed and importable."
                            echo "- hdbcli Check: OK (Installed)" >> "$RESULTS_FILE"
                        else
                            # Changed to WARNING instead of ERROR as requested
                            log_warning "hdbcli Python library is NOT installed or importable. It is recommended for HANA revisions below 2.0 SPS 56."
                            echo "- hdbcli Check: WARNING (Not installed/importable - Recommended for this HANA version)" >> "$RESULTS_FILE"
                            # Increment warning count instead of error count
                            ((WARNING_COUNT++))
                        fi
                    fi
                    else
                    log "HANA SPS ${HANA_SPS_PADDED:-000} is not below target $TARGET_SPS_PADDED. hdbcli check not required for this version."
                    echo "- hdbcli Check: SKIPPED (Not required for this HANA version)" >> "$RESULTS_FILE"
                    fi

                    # System parameters
                    {
                    echo "- vm.max_map_count: $(sysctl -n vm.max_map_count 2>/dev/null || echo "Not available")"
                    echo "- vm.overcommit_memory: $(sysctl -n vm.overcommit_memory 2>/dev/null || echo "Not available")"
                    echo "- net.ipv4.tcp_slow_start_after_idle: $(sysctl -n net.ipv4.tcp_slow_start_after_idle 2>/dev/null || echo "Not available")"
                    echo "- net.ipv4.tcp_rmem: $(sysctl -n net.ipv4.tcp_rmem 2>/dev/null || echo "Not available")"
                    echo "- net.ipv4.tcp_wmem: $(sysctl -n net.ipv4.tcp_wmem 2>/dev/null || echo "Not available")"
                    } >> "$RESULTS_FILE"

                    # Hardware info
                    { 
                    TOTAL_MEM=$(free -g | awk '/^Mem:/{print $2}')
                    echo "- Total Memory: $TOTAL_MEM GB"

                    CPU_CORES=$(grep -c ^processor /proc/cpuinfo)
                    CPU_MODEL=$(grep "model name" /proc/cpuinfo | head -1 | cut -d: -f2 | sed 's/^ *//')
                    echo "- CPU Cores: $CPU_CORES"
                    echo "- CPU Model: $CPU_MODEL"
                    } >> "$RESULTS_FILE"

                    # User limits check for sidadm
                    if id "$SIDADM" >/dev/null 2>&1; then
                    echo -e "\nUser Limits for $SIDADM:" >> "$RESULTS_FILE"
                    su - $SIDADM -c "ulimit -a" | sed 's/^/  /' >> "$RESULTS_FILE"

                    # Check nofile limit
                    NOFILE_SOFT=$(su - $SIDADM -c "ulimit -Sn")
                    NOFILE_HARD=$(su - $SIDADM -c "ulimit -Hn")

                    if [ "$NOFILE_SOFT" -lt 1048576 ]; then
                        log_warning "Soft nofile limit for $SIDADM is too low: $NOFILE_SOFT (recommended: ≥1048576)"
                        echo "- WARNING: Soft nofile limit too low: $NOFILE_SOFT (recommended: ≥1048576)" >> "$RESULTS_FILE"
                    else
                        log_success "Soft nofile limit for $SIDADM is adequate: $NOFILE_SOFT"
                    fi

                    if [ "$NOFILE_HARD" -lt 1048576 ]; then
                        log_warning "Hard nofile limit for $SIDADM is too low: $NOFILE_HARD (recommended: ≥1048576)"
                        echo "- WARNING: Hard nofile limit too low: $NOFILE_HARD (recommended: ≥1048576)" >> "$RESULTS_FILE"
                    else
                        log_success "Hard nofile limit for $SIDADM is adequate: $NOFILE_HARD"
                    fi
                    fi

                    write_summary
                    cp "$RESULTS_FILE" "/tmp/hana_health/environment_results.txt"

                    if [ $ERROR_COUNT -gt 0 ]; then
                        log_error "Environment check failed with $ERROR_COUNT errors"
                        exit 1
                    elif [ $WARNING_COUNT -gt 0 ]; then
                        log_warning "Environment check completed with $WARNING_COUNT warnings"
                        exit 0
                    else
                        log_success "Environment check completed successfully"
                        exit 0
                    fi

          - name: InvokePart2
            action: aws:executeAutomation
            onFailure: Continue
            inputs:
              DocumentName: !Sub 'SAPBackupPreCheck-${AWS::StackName}-${SID}-Part2'
              RuntimeParameters:
                InstanceId: '{{ InstanceId }}'
                RunHSIScript: '{{ RunHSIScript }}'
                SID: '{{ SID }}'
                Timestamp: '{{ Timestamp }}'
                S3BucketForLogs: '{{ S3BucketForLogs }}'
                S3UploaderLink: '{{ S3UploaderLink }}'
                HANASupportInfoBucket: '{{ HANASupportInfoBucket }}'
                HANASupportInfoPath: '{{ HANASupportInfoPath }}'
                HANASupportInfoS3Key: '{{ HANASupportInfoS3Key }}'
                SecretArn: '{{ SecretArn }}'
  SAPBackupPreCheckPart2:
    Type: AWS::SSM::Document
    Properties:
      DocumentType: Automation
      Name: !Sub 'SAPBackupPreCheck-${AWS::StackName}-${SID}-Part2'
      Content:
        schemaVersion: '0.3'
        description: AWS Backup SAP HANA Pre-Check Automation (Part 2)
        parameters:
          InstanceId:
            type: String
            description: EC2 instance ID running SAP HANA
          RunHSIScript:
            type: String
            description: Would you like to use the HANA Support Info tool? (yes/no)
            allowedValues:
              - 'yes'
              - 'no'
          SID:
            type: String
            description: SAP HANA system ID
          S3BucketForLogs:
            type: String
            description: S3 bucket for logs (optional)
            default: ''
          S3UploaderLink:
            type: String
            description: AWS Support upload link (optional)
            default: ''
          Timestamp:
            type: String
            default: '{{ automation:EXECUTION_ID }}'
          SecretArn:
            type: String
            description: ARN of secret in Secrets Manager
          HANASupportInfoBucket:
            type: String
            description: S3 bucket containing HANASupportInfo.sh script (optional)
            default: ''
          HANASupportInfoPath:
            type: String
            description: File path where HANASupportInfo.sh script is located or should be downloaded to
            default: /tmp/HANASupportInfo.sh
          HANASupportInfoS3Key:
            type: String
            description: Object key (path + filename) of the script within the S3 bucket
            default: HANASupportInfo.sh
        mainSteps:
          - name: CheckSAPHostAgent
            action: aws:runCommand
            nextStep: DiscoveryLastRun
            onFailure: step:DiscoveryLastRun
            inputs:
              DocumentName: AWS-RunShellScript
              InstanceIds: ['{{ InstanceId }}']
              Parameters:
                commands:
                  - |
                    #!/bin/bash
                    mkdir -p /tmp/hana_health
                    source /tmp/hana_health/env_vars.sh
                    setup_log_files "hostagent_check"
                    INSTANCES_FOUND=0

                    echo "SAP Host Agent Check Results" > "$RESULTS_FILE"

                    echo "SAP Host Agent Version Check:" >> "$RESULTS_FILE"
                    echo "-------------------------" >> "$RESULTS_FILE"

                    if [ -x "/usr/sap/hostctrl/exe/saphostexec" ]; then
                        VERSION_OUTPUT=$(sudo /usr/sap/hostctrl/exe/saphostexec -version 2>&1)
                        if [ $? -eq 0 ]; then
                            echo "- Host Agent Version: $VERSION_OUTPUT" >> "$RESULTS_FILE"
                            log_success "SAP Host Agent version check completed"
                        else
                            echo "- Host Agent Version: Error getting version: $VERSION_OUTPUT" >> "$RESULTS_FILE"
                            log_error "Failed to get SAP Host Agent version"
                            ((ERROR_COUNT++))
                        fi
                    else
                        echo "- Host Agent Version: SAP Host Agent executable not found or not executable" >> "$RESULTS_FILE"
                        log_error "SAP Host Agent executable not found"
                        ((ERROR_COUNT++))
                    fi

                    echo "" >> "$RESULTS_FILE"

                    # Check SAP Host Agent services
                    echo "SAP Host Agent Services Check:" >> "$RESULTS_FILE"
                    echo "---------------------------" >> "$RESULTS_FILE"

                    if command -v systemctl >/dev/null 2>&1; then
                        sapinit_status=$(systemctl status sapinit.service 2>&1)
                        if echo "$sapinit_status" | grep -q "Active: active (running)"; then
                            echo "- SAP Start Service (sapinit): Running" >> "$RESULTS_FILE"
                            echo "  $(echo "$sapinit_status" | grep "Active:")" >> "$RESULTS_FILE"
                            log_success "SAP Start Service is running"
                        else
                            echo "- SAP Start Service (sapinit): Not running" >> "$RESULTS_FILE"
                            echo "  $(echo "$sapinit_status" | grep "Active:")" >> "$RESULTS_FILE"
                            log_warning "SAP Start Service is not running"
                            ((WARNING_COUNT++))
                        fi
                        
                        saphostagent_status=$(systemctl status saphostagent.service 2>&1)
                        if echo "$saphostagent_status" | grep -q "Active: active (running)"; then
                            echo "- SAP Host Agent Service: Running" >> "$RESULTS_FILE"
                            echo "  $(echo "$saphostagent_status" | grep "Active:")" >> "$RESULTS_FILE"
                            log_success "SAP Host Agent Service is running"
                        else
                            echo "- SAP Host Agent Service: Not running" >> "$RESULTS_FILE"
                            echo "  $(echo "$saphostagent_status" | grep "Active:")" >> "$RESULTS_FILE"
                            log_error "SAP Host Agent Service is not running"
                            ((ERROR_COUNT++))
                        fi
                    else
                        echo "- Service Status: Cannot check (systemctl not available)" >> "$RESULTS_FILE"
                        log_warning "systemctl not available to check service status"
                        ((WARNING_COUNT++))
                    fi

                    echo "" >> "$RESULTS_FILE"

                    echo "SAP Host Agent Processes Check:" >> "$RESULTS_FILE"
                    echo "----------------------------" >> "$RESULTS_FILE"

                    sap_processes=$(ps -ef | grep -v grep | grep -E 'sapstartsrv|saphostexec|hostctrl')
                    if [ -n "$sap_processes" ]; then
                        process_count=$(echo "$sap_processes" | wc -l)
                        echo "- SAP-related processes found: $process_count" >> "$RESULTS_FILE"
                        echo "$sap_processes" | sed 's/^/  /' >> "$RESULTS_FILE"
                        log_success "SAP-related processes are running"
                    else
                        echo "- SAP-related processes: None found" >> "$RESULTS_FILE"
                        log_error "No SAP-related processes found"
                        ((ERROR_COUNT++))
                    fi

                    echo "" >> "$RESULTS_FILE"

                    # Check host_profile file
                    echo "Host Profile Check:" >> "$RESULTS_FILE"
                    echo "-----------------" >> "$RESULTS_FILE"

                    host_profile="/usr/sap/hostctrl/exe/host_profile"
                    if [ -f "$host_profile" ]; then
                        # Check permissions
                        perms=$(stat -c "%a %U:%G" "$host_profile")
                        echo "- Host profile file: Present" >> "$RESULTS_FILE"
                        echo "- File permissions: $perms" >> "$RESULTS_FILE"
                        
                        perm_mode=$(stat -c "%a" "$host_profile")
                        perm_group=$(stat -c "%G" "$host_profile")
                        
                        if [ "$perm_mode" = "640" ] || [ "$perm_mode" = "644" ]; then
                            echo "- Permission mode: OK" >> "$RESULTS_FILE"
                            log_success "Host profile has correct permissions"
                        else
                            echo "- Permission mode: INCORRECT (should be 640 or 644)" >> "$RESULTS_FILE"
                            log_error "Host profile has incorrect permissions"
                            ((ERROR_COUNT++))
                        fi
                        
                        if [ "$perm_group" = "sapsys" ]; then
                            echo "- Group owner: OK (sapsys)" >> "$RESULTS_FILE"
                            log_success "Host profile has correct group ownership"
                        else
                            echo "- Group owner: INCORRECT (should be sapsys)" >> "$RESULTS_FILE"
                            log_error "Host profile has incorrect group ownership"
                            ((ERROR_COUNT++))
                        fi
                        
                        echo "- Host profile content (first 5 lines):" >> "$RESULTS_FILE"
                        head -5 "$host_profile" | sed 's/^/  /' >> "$RESULTS_FILE"
                    else
                        echo "- Host profile file: Not found" >> "$RESULTS_FILE"
                        log_error "Host profile file not found"
                        ((ERROR_COUNT++))
                    fi

                    echo "" >> "$RESULTS_FILE"

                    # Check /etc/hosts configuration
                    echo "Hosts File Check:" >> "$RESULTS_FILE"
                    echo "---------------" >> "$RESULTS_FILE"

                    if [ -f "/etc/hosts" ]; then
                        # Count non-comment entries
                        entry_count=$(grep -v "^#" /etc/hosts | grep -v "^$" | wc -l)
                        echo "- Hosts file: Present ($entry_count entries)" >> "$RESULTS_FILE"
                        
                        echo "- Hosts file content:" >> "$RESULTS_FILE"
                        grep -v "^#" /etc/hosts | grep -v "^$" | sed 's/^/  /' >> "$RESULTS_FILE"
                        
                        current_hostname=$(hostname)
                        if grep -q "$current_hostname" /etc/hosts; then
                            echo "- Hostname ($current_hostname) entry: Found" >> "$RESULTS_FILE"
                            log_success "Hostname entry found in /etc/hosts"
                        else
                            echo "- Hostname ($current_hostname) entry: Not found" >> "$RESULTS_FILE"
                            log_warning "Hostname entry not found in /etc/hosts"
                            ((WARNING_COUNT++))
                        fi
                    else
                        echo "- Hosts file: Not found" >> "$RESULTS_FILE"
                        log_error "Hosts file not found"
                        ((ERROR_COUNT++))
                    fi

                    echo "" >> "$RESULTS_FILE"

                    # Check /tmp directory permissions
                    echo "Temp Directory Check:" >> "$RESULTS_FILE"
                    echo "------------------" >> "$RESULTS_FILE"

                    sap_tmp_files=$(ls -altr /tmp/.* 2>/dev/null | grep -i sap)
                    if [ -n "$sap_tmp_files" ]; then
                        echo "- SAP-related files in /tmp:" >> "$RESULTS_FILE"
                        echo "$sap_tmp_files" | sed 's/^/  /' >> "$RESULTS_FILE"
                        log_success "SAP-related files found in /tmp"
                    else
                        echo "- SAP-related files in /tmp: None found" >> "$RESULTS_FILE"
                        log_warning "No SAP-related files found in /tmp"
                        ((WARNING_COUNT++))
                    fi

                    tmp_mount_options=$(findmnt -n -o OPTIONS /tmp 2>/dev/null)
                    echo "- /tmp mount options: $tmp_mount_options" >> "$RESULTS_FILE"

                    if echo "$tmp_mount_options" | grep -q "noexec"; then
                        echo "  WARNING: /tmp is mounted with 'noexec' option" >> "$RESULTS_FILE"
                        log_warning "/tmp is mounted with noexec option which may affect SAP operations"
                        ((WARNING_COUNT++))
                    fi

                    echo "" >> "$RESULTS_FILE"

                    # Check SAP instances via saphostctrl
                    echo "SAP Instances Check:" >> "$RESULTS_FILE"
                    echo "------------------" >> "$RESULTS_FILE"

                    if [ -x "/usr/sap/hostctrl/exe/saphostctrl" ]; then
                        INSTANCE_OUTPUT=$(sudo /usr/sap/hostctrl/exe/saphostctrl -function GetCIMObject -enuminstances SAPInstance -format json 2>&1)
                        if [ $? -eq 0 ]; then
                            JSON_TMP="/tmp/hana_health/instance_output.json"
                            echo "$INSTANCE_OUTPUT" > "$JSON_TMP"
                            log_success "Retrieved SAP instance information"
                            
                            # Process running instances
                            RUNNING_INSTANCES=$(grep -o '{[^{]*"Status":"Running"[^}]*}' "$JSON_TMP" || true)
                            
                            if [ -n "$RUNNING_INSTANCES" ]; then
                                while IFS= read -r instance; do
                                    SID=$(echo "$instance" | sed -n 's/.*"SID":"\([^"]*\)".*/\1/p')
                                    INSTANCE_NAME=$(echo "$instance" | sed -n 's/.*"InstanceName":"\([^"]*\)".*/\1/p')
                                    HOSTNAME=$(echo "$instance" | sed -n 's/.*"Hostname":"\([^"]*\)".*/\1/p')
                                    FEATURES=$(echo "$instance" | sed -n 's/.*"Features":"\([^"]*\)".*/\1/p')
                                    
                                    if [ -n "$SID" ] && [ -n "$INSTANCE_NAME" ]; then
                                        echo "- ${SID} (${INSTANCE_NAME}) on ${HOSTNAME}: Running" >> "$RESULTS_FILE"
                                        echo "  Features: $FEATURES" >> "$RESULTS_FILE"
                                        ((INSTANCES_FOUND++))
                                    fi
                                done <<< "$RUNNING_INSTANCES"
                                
                                # Save the actual instance data for other checks
                                if [ -n "$SID" ]; then
                                    echo "export DETECTED_SID=\"$SID\"" >> /tmp/hana_health/detected_instance.sh
                                    echo "export DETECTED_INSTANCE=\"$INSTANCE_NAME\"" >> /tmp/hana_health/detected_instance.sh
                                    log_success "Found and saved detected instance information"
                                fi
                            fi
                            
                            if [ $INSTANCES_FOUND -eq 0 ]; then
                                echo "- No running instances found" >> "$RESULTS_FILE"
                                log_warning "No running SAP instances detected via saphostctrl"
                                ((WARNING_COUNT++))
                            else
                                echo "- Total running instances: $INSTANCES_FOUND" >> "$RESULTS_FILE"
                                log_success "Found $INSTANCES_FOUND running SAP instances"
                            fi
                        else
                            echo "- Instance Info: Error getting instance information via saphostctrl" >> "$RESULTS_FILE"
                            echo "  Error: $INSTANCE_OUTPUT" >> "$RESULTS_FILE"
                            log_error "Failed to get SAP instance information"
                            ((ERROR_COUNT++))
                        fi
                    else
                        echo "- Instance Info: saphostctrl executable not found or not executable" >> "$RESULTS_FILE"
                        log_error "saphostctrl executable not found"
                        ((ERROR_COUNT++))
                    fi

                    echo "" >> "$RESULTS_FILE"

                    # Test direct HDB info command
                    echo "HDB Info Check:" >> "$RESULTS_FILE"
                    echo "-------------" >> "$RESULTS_FILE"

                    if [ -n "$SID" ]; then
                        SIDADM="${SID,,}adm"
                        HDB_INFO_OUTPUT=$(su - $SIDADM -c 'HDB info' 2>&1)
                        
                        if [ $? -eq 0 ] && [ -n "$HDB_INFO_OUTPUT" ]; then
                            echo "- HDB info command: Successful" >> "$RESULTS_FILE"
                            echo "- HDB processes:" >> "$RESULTS_FILE"
                            echo "$HDB_INFO_OUTPUT" | head -10 | sed 's/^/  /' >> "$RESULTS_FILE"
                            log_success "HDB info command executed successfully"
                        else
                            echo "- HDB info command: Failed" >> "$RESULTS_FILE"
                            echo "  Error: $HDB_INFO_OUTPUT" >> "$RESULTS_FILE"
                            log_warning "HDB info command failed"
                            ((WARNING_COUNT++))
                        fi
                    else
                        echo "- HDB info command: Skipped (SID not available)" >> "$RESULTS_FILE"
                        log_warning "Cannot run HDB info command (SID not available)"
                        ((WARNING_COUNT++))
                    fi

                    echo "" >> "$RESULTS_FILE"

                    # Summary
                    echo "Summary:" >> "$RESULTS_FILE"
                    echo "-------" >> "$RESULTS_FILE"
                    echo "Total Errors: $ERROR_COUNT" >> "$RESULTS_FILE"
                    echo "Total Warnings: $WARNING_COUNT" >> "$RESULTS_FILE"
                    echo "Running Instances: $INSTANCES_FOUND" >> "$RESULTS_FILE"

                    # Add recommendations section if issues found
                    if [ $ERROR_COUNT -gt 0 ] || [ $WARNING_COUNT -gt 0 ]; then
                        echo "" >> "$RESULTS_FILE"
                        echo "Recommendations:" >> "$RESULTS_FILE"
                        echo "---------------" >> "$RESULTS_FILE"
                        
                        if ! systemctl is-active sapinit.service >/dev/null 2>&1; then
                            echo "- Start the SAP start service: systemctl start sapinit.service" >> "$RESULTS_FILE"
                        fi
                        
                        if ! systemctl is-active saphostagent.service >/dev/null 2>&1; then
                            echo "- Start the SAP host agent service: systemctl start saphostagent.service" >> "$RESULTS_FILE"
                        fi
                        
                        if [ ! -f "/usr/sap/hostctrl/exe/host_profile" ] || ! stat -c "%a" "/usr/sap/hostctrl/exe/host_profile" | grep -E "^64[04]$" >/dev/null; then
                            echo "- Fix host_profile permissions: chmod 640 /usr/sap/hostctrl/exe/host_profile" >> "$RESULTS_FILE"
                            echo "- Fix host_profile group: chown :sapsys /usr/sap/hostctrl/exe/host_profile" >> "$RESULTS_FILE"
                        fi
                        
                        if ! grep -q "$(hostname)" /etc/hosts; then
                            echo "- Add hostname to /etc/hosts: echo \"$(hostname -I | awk '{print $1}') $(hostname)\" >> /etc/hosts" >> "$RESULTS_FILE"
                        fi
                        
                        if findmnt -n -o OPTIONS /tmp 2>/dev/null | grep -q "noexec"; then
                            echo "- Warning: /tmp is mounted with noexec option which may affect SAP operations" >> "$RESULTS_FILE"
                            echo "  Consider remounting or adjusting fstab if SAP operations are affected" >> "$RESULTS_FILE"
                        fi
                    fi

                    write_summary

                    if [ $ERROR_COUNT -gt 0 ]; then
                        log_error "SAP Host Agent check failed with $ERROR_COUNT errors"
                        exit 1
                    elif [ $WARNING_COUNT -gt 0 ]; then
                        log_warning "SAP Host Agent check completed with $WARNING_COUNT warnings"
                        exit 0
                    else
                        log_success "SAP Host Agent check completed successfully"
                        exit 0
                    fi
          - name: DiscoveryLastRun
            action: aws:runCommand
            nextStep: NetworkingCheck
            onFailure: step:NetworkingCheck
            inputs:
              DocumentName: AWS-RunShellScript
              InstanceIds: ['{{ InstanceId }}']
              Parameters:
                commands:
                  - |
                    #!/bin/bash
                    source /tmp/hana_health/env_vars.sh
                    setup_log_files "discovery_check"
                    log "Starting SSM Discovery status check"

                    echo "SSM Discovery Status Check Results" > "$RESULTS_FILE"
                    echo "Note: These checks are only relevant if AWS Systems Manager for SAP is installed." >> "$RESULTS_FILE"
                    echo "If you haven't configured SSM-SAP, this check will simply provide status information." >> "$RESULTS_FILE"
                    echo "" >> "$RESULTS_FILE"

                    check_discovery_status() {
                        # Define the standard path for the actual SSM discovery log
                        # Note: This path might differ slightly between OS versions (e.g., /nsr/app/sap/aws-systems-manager-sap-agent/...)
                        # Adjust if necessary based on typical SSM Agent for SAP installations.
                        ACTUAL_DISCOVERY_LOG="/var/log/amazon/ssm/sap/discovery.log"
                        CURRENT_TIME=$(date +%s)
                        # Use local variables for counts within this function scope
                        local ERROR_COUNT=0
                        local WARNING_COUNT=0
                        local SSM_SAP_INSTALLED=false

                        # Function-local logging to stderr to avoid contaminating stdout
                        log_stderr() { echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" >&2; }
                        log_success_stderr() { log_stderr "SUCCESS: $1"; }
                        log_warning_stderr() { log_stderr "WARN: $1"; ((WARNING_COUNT++)); }
                        log_error_stderr() { log_stderr "ERR: $1"; ((ERROR_COUNT++)); }
                        log_info_stderr() { log_stderr "INFO: $1"; }
                        # Function-local results writing to stderr
                        echo_stderr() { echo "$@" >&2; }


                        # 1. Check Current Discovery Status via API
                        echo_stderr "- Checking Discovery Status via API for SID: $SID"
                        ssmsap_info=$(aws ssm-sap get-application --application-id "$SID" 2>/dev/null)
                        if [ $? -eq 0 ] && [ -n "$ssmsap_info" ]; then
                            echo_stderr "- SSM SAP Application ID Found: $SID"
                            SSM_SAP_INSTALLED=true
                            discovery_status=$(echo "$ssmsap_info" | grep -o '"DiscoveryStatus":[[:space:]]*"[^"]*"' | cut -d'"' -f4)
                            echo_stderr "- Current Discovery Status reported by API: $discovery_status"

                            case "$discovery_status" in
                                "SUCCESS")
                                    log_success_stderr "SSM SAP Application discovery successful (API)"
                                    ;;
                                "REGISTERING")
                                    log_warning_stderr "SSM SAP Application discovery in progress (API: REGISTERING)"
                                    ;;
                                "REGISTRATION_FAILED"|"REFRESH_FAILED")
                                    log_warning_stderr "SSM SAP Application discovery status: $discovery_status"
                                    ;;
                                *)
                                    log_warning_stderr "Unexpected SSM SAP Application discovery status from API: $discovery_status"
                                    ;;
                            esac
                        else
                            echo_stderr "- SSM SAP Application ID: Not Found via API ($SID)"
                            log_info_stderr "SSM-SAP may not be installed or configured for $SID"
                        fi

                        # 2. Check Actual Discovery Log File
                        echo_stderr "- Checking Discovery Log File: $ACTUAL_DISCOVERY_LOG"
                        if [ ! -f "$ACTUAL_DISCOVERY_LOG" ]; then
                            echo_stderr "- Discovery Log File: NOT FOUND ($ACTUAL_DISCOVERY_LOG)"
                            log_info_stderr "Looking for discovery logs in alternate locations"
                            
                            # Check alternative locations
                            ALT_LOCATIONS=(
                                "/var/log/aws/ssm-sap"
                                "/var/log/aws-systems-manager-sap-agent"
                                "/usr/bin/ssm-sap/logs"
                            )
                            for loc in "${ALT_LOCATIONS[@]}"; do
                                if [ -d "$loc" ]; then
                                    echo_stderr "- Found potential SSM-SAP log directory: $loc"
                                    if ls "$loc"/*.log &>/dev/null; then
                                        echo_stderr "- Log files exist in alternate location: $loc"
                                        ACTUAL_DISCOVERY_LOG=$(find "$loc" -name "*discovery*.log" -type f 2>/dev/null | head -1)
                                        if [ -n "$ACTUAL_DISCOVERY_LOG" ]; then
                                            echo_stderr "- Using alternate discovery log: $ACTUAL_DISCOVERY_LOG"
                                            SSM_SAP_INSTALLED=true
                                            break
                                        fi
                                    fi
                                fi
                            done
                            
                            if [ ! -f "$ACTUAL_DISCOVERY_LOG" ]; then
                                echo_stderr "- No SSM-SAP discovery logs found in any location"
                                echo_stderr "- This is normal if SSM-SAP has not been configured for this instance"
                                # Output setup recommendation instead of counting as errors
                                echo "0|0|false"  # ERROR_COUNT|WARNING_COUNT|SSM_SAP_INSTALLED
                                return
                            fi
                        else
                            SSM_SAP_INSTALLED=true
                        fi

                        if [ "$SSM_SAP_INSTALLED" = true ]; then
                            echo_stderr "- Discovery Log File: Found ($ACTUAL_DISCOVERY_LOG)"
                            LAST_RUN=$(stat -c %Y "$ACTUAL_DISCOVERY_LOG" 2>/dev/null || echo 0) # Default to 0 if stat fails
                            TIME_DIFF=$((CURRENT_TIME - LAST_RUN))
                            HOUR_IN_SECONDS=3600

                            echo_stderr "- Discovery Log Last Run: $(date -d @${LAST_RUN})"
                            echo_stderr "- Time Since Last Run: $((TIME_DIFF / 60)) minutes"

                            if [ $TIME_DIFF -gt $HOUR_IN_SECONDS ]; then
                                echo_stderr "- Discovery Log Status: ERROR - Not run in the past hour"
                                ((ERROR_COUNT++))
                                log_error_stderr "Discovery has not run in the past hour (Log: $ACTUAL_DISCOVERY_LOG)"
                            else
                                echo_stderr "- Discovery Log Status: OK - Running within expected interval"
                                log_success_stderr "Discovery is running within expected interval (Log: $ACTUAL_DISCOVERY_LOG)"
                            fi

                            # 3. Check Log Content
                            echo_stderr "- Checking Content of Discovery Log: $ACTUAL_DISCOVERY_LOG"
                            if tail -n 50 "$ACTUAL_DISCOVERY_LOG" 2>/dev/null | grep -qiE "error|failed|exception"; then
                                echo_stderr "- Discovery Log Content: WARNING - Recent errors found"
                                log_warning_stderr "Recent errors found in actual discovery log ($ACTUAL_DISCOVERY_LOG)"
                            else
                                echo_stderr "- Discovery Log Content: OK - No recent errors found"
                                log_success_stderr "No recent errors found in actual discovery log ($ACTUAL_DISCOVERY_LOG)"
                            fi

                            if grep -qi "Successfully discovered database" "$ACTUAL_DISCOVERY_LOG" 2>/dev/null; then
                                echo_stderr "- Database Discovery Log Entry: Found"
                                log_success_stderr "Database successfully discovered message found in log"
                            else
                                echo_stderr "- Database Discovery Log Entry: WARNING - Not Found"
                                log_warning_stderr "No database discovery confirmation found in log"
                            fi

                            if grep -qi "Successfully registered application" "$ACTUAL_DISCOVERY_LOG" 2>/dev/null; then
                                echo_stderr "- Application Registration Log Entry: Found"
                                log_success_stderr "Application successfully registered message found in log"
                            else
                                echo_stderr "- Application Registration Log Entry: WARNING - Not Found"
                                log_warning_stderr "No application registration confirmation found in log"
                            fi
                        fi

                        # IMPORTANT: Only output the counts to stdout for capture
                        echo "$ERROR_COUNT|$WARNING_COUNT|$SSM_SAP_INSTALLED"
                    }

                    # --- Execution ---
                    # Capture only the counts from stdout
                    counts_output=$(check_discovery_status)
                    RC_CHECK=$? # Check if the function itself had an issue

                    # Write the detailed status (stderr from check_discovery_status) to the results file
                    # Re-run the function, redirecting its stdout (counts) to null, and append its stderr to results/log
                    check_discovery_status > /dev/null 2>> "$RESULTS_FILE"
                    # Also log the detailed status to the main log file
                    check_discovery_status > /dev/null 2>> "$LOG_FILE"

                    # Parse the captured counts
                    IFS='|' read -r LOCAL_ERRORS LOCAL_WARNINGS SSM_SAP_INSTALLED <<< "$counts_output"

                    # Add local counts to global counts (ensure they are numbers)
                    ERROR_COUNT=$(( ${ERROR_COUNT:-0} + ${LOCAL_ERRORS:-0} ))
                    WARNING_COUNT=$(( ${WARNING_COUNT:-0} + ${LOCAL_WARNINGS:-0} ))

                    # Add recommendations if needed
                    echo -e "\nSSM-SAP Setup Information:" >> "$RESULTS_FILE"
                    if [ "$SSM_SAP_INSTALLED" = "true" ]; then
                        echo "AWS Systems Manager for SAP appears to be installed." >> "$RESULTS_FILE"
                        
                        if [ "$WARNING_COUNT" -gt 0 ]; then
                            echo "There are $WARNING_COUNT warnings that may require attention." >> "$RESULTS_FILE"
                        else
                            echo "No major issues detected with the SSM-SAP installation." >> "$RESULTS_FILE"
                        fi
                    else
                        echo "AWS Systems Manager for SAP does not appear to be installed or configured." >> "$RESULTS_FILE"
                        echo "If you want to use SSM-SAP, you can set it up with the following command:" >> "$RESULTS_FILE"
                        INSTANCE_ID=$(curl -s http://169.254.169.254/latest/meta-data/instance-id 2>/dev/null || echo "{{ InstanceId }}")
                        REGION=$(curl -s http://169.254.169.254/latest/meta-data/placement/region 2>/dev/null || aws configure get region 2>/dev/null || echo "us-east-1")
                        echo "aws ssm start-automation-execution \\" >> "$RESULTS_FILE"
                        echo "  --document-name \"AWSSystemsManagerSAP-Discovery\" \\" >> "$RESULTS_FILE"
                        echo "  --parameters \"InstanceId=$INSTANCE_ID\" \\" >> "$RESULTS_FILE"
                        echo "  --region \"$REGION\"" >> "$RESULTS_FILE"
                    fi

                    # Write the overall summary using global counts
                    write_summary

                    # If SSM-SAP is not installed, don't treat it as an error
                    if [ "$SSM_SAP_INSTALLED" = "false" ]; then
                        log_success "Discovery check completed - SSM-SAP not installed (informational only)"
                        exit 0
                    # Properly report errors with non-zero exit code only if SSM-SAP is installed
                    elif [ $RC_CHECK -ne 0 ]; then
                        log_error "Discovery check finished with script errors (RC=$RC_CHECK)"
                        exit 1
                    elif [ $ERROR_COUNT -gt 0 ]; then
                        log_error "Discovery check finished with errors (Errors=$ERROR_COUNT)"
                        exit 1  # Fail on errors
                    elif [ $WARNING_COUNT -gt 0 ]; then
                        log_warning "Discovery check completed with warnings (Warnings=$WARNING_COUNT)"
                        exit 0  # Don't fail on warnings
                    else
                        log_success "Discovery check completed successfully"
                        exit 0
                    fi

          - name: NetworkingCheck
            action: aws:runCommand
            nextStep: InvokePart3 
            onFailure: Continue
            inputs:
              DocumentName: AWS-RunShellScript
              InstanceIds: ['{{ InstanceId }}']
              Parameters:
                commands:
                  - |
                    #!/bin/bash
                    mkdir -p /tmp/hana_health
                    source /tmp/hana_health/env_vars.sh 2>/dev/null || true

                    LOG_FILE="/tmp/hana_health/net_check.log"
                    RESULTS_FILE="/tmp/hana_health/net_results.txt"
                    ERROR_COUNT=0
                    WARNING_COUNT=0

                    log() {
                        echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" | tee -a "$LOG_FILE"
                    }

                    log_success() {
                        echo "? $1" >> "$RESULTS_FILE"
                        log "SUCCESS: $1"
                    }

                    log_warning() {
                        echo "? WARNING: $1" >> "$RESULTS_FILE"
                        log "WARNING: $1"
                        ((WARNING_COUNT++))
                    }

                    log_error() {
                        echo "? ERROR: $1" >> "$RESULTS_FILE"
                        log "ERROR: $1"
                        ((ERROR_COUNT++))
                    }

                    echo "Network Configuration Check" > "$RESULTS_FILE"
                    echo "=========================" >> "$RESULTS_FILE"

                    # Get instance metadata using IMDS
                    TOKEN=$(curl -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 21600" 2>/dev/null || echo "")
                    if [ -n "$TOKEN" ]; then
                        REGION=$(curl -H "X-aws-ec2-metadata-token: $TOKEN" -s http://169.254.169.254/latest/meta-data/placement/region 2>/dev/null)
                        INSTANCE_ID=$(curl -H "X-aws-ec2-metadata-token: $TOKEN" -s http://169.254.169.254/latest/meta-data/instance-id 2>/dev/null)
                        MAC=$(curl -H "X-aws-ec2-metadata-token: $TOKEN" -s http://169.254.169.254/latest/meta-data/mac 2>/dev/null)
                        VPC_CIDR=$(curl -H "X-aws-ec2-metadata-token: $TOKEN" -s http://169.254.169.254/latest/meta-data/network/interfaces/macs/$MAC/vpc-ipv4-cidr-block 2>/dev/null)
                        SUBNET_ID=$(curl -H "X-aws-ec2-metadata-token: $TOKEN" -s http://169.254.169.254/latest/meta-data/network/interfaces/macs/$MAC/subnet-id 2>/dev/null)
                        PRIVATE_IP=$(curl -H "X-aws-ec2-metadata-token: $TOKEN" -s http://169.254.169.254/latest/meta-data/local-ipv4 2>/dev/null)
                    else
                        REGION=$(curl -s http://169.254.169.254/latest/meta-data/placement/region 2>/dev/null)
                        INSTANCE_ID=$(curl -s http://169.254.169.254/latest/meta-data/instance-id 2>/dev/null)
                        MAC=$(curl -s http://169.254.169.254/latest/meta-data/mac 2>/dev/null)
                        VPC_CIDR=$(curl -s http://169.254.169.254/latest/meta-data/network/interfaces/macs/$MAC/vpc-ipv4-cidr-block 2>/dev/null)
                        SUBNET_ID=$(curl -s http://169.254.169.254/latest/meta-data/network/interfaces/macs/$MAC/subnet-id 2>/dev/null)
                        PRIVATE_IP=$(curl -s http://169.254.169.254/latest/meta-data/local-ipv4 2>/dev/null)
                    fi

                    INSTANCE_ID="${INSTANCE_ID:-{{ InstanceId }}}"
                    echo "export REGION=\"$REGION\"" >> /tmp/hana_health/env_vars.sh
                    echo "export INSTANCE_ID=\"$INSTANCE_ID\"" >> /tmp/hana_health/env_vars.sh
                    echo "export SUBNET_ID=\"$SUBNET_ID\"" >> /tmp/hana_health/env_vars.sh
                    echo "export PRIVATE_IP=\"$PRIVATE_IP\"" >> /tmp/hana_health/env_vars.sh
                    echo "export VPC_CIDR=\"$VPC_CIDR\"" >> /tmp/hana_health/env_vars.sh

                    if command -v aws >/dev/null 2>&1 && [ -n "$REGION" ]; then
                        VPC_INFO=$(aws ec2 describe-instances \
                            --instance-ids "$INSTANCE_ID" \
                            --region "$REGION" \
                            --query 'Reservations[0].Instances[0].VpcId' \
                            --output text 2>/dev/null || echo "unknown")

                        if [ "$VPC_INFO" = "None" ] || [ "$VPC_INFO" = "unknown" ]; then
                            log_warning "Could not determine VPC ID, using 'unknown'"
                            VPC_ID="unknown"
                        else
                            VPC_ID="$VPC_INFO"
                            echo "export VPC_ID=\"$VPC_ID\"" >> /tmp/hana_health/env_vars.sh
                        fi
                    else
                        log_warning "AWS CLI not available - skipping VPC ID lookup"
                        VPC_ID="unknown"
                    fi

                    echo "1. Instance Network Information:" >> "$RESULTS_FILE"
                    echo "------------------------------" >> "$RESULTS_FILE"
                    echo "Region: $REGION" >> "$RESULTS_FILE"
                    echo "Instance ID: $INSTANCE_ID" >> "$RESULTS_FILE"
                    echo "VPC ID: $VPC_ID" >> "$RESULTS_FILE"
                    echo "VPC CIDR: $VPC_CIDR" >> "$RESULTS_FILE"
                    echo "Subnet ID: $SUBNET_ID" >> "$RESULTS_FILE"
                    echo "Private IP: $PRIVATE_IP" >> "$RESULTS_FILE"

                    # Check interface configuration
                    echo "" >> "$RESULTS_FILE"
                    echo "2. Network Interface Configuration:" >> "$RESULTS_FILE"
                    echo "--------------------------------" >> "$RESULTS_FILE"

                    if command -v ip >/dev/null 2>&1; then
                        IP_ADDR=$(ip addr show | grep -v "^[[:space:]]")
                        IP_ROUTE=$(ip route)
                        
                        echo "- Network Interfaces:" >> "$RESULTS_FILE"
                        echo "$IP_ADDR" | sed 's/^/  /' >> "$RESULTS_FILE"
                        
                        echo "" >> "$RESULTS_FILE"
                        echo "- Routing Table:" >> "$RESULTS_FILE"
                        echo "$IP_ROUTE" | sed 's/^/  /' >> "$RESULTS_FILE"
                        
                        # Check if default route exists
                        if echo "$IP_ROUTE" | grep -q "default"; then
                            log_success "Default route found"
                        else
                            log_error "No default route found"
                            echo "  WARNING: No default route found" >> "$RESULTS_FILE"
                        fi
                    else
                        log_warning "ip command not available, using ifconfig"
                        IFCONFIG=$(ifconfig 2>/dev/null || echo "ifconfig not available")
                        NETSTAT=$(netstat -rn 2>/dev/null || echo "netstat -rn not available")
                        
                        echo "- Network Interfaces:" >> "$RESULTS_FILE"
                        echo "$IFCONFIG" | sed 's/^/  /' >> "$RESULTS_FILE"
                        
                        echo "" >> "$RESULTS_FILE"
                        echo "- Routing Table:" >> "$RESULTS_FILE"
                        echo "$NETSTAT" | sed 's/^/  /' >> "$RESULTS_FILE"
                        
                        # Check if default route exists
                        if echo "$NETSTAT" | grep -q "0.0.0.0"; then
                            log_success "Default route found"
                        else
                            log_error "No default route found"
                            echo "  WARNING: No default route found" >> "$RESULTS_FILE"
                        fi
                    fi

                    if ip netns 2>/dev/null | grep -q ""; then
                        echo "" >> "$RESULTS_FILE"
                        echo "- Network Namespaces Detected:" >> "$RESULTS_FILE"
                        ip netns | sed 's/^/  /' >> "$RESULTS_FILE"
                        log_warning "Network namespaces detected - could indicate network virtualization or proxy"
                    fi

                    echo "" >> "$RESULTS_FILE"
                    echo "3. VPC Endpoint Configuration:" >> "$RESULTS_FILE"
                    echo "----------------------------" >> "$RESULTS_FILE"

                    log "Checking endpoints for VPC: $VPC_ID in region: $REGION"

                    REQUIRED_ENDPOINTS=(
                        "com.amazonaws.$REGION.s3|Gateway|Amazon S3"
                        "com.amazonaws.$REGION.secretsmanager|Interface|Secrets Manager"
                    )

                    if command -v aws >/dev/null 2>&1 && [ -n "$REGION" ] && [ "$VPC_ID" != "unknown" ]; then
                        EXISTING_ENDPOINTS=$(aws ec2 describe-vpc-endpoints \
                            --filters "Name=vpc-id,Values=$VPC_ID" \
                            --region "$REGION" \
                            --query 'VpcEndpoints[*].[ServiceName,VpcEndpointType,State]' \
                            --output text 2>/dev/null || echo "")

                        echo "Existing Endpoints:" >> "$RESULTS_FILE"
                        if [ -n "$EXISTING_ENDPOINTS" ]; then
                            echo "$EXISTING_ENDPOINTS" >> "$RESULTS_FILE"
                        else
                            echo "None found" >> "$RESULTS_FILE"
                        fi

                        echo "" >> "$RESULTS_FILE"
                        echo "Missing Endpoints:" >> "$RESULTS_FILE"
                        MISSING_COUNT=0

                        for endpoint in "${REQUIRED_ENDPOINTS[@]}"; do
                            SERVICE_NAME=$(echo "$endpoint" | cut -d'|' -f1)
                            REQUIRED_TYPE=$(echo "$endpoint" | cut -d'|' -f2)
                            SERVICE_DESC=$(echo "$endpoint" | cut -d'|' -f3)
                            
                            if ! echo "$EXISTING_ENDPOINTS" | grep -q "$SERVICE_NAME"; then
                                echo "- $SERVICE_DESC ($SERVICE_NAME) - Type: $REQUIRED_TYPE" >> "$RESULTS_FILE"
                                MISSING_COUNT=$((MISSING_COUNT + 1))
                                log_warning "Missing endpoint: $SERVICE_DESC"
                            else
                                log_success "Found endpoint: $SERVICE_DESC"
                            fi
                        done

                        if [ $MISSING_COUNT -eq 0 ]; then
                            echo "No missing endpoints" >> "$RESULTS_FILE"
                        fi
                    else
                        log_warning "AWS CLI not available or VPC ID unknown - skipping endpoint check"
                        echo "VPC endpoint check skipped - AWS CLI not available or VPC ID unknown" >> "$RESULTS_FILE"
                    fi

                    echo "" >> "$RESULTS_FILE"
                    echo "4. AWS Backup Service Connectivity:" >> "$RESULTS_FILE"
                    echo "---------------------------------" >> "$RESULTS_FILE"

                    echo "DNS Resolution:" >> "$RESULTS_FILE"

                    echo "- AWS Backup Endpoint:" >> "$RESULTS_FILE"
                    if command -v dig >/dev/null 2>&1; then
                        # Use dig command if available
                        DIG_RESULT=$(dig +short $BACKUP_ENDPOINT 2>/dev/null)
                        if [ -n "$DIG_RESULT" ]; then
                            echo "  DNS Resolution: Success" >> "$RESULTS_FILE"
                            echo "  IP Addresses: $DIG_RESULT" >> "$RESULTS_FILE"
                            log_success "DNS resolution working for AWS Backup"
                            
                            # Check if resolves to a cryo domain
                            DIG_CRYO=$(dig +short $BACKUP_ENDPOINT 2>/dev/null | grep "a2z.com")
                            if [ -n "$DIG_CRYO" ]; then
                                echo "  Resolves to: $DIG_CRYO" >> "$RESULTS_FILE"
                            fi
                        else
                            echo "  DNS Resolution: Failed" >> "$RESULTS_FILE"
                            log_error "DNS resolution failed for AWS Backup"
                        fi
                    elif command -v host >/dev/null 2>&1; then
                        if host $BACKUP_ENDPOINT >/dev/null 2>&1; then
                            echo "  DNS Resolution: Success" >> "$RESULTS_FILE"
                            HOST_RESULT=$(host $BACKUP_ENDPOINT | grep "has address" | head -3)
                            echo "  $HOST_RESULT" >> "$RESULTS_FILE"
                            log_success "DNS resolution working for AWS Backup"
                        else
                            echo "  DNS Resolution: Failed" >> "$RESULTS_FILE"
                            log_error "DNS resolution failed for AWS Backup"
                        fi
                    else
                        if nslookup $BACKUP_ENDPOINT >/dev/null 2>&1; then
                            echo "  DNS Resolution: Success" >> "$RESULTS_FILE"
                            log_success "DNS resolution working for AWS Backup"
                        else
                            echo "  DNS Resolution: Failed" >> "$RESULTS_FILE"
                            log_error "DNS resolution failed for AWS Backup"
                        fi
                    fi

                    echo "- S3 Endpoint:" >> "$RESULTS_FILE"
                    if command -v dig >/dev/null 2>&1; then
                        DIG_RESULT=$(dig +short $S3_ENDPOINT 2>/dev/null)
                        if [ -n "$DIG_RESULT" ]; then
                            echo "  DNS Resolution: Success" >> "$RESULTS_FILE"
                            echo "  IP Addresses: $DIG_RESULT" >> "$RESULTS_FILE"
                            log_success "DNS resolution working for S3"
                        else
                            echo "  DNS Resolution: Failed" >> "$RESULTS_FILE"
                            log_error "DNS resolution failed for S3"
                        fi
                    elif command -v host >/dev/null 2>&1; then
                        if host $S3_ENDPOINT >/dev/null 2>&1; then
                            echo "  DNS Resolution: Success" >> "$RESULTS_FILE"
                            log_success "DNS resolution working for S3"
                        else
                            echo "  DNS Resolution: Failed" >> "$RESULTS_FILE"
                            log_error "DNS resolution failed for S3"
                        fi
                    else
                        if nslookup $S3_ENDPOINT >/dev/null 2>&1; then
                            echo "  DNS Resolution: Success" >> "$RESULTS_FILE"
                            log_success "DNS resolution working for S3"
                        else
                            echo "  DNS Resolution: Failed" >> "$RESULTS_FILE"
                            log_error "DNS resolution failed for S3"
                        fi
                    fi

                    echo "" >> "$RESULTS_FILE"
                    echo "5. Connectivity Tests:" >> "$RESULTS_FILE"
                    echo "--------------------" >> "$RESULTS_FILE"

                    # Test IMDS connectivity
                    echo "- IMDS Connectivity:" >> "$RESULTS_FILE"
                    if curl -s --connect-timeout 2 http://169.254.169.254/latest/meta-data/instance-id >/dev/null; then
                        echo "  Status: Success" >> "$RESULTS_FILE"
                        log_success "IMDS connectivity working"
                    else
                        echo "  Status: Failed" >> "$RESULTS_FILE"
                        log_error "IMDS connectivity failed"
                    fi

                    echo "- Internet Connectivity:" >> "$RESULTS_FILE"
                    if ping -c 1 -W 5 8.8.8.8 >/dev/null 2>&1; then
                        echo "  Status: Success" >> "$RESULTS_FILE"
                        log_success "Internet connectivity working"
                    else
                        echo "  Status: Failed" >> "$RESULTS_FILE"
                        log_warning "Internet connectivity issues"
                    fi

                    echo "" >> "$RESULTS_FILE"
                    echo "6. Time Synchronization Check:" >> "$RESULTS_FILE"
                    echo "---------------------------" >> "$RESULTS_FILE"

                    LOCAL_TIME=$(date -u +"%a, %e %b %Y %T %Z")
                    echo "- Local system time: $LOCAL_TIME" >> "$RESULTS_FILE"

                    if command -v curl >/dev/null 2>&1; then
                        S3_DATE=$(curl -v -L https://s3.amazonaws.com 2>&1 | grep -i 'date:' | head -1 | sed 's/.*date: //i')
                        if [ -n "$S3_DATE" ]; then
                            echo "- S3 service time: $S3_DATE" >> "$RESULTS_FILE"
                            log_success "Retrieved S3 server time for comparison"
                        else
                            echo "- S3 service time: Could not retrieve" >> "$RESULTS_FILE"
                            log_warning "Could not retrieve S3 server time"
                        fi
                    fi

                    if command -v systemctl >/dev/null 2>&1; then
                        if systemctl is-active chronyd >/dev/null 2>&1; then
                            echo "- chrony service: Running" >> "$RESULTS_FILE"
                            log_success "chrony service is running"
                            
                            # Check chrony sources
                            if command -v chronyc >/dev/null 2>&1; then
                                CHRONY_SOURCES=$(chronyc sources 2>/dev/null | head -5)
                                echo "- chrony sources:" >> "$RESULTS_FILE"
                                echo "$CHRONY_SOURCES" | sed 's/^/  /' >> "$RESULTS_FILE"
                            fi
                        elif systemctl is-active ntpd >/dev/null 2>&1; then
                            echo "- ntpd service: Running" >> "$RESULTS_FILE"
                            log_success "ntpd service is running"
                        else
                            echo "- Time sync service: Not running" >> "$RESULTS_FILE"
                            log_warning "No time sync service running"
                        fi
                    fi

                    echo "" >> "$RESULTS_FILE"
                    echo "7. Proxy Configuration Check:" >> "$RESULTS_FILE"
                    echo "---------------------------" >> "$RESULTS_FILE"

                    # Check system proxy settings
                    if [ -f "/etc/sysconfig/proxy" ]; then
                        echo "- System proxy configuration found:" >> "$RESULTS_FILE"
                        grep -v "^#" /etc/sysconfig/proxy | grep -v "^$" | sed 's/^/  /' >> "$RESULTS_FILE"
                        
                        # Check if no_proxy includes AWS endpoints
                        if grep -i "no_proxy" /etc/sysconfig/proxy | grep -q "169.254.169.254"; then
                            echo "  ? IMDS excluded from proxy: Yes" >> "$RESULTS_FILE"
                            log_success "IMDS is properly excluded from proxy"
                        else
                            echo "  ? IMDS excluded from proxy: No" >> "$RESULTS_FILE"
                            log_warning "IMDS is not excluded from proxy"
                        fi
                    else
                        echo "- System proxy configuration: Not found" >> "$RESULTS_FILE"
                    fi

                    echo "- Environment proxy variables:" >> "$RESULTS_FILE"
                    env | grep -i "proxy" | sed 's/^/  /' >> "$RESULTS_FILE"

                    AWS_BACKINT_LAUNCHER=$(/usr/bin/find / -name 'aws-backint-agent-launcher.sh' 2>/dev/null | head -1)
                    if [ -n "$AWS_BACKINT_LAUNCHER" ]; then
                        echo "- AWS Backint Agent launcher script: Found at $AWS_BACKINT_LAUNCHER" >> "$RESULTS_FILE"
                        
                        if grep -q "proxy" "$AWS_BACKINT_LAUNCHER"; then
                            echo "  ? Proxy configuration in launcher: Yes" >> "$RESULTS_FILE"
                            
                            if grep -q "no_proxy\|NO_PROXY" "$AWS_BACKINT_LAUNCHER"; then
                                echo "  ? no_proxy configuration: Yes" >> "$RESULTS_FILE"
                                log_success "AWS Backint Agent has proper proxy configuration"
                            else
                                echo "  ? no_proxy configuration: Missing" >> "$RESULTS_FILE"
                                log_warning "AWS Backint Agent launcher is missing no_proxy configuration"
                            fi
                        else
                            echo "  ? Proxy configuration in launcher: No" >> "$RESULTS_FILE"
                        fi
                    else
                        echo "- AWS Backint Agent launcher script: Not found" >> "$RESULTS_FILE"
                    fi

                    echo "" >> "$RESULTS_FILE"
                    echo "8. Network Performance Check:" >> "$RESULTS_FILE"
                    echo "--------------------------" >> "$RESULTS_FILE"

                    if [ -n "$TOKEN" ]; then
                        INSTANCE_TYPE=$(curl -H "X-aws-ec2-metadata-token: $TOKEN" -s http://169.254.169.254/latest/meta-data/instance-type 2>/dev/null)
                    else
                        INSTANCE_TYPE=$(curl -s http://169.254.169.254/latest/meta-data/instance-type 2>/dev/null)
                    fi

                    echo "- Instance type: $INSTANCE_TYPE" >> "$RESULTS_FILE"

                    TRACEROUTE_PATH=$(which traceroute 2>/dev/null)
                    if [ -n "$TRACEROUTE_PATH" ]; then
                        if [ -n "$REGION" ]; then
                            echo "- Network path to AWS Backup service:" >> "$RESULTS_FILE"
                            TRACE_OUTPUT=$(traceroute -n -m 5 backup.$REGION.amazonaws.com 2>&1 | head -6)
                            echo "$TRACE_OUTPUT" | sed 's/^/  /' >> "$RESULTS_FILE"
                        fi
                    fi

                    ETHTOOL_PATH=$(which ethtool 2>/dev/null)
                    if [ -n "$ETHTOOL_PATH" ]; then
                        PRIMARY_IF=$(ip route | grep default | awk '{print $5}')
                        if [ -n "$PRIMARY_IF" ]; then
                            echo "- Network interface speed ($PRIMARY_IF):" >> "$RESULTS_FILE"
                            ETHTOOL_OUTPUT=$(ethtool $PRIMARY_IF 2>/dev/null | grep -E "Speed:|Duplex:|Link detected:")
                            echo "$ETHTOOL_OUTPUT" | sed 's/^/  /' >> "$RESULTS_FILE"
                        fi
                    fi

                    echo "" >> "$RESULTS_FILE"
                    echo "Summary:" >> "$RESULTS_FILE"
                    echo "--------" >> "$RESULTS_FILE"
                    echo "Total Errors: $ERROR_COUNT" >> "$RESULTS_FILE"
                    echo "Total Warnings: $WARNING_COUNT" >> "$RESULTS_FILE"
                    echo "Missing Endpoints: $MISSING_COUNT" >> "$RESULTS_FILE"

                    if [ $ERROR_COUNT -gt 0 ] || [ $WARNING_COUNT -gt 0 ]; then
                        echo "" >> "$RESULTS_FILE"
                        echo "Recommendations:" >> "$RESULTS_FILE"
                        echo "---------------" >> "$RESULTS_FILE"
                        
                        if grep -q "DNS Resolution: Failed" "$RESULTS_FILE"; then
                            echo "- DNS resolution issues detected. Check your DNS configuration and ensure" >> "$RESULTS_FILE"
                            echo "  connectivity to AWS service endpoints." >> "$RESULTS_FILE"
                        fi
                        
                        if grep -q "IMDS excluded from proxy: No" "$RESULTS_FILE"; then
                            echo "- Configure no_proxy to include IMDS (169.254.169.254) and AWS service endpoints." >> "$RESULTS_FILE"
                            echo "  Example: export no_proxy=\"::1,localhost,127.0.0.1,169.254.169.254,fd00:ec2::254,s3.amazonaws.com,.s3.${REGION}.amazonaws.com\"" >> "$RESULTS_FILE"
                        fi
                        
                        if grep -q "Time sync service: Not running" "$RESULTS_FILE"; then
                            echo "- Install and enable chronyd: systemctl enable --now chronyd" >> "$RESULTS_FILE"
                            echo "  Time synchronization is critical for AWS API requests." >> "$RESULTS_FILE"
                        fi
                        
                        if grep -q "no_proxy configuration: Missing" "$RESULTS_FILE"; then
                            echo "- Update AWS Backint Agent launcher script to include proper no_proxy settings:" >> "$RESULTS_FILE"
                            echo "  Add to $AWS_BACKINT_LAUNCHER:" >> "$RESULTS_FILE"
                            echo "  export no_proxy=\"::1,localhost,127.0.0.1,169.254.169.254,fd00:ec2::254,s3.amazonaws.com,.s3.${REGION}.amazonaws.com\"" >> "$RESULTS_FILE"
                        fi
                        
                        if [ $MISSING_COUNT -gt 0 ]; then
                            echo "- Consider creating the missing VPC endpoints for optimal AWS service connectivity." >> "$RESULTS_FILE"
                            echo "  AWS Backup and S3 endpoints are especially important for backup operations." >> "$RESULTS_FILE"
                        fi
                        
                        # Check for proxy bottleneck scenario
                        if [ -n "$INSTANCE_TYPE" ] && [[ "$INSTANCE_TYPE" == x1* || "$INSTANCE_TYPE" == r5* || "$INSTANCE_TYPE" == x2* ]]; then
                            echo "- You're running on a high-performance instance type ($INSTANCE_TYPE)." >> "$RESULTS_FILE"
                            echo "  If using a firewall/proxy, ensure it has sufficient network capacity" >> "$RESULTS_FILE"
                            echo "  to match your SAP HANA instance capabilities." >> "$RESULTS_FILE"
                        fi
                    fi

                    log "Network check completed with $ERROR_COUNT errors and $WARNING_COUNT warnings"

                    if [ $ERROR_COUNT -gt 0 ]; then
                        exit 1
                    else
                        exit 0
                    fi

          - name: InvokePart3 
            action: aws:executeAutomation
            inputs:
              DocumentName: !Sub 'SAPBackupPreCheck-${AWS::StackName}-${SID}-Part3'
              RuntimeParameters:
                InstanceId: '{{ InstanceId }}'
                RunHSIScript: '{{ RunHSIScript }}'
                SID: '{{ SID }}'
                Timestamp: '{{ Timestamp }}'
                S3BucketForLogs: '{{ S3BucketForLogs }}'
                S3UploaderLink: '{{ S3UploaderLink }}'
                HANASupportInfoBucket: '{{ HANASupportInfoBucket }}'
                HANASupportInfoPath: '{{ HANASupportInfoPath }}'
                HANASupportInfoS3Key: '{{ HANASupportInfoS3Key }}'
                SecretArn: '{{ SecretArn }}'         
  SAPBackupPreCheckPart3:
    Type: AWS::SSM::Document
    Properties:
      DocumentType: Automation
      Name: !Sub 'SAPBackupPreCheck-${AWS::StackName}-${SID}-Part3'
      Content:
        schemaVersion: '0.3'
        description: AWS Backup SAP HANA Pre-Check Automation (Part 3)
        parameters:
          InstanceId:
            type: String
            description: EC2 instance ID running SAP HANA
          RunHSIScript:
            type: String
            description: Would you like to use the HANA Support Info tool? (yes/no)
            allowedValues:
              - 'yes'
              - 'no'
          SID:
            type: String
            description: SAP HANA system ID
          S3BucketForLogs:
            type: String
            description: S3 bucket for logs (optional)
            default: ''
          S3UploaderLink:
            type: String
            description: AWS Support upload link (optional)
            default: ''
          Timestamp:
            type: String
            default: '{{ automation:EXECUTION_ID }}'
          SecretArn:
            type: String
            description: ARN of secret in Secrets Manager
          HANASupportInfoBucket:
            type: String
            description: S3 bucket containing HANASupportInfo.sh script (optional)
            default: ''
          HANASupportInfoPath:
            type: String
            description: File path where HANASupportInfo.sh script is located or should be downloaded to
            default: /tmp/HANASupportInfo.sh
          HANASupportInfoS3Key:
            type: String
            description: Object key (path + filename) of the script within the S3 bucket
            default: HANASupportInfo.sh
        mainSteps:
          - name: CheckClusterConfiguration
            action: aws:runCommand
            nextStep: CheckHanaStatus
            onFailure: step:CheckHanaStatus
            inputs:
              DocumentName: AWS-RunShellScript
              InstanceIds: ['{{ InstanceId }}']
              Parameters:
                commands:
                  - |
                    #!/bin/bash
                    mkdir -p /tmp/hana_health
                    source /tmp/hana_health/env_vars.sh
                    setup_log_files "cluster_check"

                    log "Starting basic cluster detection"

                    CLUSTER_DETECTED=0
                    CLUSTER_TYPE="NONE"

                    if command -v crm &>/dev/null; then
                        CLUSTER_DETECTED=1
                        CLUSTER_TYPE="SUSE"
                        log "Detected SUSE cluster (crm found)"
                        echo "Cluster Type: SUSE" >> "$RESULTS_FILE"

                        if crm status 2>/dev/null | grep -q SAPHana; then
                            echo "HANA Cluster Resource: Found" >> "$RESULTS_FILE"
                        else
                            echo "HANA Cluster Resource: Not found" >> "$RESULTS_FILE"
                        fi

                    elif command -v pcs &>/dev/null; then
                        CLUSTER_DETECTED=1
                        CLUSTER_TYPE="RHEL"
                        log "Detected RHEL cluster (pcs found)"
                        echo "Cluster Type: RHEL" >> "$RESULTS_FILE"

                        if pcs status 2>/dev/null | grep -q SAPHana; then
                            echo "HANA Cluster Resource: Found" >> "$RESULTS_FILE"
                        else
                            echo "HANA Cluster Resource: Not found" >> "$RESULTS_FILE"
                        fi
                    else
                        log "No cluster detected"
                        echo "Cluster Check: No cluster detected" >> "$RESULTS_FILE"
                    fi

                    NODE_COUNT=1            # default

                    if command -v crm &>/dev/null; then                   # SUSE cluster
                        if crm cluster status 2>/dev/null | grep -q '^Nodes configured'; then
                            NODE_COUNT=$(crm cluster status 2>/dev/null \
                                          | awk '/^Nodes configured/ {print $3}')
                        else
                            NODE_COUNT=$(crm_node -l 2>/dev/null | wc -l)
                        fi

                    elif command -v pcs &>/dev/null; then                 # RHEL / Pacemaker
                        if pcs status nodes 2>/dev/null | grep -q '^Online'; then
                            NODE_COUNT=$(pcs status nodes 2>/dev/null | grep -c '^Online')
                        else
                            NODE_COUNT=$(pcs status 2>/dev/null | grep -c '^Node ')
                        fi

                    else                                                  # no cluster manager
                        # Fallback ? old directory count keeps single?box behaviour
                        NODE_COUNT=$(ls -1d /usr/sap/${SID}/HDB??/*/trace 2>/dev/null | wc -l)
                    fi

                    if [ "$NODE_COUNT" -gt 1 ]; then
                        echo "Multi-node: Yes ($NODE_COUNT nodes detected)" >> "$RESULTS_FILE"
                    else
                        echo "Multi-node: No" >> "$RESULTS_FILE"
                    fi
                    # ------------------------------------------------------------------

                    echo "export CLUSTER_DETECTED=$CLUSTER_DETECTED" >> /tmp/hana_health/env_vars.sh
                    echo "export CLUSTER_TYPE=\"$CLUSTER_TYPE\""    >> /tmp/hana_health/env_vars.sh
                    echo "export NODE_COUNT=$HANA_NODES"            >> /tmp/hana_health/env_vars.sh

                    {
                      echo -e "\nSummary:"
                      echo "Cluster detected: $([ $CLUSTER_DETECTED -eq 1 ] && echo \"Yes - $CLUSTER_TYPE\" || echo \"No\")"
                    } >> "$RESULTS_FILE"

                    log "Completed basic cluster check - $([ $CLUSTER_DETECTED -eq 1 ] && echo \"Cluster: $CLUSTER_TYPE\" || echo \"No cluster\")"
                    exit 0
          - name: CheckHanaStatus
            action: aws:runCommand
            nextStep: CheckBackupConfiguration
            onFailure: step:CheckBackupConfiguration
            inputs:
              DocumentName: AWS-RunShellScript
              InstanceIds: ['{{ InstanceId }}']
              Parameters:
                commands:
                  - |
                    #!/bin/bash
                    mkdir -p /tmp/hana_health
                    source /tmp/hana_health/env_vars.sh
                    setup_log_files "hana_status"

                    # Main execution starts here
                    hana_active=1
                    WARNING_COUNT=0
                    ERROR_COUNT=0

                    # Check if HANA processes are running
                    if pgrep -f "HDB" > /dev/null; then
                      hdb_pid=$(pgrep -f "hdbnameserver" | head -1)
                      if [ -n "$hdb_pid" ]; then
                        hdb_uptime=$(ps -p "$hdb_pid" -o etime= 2>/dev/null | tr -d ' ')
                        log_success "SAP HANA is ACTIVE (uptime: $hdb_uptime)"
                        echo "HANA Status: ACTIVE (uptime: $hdb_uptime)" >> "$RESULTS_FILE"
                        hana_active=0
                        
                        # Check if essential services are running
                        essential_processes=("hdbnameserver" "hdbindexserver" "hdbcompileserver")
                        all_essential=true
                        
                        for proc in "${essential_processes[@]}"; do
                          if ! pgrep -f "$proc" > /dev/null; then
                            all_essential=false
                            log_warning "Essential process $proc not found"
                            ((WARNING_COUNT++))
                          fi
                        done
                        
                        if [ "$all_essential" = true ]; then
                          log_success "All essential HANA processes are running"
                        else
                          log_warning "Some essential HANA processes are missing, but system is considered active"
                        fi
                      else
                        log_error "SAP HANA processes found but nameserver is not running"
                        echo "HANA Status: NOT ACTIVE (nameserver not running)" >> "$RESULTS_FILE"
                        ((ERROR_COUNT++))
                      fi
                    else
                      log_error "SAP HANA is NOT ACTIVE (no processes running)"
                      echo "HANA Status: NOT ACTIVE" >> "$RESULTS_FILE"
                      ((ERROR_COUNT++))
                    fi

                    # Optional: Add replication status check without requiring query execution
                    if [ "$hana_active" -eq 0 ]; then
                      if [ -f "/usr/sap/${SID}/SYS/global/hdb/custom/config/global.ini" ]; then
                        if grep -q "enable_primary_read_only" "/usr/sap/${SID}/SYS/global/hdb/custom/config/global.ini" || \
                          grep -q "site_id" "/usr/sap/${SID}/SYS/global/hdb/custom/config/global.ini"; then
                          echo "Replication: Configured (based on config)" >> "$RESULTS_FILE"
                        else
                          echo "Replication: Not configured (based on config)" >> "$RESULTS_FILE"
                        fi
                      fi
                    fi

                    write_summary

                    if [ $ERROR_COUNT -gt 0 ]; then
                        log_error "HANA status check failed with $ERROR_COUNT errors"
                        exit 1
                    elif [ $WARNING_COUNT -gt 0 ]; then
                        log_warning "HANA status check completed with $WARNING_COUNT warnings"
                        exit 0
                    else
                        log_success "HANA status check completed successfully"
                        exit 0
                    fi

          - name: CheckBackupConfiguration
            action: aws:runCommand
            nextStep: InvokePart4
            onFailure: Continue
            inputs:
              DocumentName: AWS-RunShellScript
              InstanceIds: ['{{ InstanceId }}']
              Parameters:
                commands:
                  - |
                    #!/bin/bash
                    mkdir -p /tmp/hana_health
                    source /tmp/hana_health/env_vars.sh
                    setup_log_files "backup_config"

                    detect_sap_instance() {
                    if [ -f "/tmp/hana_health/env_vars.sh" ]; then
                        source /tmp/hana_health/env_vars.sh
                    else
                        log_error "env_vars.sh not found - this might cause inconsistent SID/instance detection"
                        SID="${SID:-{{ SID }}}"
                        INSTANCE_NUM="${INSTANCE_NUM:-$(ls -d /usr/sap/$SID/HDB[0-9][0-9] 2>/dev/null | grep -Po 'HDB\K[0-9]+' | head -1 || echo "00")}"
                        INSTANCE_NUMBER="${INSTANCE_NUM}"
                        SIDADM="${SID,,}adm"
                        HOSTNAME=${HOSTNAME:-$(hostname)}
                    fi
                    }

                    setup_log_files "backup_config"
                    detect_sap_instance

                    # Initialize counters
                    ERROR_COUNT=0
                    WARNING_COUNT=0
                    MISSING_COUNT=0

                    # Check AWS CLI Configuration (removed AWS region check)
                    check_aws_cli() {
                    echo "AWS CLI Configuration Check:" >> "$RESULTS_FILE"
                    echo "--------------------------" >> "$RESULTS_FILE"

                    if command -v aws >/dev/null 2>&1; then
                        AWS_VERSION=$(aws --version 2>&1)
                        echo "- AWS CLI: Installed - $AWS_VERSION" >> "$RESULTS_FILE"
                        log_success "AWS CLI installed: $AWS_VERSION"
                        
                        AWS_CONFIG=$(aws configure list 2>&1)
                        echo "- AWS Config:" >> "$RESULTS_FILE"
                        echo "$AWS_CONFIG" | head -5 | sed 's/^/  /' >> "$RESULTS_FILE"
                        
                        # Check credential source
                        if echo "$AWS_CONFIG" | grep -q "iam-role"; then
                        echo "- Credential source: IAM Role" >> "$RESULTS_FILE"
                        log_success "AWS CLI using IAM Role"
                        else
                        echo "- Credential source: $(echo "$AWS_CONFIG" | grep "credential_source" | awk '{print $2}')" >> "$RESULTS_FILE"
                        log_warning "AWS CLI may not be using IAM Role"
                        ((WARNING_COUNT++))
                        fi
                        
                    else
                        echo "- AWS CLI: Not installed" >> "$RESULTS_FILE"
                        log_error "AWS CLI not installed"
                        ((ERROR_COUNT++))
                    fi

                    # Check if we have /root/.aws/config
                    if [ -f "/root/.aws/config" ]; then
                        echo "- Root AWS config file: Present" >> "$RESULTS_FILE"
                        log_success "Root AWS config file exists"
                    else
                        echo "- Root AWS config file: Missing" >> "$RESULTS_FILE"
                        log_warning "Root AWS config file missing"
                        ((WARNING_COUNT++))
                    fi

                    echo "" >> "$RESULTS_FILE"
                    }

                    check_backup_catalog() {
                    echo "Backup Catalog Check:" >> "$RESULTS_FILE"
                    echo "--------------------" >> "$RESULTS_FILE"

                    if [ -f "/tmp/hana_health/backup_config.txt" ]; then
                        echo "- Backup config file: Exists" >> "$RESULTS_FILE"
                        log_success "Backup config file exists"
                    else
                        echo "- Backup config file: Missing" >> "$RESULTS_FILE"
                        log_warning "Backup config file missing"
                        ((WARNING_COUNT++))
                    fi

                    if [ -f "/tmp/hana_health/backup_config.log" ]; then
                        echo "- Backup config log: Exists" >> "$RESULTS_FILE"
                        log_success "Backup config log exists"
                    else
                        echo "- Backup config log: Missing" >> "$RESULTS_FILE"
                        log_warning "Backup config log missing"
                        ((WARNING_COUNT++))
                    fi

                    echo "" >> "$RESULTS_FILE"
                    }

                    check_log_backup_config() {
                    echo "Log Backup Configuration:" >> "$RESULTS_FILE"
                    echo "------------------------" >> "$RESULTS_FILE"

                    global_ini="/usr/sap/$SID/SYS/global/hdb/custom/config/global.ini"

                    if [ ! -f "$global_ini" ]; then
                        log_warning "global.ini not found"
                        echo "- global.ini: Not found" >> "$RESULTS_FILE"
                        return 1
                    fi

                    log_mode=$(grep -A 5 "\[persistence\]" "$global_ini" | grep "log_mode" | awk -F'=' '{print $2}' | tr -d ' ')

                    if [ -z "$log_mode" ]; then
                        sys_global_ini="/usr/sap/$SID/SYS/global/hdb/custom/config/global.ini"
                        if [ -f "$sys_global_ini" ]; then
                        log_mode=$(grep -A 5 "\[persistence\]" "$sys_global_ini" | grep "log_mode" | awk -F'=' '{print $2}' | tr -d ' ')
                        fi
                    fi

                    if [ -z "$log_mode" ]; then
                        log "Log mode not explicitly set, using default (normal)"
                        echo "- Log mode: Default (normal)" >> "$RESULTS_FILE"
                        log_mode="normal"
                    else
                        echo "- Log mode: $log_mode" >> "$RESULTS_FILE"
                    fi

                    if [ "$log_mode" = "overwrite" ]; then
                        log_error "Log mode set to 'overwrite' - prevents log backups"
                        echo "- Log mode: overwrite (prevents backups)" >> "$RESULTS_FILE"
                        ((ERROR_COUNT++))
                    fi

                    # Check other log backup parameters
                    log_backup_interval=$(grep -A 10 "\[persistence\]" "$global_ini" | grep "log_backup_interval" | awk -F'=' '{print $2}' | tr -d ' ')
                    if [ -n "$log_backup_interval" ]; then
                        echo "- Log backup interval: $log_backup_interval" >> "$RESULTS_FILE"
                        if [ "$log_backup_interval" -gt 60 ]; then
                        log_warning "Log backup interval ($log_backup_interval) > 60"
                        echo "  WARNING: Interval higher than recommended value (60)" >> "$RESULTS_FILE"
                        ((WARNING_COUNT++))
                        else
                        log_success "Log backup interval within recommended range"
                        fi
                    else
                        echo "- Log backup interval: Not set (using default)" >> "$RESULTS_FILE"
                    fi

                    auto_log_backup=$(grep -A 10 "\[persistence\]" "$global_ini" | grep "auto_log_backup" | awk -F'=' '{print $2}' | tr -d ' ')
                    if [ -n "$auto_log_backup" ]; then
                        echo "- Automatic log backup: $auto_log_backup" >> "$RESULTS_FILE"
                        if [ "$auto_log_backup" = "false" ] || [ "$auto_log_backup" = "no" ]; then
                        log_warning "Automatic log backup disabled"
                        echo "  WARNING: Automatic log backup is disabled" >> "$RESULTS_FILE"
                        ((WARNING_COUNT++))
                        else
                        log_success "Automatic log backup enabled"
                        fi
                    else
                        echo "- Automatic log backup: Not set (using default)" >> "$RESULTS_FILE"
                    fi

                    echo "" >> "$RESULTS_FILE"
                    }

                    check_backup_destinations() {
                    echo "Backup Destinations Check:" >> "$RESULTS_FILE"
                    echo "------------------------" >> "$RESULTS_FILE"

                    # Find AWS Backint agent using find
                    BACKINT_DIRS=$(/usr/bin/find / -type d -name 'aws-backint-agent' 2>/dev/null)

                    if [ -z "$BACKINT_DIRS" ]; then
                        echo "- AWS Backint Agent: Not found on system" >> "$RESULTS_FILE"
                        log_error "AWS Backint agent directory not found"
                        ((ERROR_COUNT++))
                        return 1
                    fi

                    # Use the first directory found
                    backint_dir=$(echo "$BACKINT_DIRS" | head -1)
                    backint_agent="$backint_dir/aws-backint-agent"

                    if [ -x "$backint_agent" ]; then
                        echo "- AWS Backint Agent: Found at $backint_agent" >> "$RESULTS_FILE"
                        
                        # Check version
                        version=$("$backint_agent" version 2>/dev/null || "$backint_agent" -v 2>/dev/null)
                        if [ -n "$version" ]; then
                        echo "  Version: $version" >> "$RESULTS_FILE"
                        log_success "Found AWS Backint agent: $version"
                        else
                        echo "  Version: Unknown" >> "$RESULTS_FILE"
                        log_warning "Could not determine AWS Backint agent version"
                        ((WARNING_COUNT++))
                        fi
                        
                        # Check config files
                        config_files=$(find "$backint_dir" -name "*.yaml" 2>/dev/null)
                        if [ -n "$config_files" ]; then
                        echo "- Configuration files:" >> "$RESULTS_FILE"
                        echo "$config_files" | while read -r config_file; do
                            echo "  Found: $config_file" >> "$RESULTS_FILE"
                        done
                        else
                        echo "- Configuration files: Not found" >> "$RESULTS_FILE"
                        log_error "AWS Backint agent config files not found"
                        ((ERROR_COUNT++))
                        fi
                        
                        # Check StorageId.json
                        storage_id_file="$backint_dir/awsbackup/StorageId.json"
                        if [ -f "$storage_id_file" ]; then
                        echo "- StorageId.json: Present" >> "$RESULTS_FILE"
                        log_success "StorageId.json file found"
                        else
                        echo "- StorageId.json: Not found" >> "$RESULTS_FILE"
                        log_warning "StorageId.json file not found"
                        ((WARNING_COUNT++))
                        fi
                        
                        # Check log files
                        echo "- Log files:" >> "$RESULTS_FILE"
                        backint_log="$backint_dir/aws-backint-agent.log"
                        if [ -f "$backint_log" ]; then
                        log_size=$(du -h "$backint_log" 2>/dev/null | cut -f1)
                        echo "  AWS Backint Agent log: Present (Size: $log_size)" >> "$RESULTS_FILE"
                        
                        # Check for recent errors
                        if tail -n 100 "$backint_log" | grep -i "error\|failed\|exception" > /dev/null; then
                            echo "    WARNING: Recent errors found in log" >> "$RESULTS_FILE"
                            log_warning "Recent errors found in Backint Agent log"
                            ((WARNING_COUNT++))
                        fi
                        else
                        echo "  AWS Backint Agent log: Not found" >> "$RESULTS_FILE"
                        log_warning "AWS Backint Agent log not found"
                        ((WARNING_COUNT++))
                        fi
                        
                        # Check SAP trace logs
                        trace_dir="/usr/sap/$SID/$SID$INSTANCE_NUM/$HOSTNAME/trace"
                        system_backint_log="$trace_dir/backint.log"
                        system_backup_log="$trace_dir/backup.log"
                        
                        if [ -f "$system_backint_log" ]; then
                        log_size=$(du -h "$system_backint_log" 2>/dev/null | cut -f1)
                        echo "  SYSTEMDB backint log: Present (Size: $log_size)" >> "$RESULTS_FILE"
                        else
                        echo "  SYSTEMDB backint log: Not found" >> "$RESULTS_FILE"
                        log_warning "SYSTEMDB backint log not found"
                        ((WARNING_COUNT++))
                        fi
                        
                        if [ -f "$system_backup_log" ]; then
                        log_size=$(du -h "$system_backup_log" 2>/dev/null | cut -f1)
                        echo "  SYSTEMDB backup log: Present (Size: $log_size)" >> "$RESULTS_FILE"
                        else
                        echo "  SYSTEMDB backup log: Not found" >> "$RESULTS_FILE"
                        log_warning "SYSTEMDB backup log not found"
                        ((WARNING_COUNT++))
                        fi
                        
                        # Check TENANT DB logs if they exist
                        tenant_dir="$trace_dir/DB_$SID"
                        if [ -d "$tenant_dir" ]; then
                        tenant_backint_log="$tenant_dir/backint.log"
                        tenant_backup_log="$tenant_dir/backup.log"
                        
                        if [ -f "$tenant_backint_log" ]; then
                            log_size=$(du -h "$tenant_backint_log" 2>/dev/null | cut -f1)
                            echo "  TENANT DB backint log: Present (Size: $log_size)" >> "$RESULTS_FILE"
                        else
                            echo "  TENANT DB backint log: Not found" >> "$RESULTS_FILE"
                            log_warning "TENANT DB backint log not found"
                            ((WARNING_COUNT++))
                        fi
                        
                        if [ -f "$tenant_backup_log" ]; then
                            log_size=$(du -h "$tenant_backup_log" 2>/dev/null | cut -f1)
                            echo "  TENANT DB backup log: Present (Size: $log_size)" >> "$RESULTS_FILE"
                        else
                            echo "  TENANT DB backup log: Not found" >> "$RESULTS_FILE"
                            log_warning "TENANT DB backup log not found"
                            ((WARNING_COUNT++))
                        fi
                        fi
                    else
                        echo "- AWS Backint Agent: Not installed or not executable at $backint_agent" >> "$RESULTS_FILE"
                        log_error "AWS Backint agent not found or not executable"
                        ((ERROR_COUNT++))
                    fi

                    echo "" >> "$RESULTS_FILE"
                    }

                    # Check for the zzz_which2 files
                    check_which_command() {
                    echo "Which Command Configuration Check:" >> "$RESULTS_FILE"
                    echo "--------------------------------" >> "$RESULTS_FILE"

                    # Just verify files exist without accessing them
                    if [ -f "/etc/profile.d/zzz_which2.sh" ]; then
                        echo "- Which command configuration shell script: Present" >> "$RESULTS_FILE"
                        log_success "Which command shell script exists"
                    else
                        echo "- Which command configuration shell script: Missing" >> "$RESULTS_FILE"
                        log_warning "Which command shell script missing"
                        ((WARNING_COUNT++))
                    fi

                    if [ -f "/etc/profile.d/zzz_which2.csh" ]; then
                        echo "- Which command configuration csh script: Present" >> "$RESULTS_FILE"
                        log_success "Which command csh script exists"
                    else
                        echo "- Which command configuration csh script: Missing" >> "$RESULTS_FILE"
                        log_warning "Which command csh script missing"
                        ((WARNING_COUNT++))
                    fi

                    echo "" >> "$RESULTS_FILE"
                    }

                    # Check user session environment for <sid>adm
                    check_user_environment() {
                    echo "User Session Environment Check:" >> "$RESULTS_FILE"
                    echo "-----------------------------" >> "$RESULTS_FILE"

                    # Check if SIDADM user exists
                    if id "$SIDADM" >/dev/null 2>&1; then
                        echo "- $SIDADM user: Exists" >> "$RESULTS_FILE"
                        log_success "$SIDADM user exists"
                    else
                        echo "- $SIDADM user: Not found" >> "$RESULTS_FILE"
                        log_error "$SIDADM user not found"
                        ((ERROR_COUNT++))
                        return 1
                    fi

                    echo "" >> "$RESULTS_FILE"
                    }

                    # Check host profile file
                    check_host_profile() {
                    echo "Host Profile Check:" >> "$RESULTS_FILE"
                    echo "------------------" >> "$RESULTS_FILE"

                    host_profile="/usr/sap/hostctrl/exe/host_profile"

                    if [ -f "$host_profile" ]; then
                        # Check permissions
                        perms=$(stat -c "%a" "$host_profile")
                        owner=$(stat -c "%U" "$host_profile")
                        group=$(stat -c "%G" "$host_profile")
                        
                        echo "- Host profile file: Present" >> "$RESULTS_FILE"
                        echo "  Permissions: $perms ($owner:$group)" >> "$RESULTS_FILE"
                        
                        if [ "$perms" = "640" ] || [ "$perms" = "644" ]; then
                        log_success "Host profile permissions are correct"
                        else
                        echo "  WARNING: Permissions should be 640 or 644" >> "$RESULTS_FILE"
                        log_warning "Host profile permissions are incorrect"
                        ((WARNING_COUNT++))
                        fi
                        
                        if [ "$group" = "sapsys" ]; then
                        log_success "Host profile group is correct"
                        else
                        echo "  WARNING: Group should be sapsys" >> "$RESULTS_FILE"
                        log_warning "Host profile group is incorrect"
                        ((WARNING_COUNT++))
                        fi
                    else
                        echo "- Host profile file: Not found" >> "$RESULTS_FILE"
                        log_error "Host profile file not found"
                        ((ERROR_COUNT++))
                    fi

                    echo "" >> "$RESULTS_FILE"
                    }

                    # Check hosts file
                    check_hosts_file() {
                    echo "Hosts File Check:" >> "$RESULTS_FILE"
                    echo "----------------" >> "$RESULTS_FILE"

                    if [ -f "/etc/hosts" ]; then
                        # Count entries
                        entries=$(grep -v "^#" /etc/hosts | grep -v "^\s*$" | wc -l)
                        
                        echo "- Hosts file: Present ($entries entries)" >> "$RESULTS_FILE"
                        
                        # Check if hostname is in hosts file
                        if grep -q "$HOSTNAME" /etc/hosts; then
                        echo "- Hostname entry: Present" >> "$RESULTS_FILE"
                        log_success "Hostname entry found in hosts file"
                        else
                        echo "- Hostname entry: Missing" >> "$RESULTS_FILE"
                        log_warning "Hostname entry not found in hosts file"
                        ((WARNING_COUNT++))
                        fi
                    else
                        echo "- Hosts file: Not found" >> "$RESULTS_FILE"
                        log_error "Hosts file not found"
                        ((ERROR_COUNT++))
                    fi

                    echo "" >> "$RESULTS_FILE"
                    }

                    # Check /tmp directory permissions
                    check_tmp_permissions() {
                    echo "Temp Directory Check:" >> "$RESULTS_FILE"
                    echo "-------------------" >> "$RESULTS_FILE"

                    # Check if /tmp directory exists
                    if [ -d "/tmp" ]; then
                        echo "- /tmp directory: Exists" >> "$RESULTS_FILE"
                        log_success "/tmp directory exists"
                    else
                        echo "- /tmp directory: Missing" >> "$RESULTS_FILE"
                        log_error "/tmp directory missing"
                        ((ERROR_COUNT++))
                    fi

                    echo "" >> "$RESULTS_FILE"
                    }

                    check_aws_cli
                    check_backup_catalog
                    check_log_backup_config
                    check_backup_destinations
                    check_which_command
                    check_user_environment
                    check_host_profile
                    check_hosts_file
                    check_tmp_permissions

                    # Add recommendations if issues found
                    if [ -f "/etc/profile.d/zzz_which2.sh" ] || [ -f "/etc/profile.d/zzz_which2.csh" ]; then
                    echo "" >> "$RESULTS_FILE"
                    echo "Recommendations:" >> "$RESULTS_FILE"
                    echo "1. Install systemd-container: dnf install -y systemd-container" >> "$RESULTS_FILE"
                    echo "2. Restart HANA services or reboot the host" >> "$RESULTS_FILE"
                    fi

                    echo "Summary:" >> "$RESULTS_FILE"
                    echo "--------" >> "$RESULTS_FILE"
                    echo "Total Errors: $ERROR_COUNT" >> "$RESULTS_FILE"
                    echo "Total Warnings: $WARNING_COUNT" >> "$RESULTS_FILE"
                    echo "Missing Elements: ${MISSING_COUNT:-0}" >> "$RESULTS_FILE"

                    if [ $ERROR_COUNT -gt 0 ]; then
                        log_error "Backup configuration check failed with $ERROR_COUNT errors"
                        exit 1
                    elif [ $WARNING_COUNT -gt 0 ]; then
                        log_warning "Backup configuration check completed with $WARNING_COUNT warnings"
                        exit 0
                    else
                        log_success "Backup configuration check completed successfully"
                        exit 0
                    fi   

          - name: InvokePart4
            action: aws:executeAutomation
            isEnd: true
            onFailure: Abort
            inputs:
              DocumentName: !Sub 'SAPBackupPreCheck-${AWS::StackName}-${SID}-Part4' 
              RuntimeParameters:
                InstanceId: '{{ InstanceId }}'
                RunHSIScript: '{{ RunHSIScript }}'
                SID: '{{ SID }}'
                Timestamp: '{{ Timestamp }}'
                S3BucketForLogs: '{{ S3BucketForLogs }}'
                S3UploaderLink: '{{ S3UploaderLink }}'
                HANASupportInfoBucket: '{{ HANASupportInfoBucket }}'
                HANASupportInfoPath: '{{ HANASupportInfoPath }}'
                HANASupportInfoS3Key: '{{ HANASupportInfoS3Key }}'
                SecretArn: '{{ SecretArn }}'

  SAPBackupPreCheckPart4:
    Type: AWS::SSM::Document
    Properties:
      DocumentType: Automation
      Name: !Sub 'SAPBackupPreCheck-${AWS::StackName}-${SID}-Part4'
      Content:
        schemaVersion: '0.3'
        description: AWS Backup SAP HANA Pre-Check Automation (Part 4)
        parameters:
          InstanceId:
            type: String
            description: EC2 instance ID running SAP HANA
          RunHSIScript:
            type: String
            description: Would you like to use the HANA Support Info tool? (yes/no)
            allowedValues:
              - 'yes'
              - 'no'
          SID:
            type: String
            description: SAP HANA system ID
          S3BucketForLogs:
            type: String
            description: S3 bucket for logs (optional)
            default: ''
          S3UploaderLink:
            type: String
            description: AWS Support upload link (optional)
            default: ''
          Timestamp:
            type: String
            default: '{{ automation:EXECUTION_ID }}'
          SecretArn:
            type: String
            description: ARN of secret in Secrets Manager
          HANASupportInfoBucket:
            type: String
            description: S3 bucket containing HANASupportInfo.sh script (optional)
            default: ''
          HANASupportInfoPath:
            type: String
            description: File path where HANASupportInfo.sh script is located or should be downloaded to
            default: /tmp/HANASupportInfo.sh
          HANASupportInfoS3Key:
            type: String
            description: Object key (path + filename) of the script within the S3 bucket
            default: HANASupportInfo.sh
        mainSteps:
          - name: CheckTenantBackupCapability
            action: aws:runCommand
            nextStep: CheckBackintAgent
            onFailure: step:CheckBackintAgent
            inputs:
              DocumentName: AWS-RunShellScript
              InstanceIds: ['{{ InstanceId }}']
              Parameters:
                commands:
                  - |
                    #!/bin/bash
                    source /tmp/hana_health/env_vars.sh
                    setup_log_files "tenant_backup_check"
                    log "Starting tenant database backup capability check"

                    echo "Tenant Database Backup Capability Check" > "$RESULTS_FILE"
                    echo "======================================" >> "$RESULTS_FILE"

                    ERROR_COUNT=0
                    WARNING_COUNT=0

                    # Ensure we have AWS credentials for Secrets Manager
                    retrieve_hana_credentials() {
                      log "Retrieving HANA credentials from Secrets Manager"
                      echo -e "\nCredentials Status:" >> "$RESULTS_FILE"
                      
                      if ! command -v aws &>/dev/null; then
                        log_error "AWS CLI not found - cannot retrieve credentials from Secrets Manager"
                        echo "✗ ERROR: AWS CLI not installed." >> "$RESULTS_FILE"
                        return 1
                      fi
                      
                      # AWS CLI is available, try to get the secret
                      SecretArn="{{ SecretArn }}"
                      log "Retrieving HANA credentials from Secrets Manager ARN=$SecretArn"
                      
                      # Try to get the full secret first to avoid multiple calls
                      SECRET_JSON=$(aws secretsmanager get-secret-value \
                        --secret-id "$SecretArn" \
                        --query "SecretString" \
                        --output text 2>/tmp/hana_health/secret_error.log)
                      
                      if [ $? -ne 0 ] || [ -z "$SECRET_JSON" ]; then
                        log_error "Failed to get secret value"
                        if [ -f /tmp/hana_health/secret_error.log ]; then
                          log "Error details: $(cat /tmp/hana_health/secret_error.log)"
                        fi
                        echo "✗ ERROR: Cannot retrieve HANA credentials." >> "$RESULTS_FILE"
                        return 1
                      fi
                      
                      # Extract username and password
                      HANA_USERNAME=$(echo "$SECRET_JSON" | grep -o '"username":"[^"]*' | grep -o '[^"]*$')
                      HANA_PASSWORD=$(echo "$SECRET_JSON" | grep -o '"password":"[^"]*' | grep -o '[^"]*$')
                      
                      if [ -z "$HANA_USERNAME" ] || [ -z "$HANA_PASSWORD" ]; then
                        log_error "Failed to parse credentials from secret JSON"
                        echo "✗ ERROR: Bad secret JSON format." >> "$RESULTS_FILE"
                        return 1
                      fi

                      export HANA_USERNAME HANA_PASSWORD
                      log_success "HANA credentials retrieved"
                      echo "✓ Successfully retrieved HANA credentials for user $HANA_USERNAME" >> "$RESULTS_FILE"
                      return 0
                    }
                    # Get tenant databases from filesystem
                    get_tenant_databases() {
                      log "Identifying tenant databases from filesystem"
                      echo -e "\nTenant Database Detection:" >> "$RESULTS_FILE"
                      
                      # Determine global configuration path based on SID and instance number
                      local global_config_path="/usr/sap/${SID}/SYS/global/hdb/custom/config"
                      if [ ! -d "$global_config_path" ]; then
                        global_config_path="/hana/shared/${SID}/global/hdb/custom/config"
                      fi
                      
                      if [ ! -d "$global_config_path" ]; then
                        log_error "Could not find global configuration directory"
                        echo "✗ Could not find global configuration directory at expected locations" >> "$RESULTS_FILE"
                        return 1
                      fi
                      
                      log "Using global configuration path: $global_config_path"
                      echo "- Using configuration path: $global_config_path" >> "$RESULTS_FILE"
                      
                      # Check if it's a multitenant database container system
                      if grep -q multidb "$global_config_path/global.ini" 2>/dev/null; then
                        local is_mdc="true"
                      else
                        local is_mdc="false"
                      fi
                      
                      if [ "$is_mdc" == "true" ] && [ -d "$global_config_path" ]; then
                        # Initialize tenant array and list
                        local tenant_array=()
                        
                        # Find tenant directories
                        while IFS= read -r line; do
                          tenant_array+=("$line")
                        done < <(find "$global_config_path" -maxdepth 1 -type d -name "DB_*" ! -name "DB_*_*" | awk -F"DB_" '{ print $2 }')
                        
                        # Convert array to comma-separated list
                        TENANT_LIST=$(printf ",%s" "${tenant_array[@]}")
                        TENANT_LIST=${TENANT_LIST:1} # Remove leading comma
                        
                        if [ -n "$TENANT_LIST" ]; then
                          log_success "Found tenant databases: $TENANT_LIST"
                          echo "✓ Found tenant databases: $TENANT_LIST" >> "$RESULTS_FILE"
                          export TENANT_LIST
                          return 0
                        else
                          log_warning "No tenant databases found in configuration directory"
                          echo "⚠ No tenant databases found in configuration directory" >> "$RESULTS_FILE"
                          echo "  This could indicate a single-container HANA system" >> "$RESULTS_FILE"
                          export TENANT_LIST=""
                          return 2
                        fi
                      else
                        log_warning "System does not appear to be a multitenant database container (MDC) system"
                        echo "⚠ System does not appear to be a multitenant database container system" >> "$RESULTS_FILE"
                        echo "  This is likely a single-container HANA system" >> "$RESULTS_FILE"
                        export TENANT_LIST=""
                        return 2
                      fi
                    }
                    # Step 1: Check if cross-database access is enabled
                    check_cross_db_access() {
                        log "Checking if cross-database access is enabled"
                        echo -e "\nCross-Database Access Status:" >> "$RESULTS_FILE"
                        
                        local cross_db_query="SELECT VALUE FROM SYS.M_INIFILE_CONTENTS 
                                            WHERE FILE_NAME = 'global.ini' 
                                            AND SECTION = 'cross_database_access' 
                                            AND KEY = 'enabled'"
                        
                        local result=$(su - $SIDADM -c "hdbsql -n localhost -i $INSTANCE_NUM -d SYSTEMDB -u $HANA_USERNAME -p $HANA_PASSWORD -j -A \"$cross_db_query\"" 2>/dev/null)
                        local exit_code=$?
                        
                        if [ $exit_code -ne 0 ]; then
                            log_error "Failed to query cross-database access status"
                            echo "  ✗ Failed to query cross-database access configuration" >> "$RESULTS_FILE"
                            return 1
                        fi
                        
                        local enabled=$(echo "$result" | grep -v "VALUE" | grep -v "rows selected" | tr -d '\r' | tr -d '\n')
                        
                        if [ "$enabled" = "true" ]; then
                            log_success "Cross-database access is enabled"
                            echo "  ✓ Cross-database access is enabled" >> "$RESULTS_FILE"
                            return 0
                        else
                            log_warning "Cross-database access is not enabled"
                            echo "  ⚠ Cross-database access is not enabled, will attempt to enable it temporarily" >> "$RESULTS_FILE"
                            # Attempt to enable cross-database access temporarily for our check
                            enable_cross_db_access
                            return $?
                        fi
                    }

                    # Step 2: Enable cross-database access if needed
                    enable_cross_db_access() {
                        log "Attempting to enable cross-database access temporarily"
                        
                        local enable_query="ALTER SYSTEM ALTER CONFIGURATION ('global.ini', 'SYSTEM') SET ('cross_database_access', 'enabled')='true' WITH RECONFIGURE"
                        
                        local result=$(su - $SIDADM -c "hdbsql -n localhost -i $INSTANCE_NUM -d SYSTEMDB -u $HANA_USERNAME -p $HANA_PASSWORD -j \"$enable_query\"" 2>/dev/null)
                        local exit_code=$?
                        
                        if [ $exit_code -ne 0 ]; then
                            log_error "Failed to enable cross-database access (requires INIFILE ADMIN privilege)"
                            echo "  ✗ Failed to enable cross-database access - user $HANA_USERNAME may need INIFILE ADMIN privilege" >> "$RESULTS_FILE"
                            echo "    Try granting the privilege with: GRANT INIFILE ADMIN TO $HANA_USERNAME WITH ADMIN OPTION;" >> "$RESULTS_FILE"
                            ((ERROR_COUNT++))
                            return 1
                        else
                            log_success "Successfully enabled cross-database access"
                            echo "  ✓ Temporarily enabled cross-database access" >> "$RESULTS_FILE"
                            
                            # Configure mappings for each tenant
                            configure_tenant_targets
                            return $?
                        fi
                    }

                    # Step 3: Configure tenant database targets
                    configure_tenant_targets() {
                        log "Configuring tenant database targets for cross-database access"
                        
                        if [ -z "$TENANT_LIST" ]; then
                            log_warning "No tenant databases found to configure for cross-database access"
                            echo "  ⚠ No tenant databases found to configure for cross-database access" >> "$RESULTS_FILE"
                            return 0
                        fi
                        
                        echo -e "\nConfiguring cross-database access for tenant databases:" >> "$RESULTS_FILE"
                        echo "  - Found databases: $TENANT_LIST" >> "$RESULTS_FILE"
                        
                        success_count=0
                        total_count=0
                        
                        # Process comma-separated list of tenants
                        IFS=',' read -ra TENANT_ARRAY <<< "$TENANT_LIST"
                        for db in "${TENANT_ARRAY[@]}"; do
                            if [ -n "$db" ]; then
                                ((total_count++))
                                # Configure cross-database access from SYSTEMDB to this tenant
                                local config_query="ALTER SYSTEM ALTER CONFIGURATION ('global.ini', 'SYSTEM') SET ('cross_database_access', 'targets_for_SYSTEMDB')='$db' WITH RECONFIGURE"
                                
                                local result=$(su - $SIDADM -c "hdbsql -n localhost -i $INSTANCE_NUM -d SYSTEMDB -u $HANA_USERNAME -p $HANA_PASSWORD -j \"$config_query\"" 2>/dev/null)
                                local exit_code=$?
                                
                                if [ $exit_code -ne 0 ]; then
                                    log_error "Failed to configure cross-database access for $db"
                                    echo "  ✗ Failed to configure access to $db" >> "$RESULTS_FILE"
                                else
                                    log_success "Successfully configured cross-database access for $db"
                                    echo "  ✓ Configured access to $db" >> "$RESULTS_FILE"
                                    ((success_count++))
                                fi
                            fi
                        done
                        
                        if [ $total_count -eq 0 ]; then
                            log_warning "No tenant databases to configure"
                            echo "  ⚠ No tenant databases to configure" >> "$RESULTS_FILE"
                            return 0
                        elif [ $success_count -eq 0 ]; then
                            log_error "Failed to configure any tenant databases for cross-database access"
                            echo "  ✗ Could not configure any tenant databases for access" >> "$RESULTS_FILE"
                            return 1
                        elif [ $success_count -lt $total_count ]; then
                            log_warning "Only configured $success_count out of $total_count tenant databases"
                            echo "  ⚠ Only configured $success_count out of $total_count tenant databases" >> "$RESULTS_FILE"
                            ((WARNING_COUNT++))
                        else
                            log_success "Successfully configured all $total_count tenant databases"
                            echo "  ✓ Successfully configured all $total_count tenant databases" >> "$RESULTS_FILE"
                        fi
                        
                        return 0
                    }
                    # Check and create remote identities for cross-database access
                    setup_remote_identities() {
                        log "Setting up remote identities for cross-database access"
                        echo -e "\nRemote Identity Setup:" >> "$RESULTS_FILE"
                        
                        if [ -z "$TENANT_LIST" ]; then
                            log_warning "No tenant databases found to configure remote identities"
                            echo "  ⚠ No tenant databases found to configure remote identities" >> "$RESULTS_FILE"
                            return 2
                        fi
                        
                        # Track success
                        local success_count=0
                        local total_count=0
                        
                        # Process comma-separated list of tenants
                        IFS=',' read -ra TENANT_ARRAY <<< "$TENANT_LIST"
                        for db in "${TENANT_ARRAY[@]}"; do
                            if [ -n "$db" ]; then
                                ((total_count++))
                                
                                # First check if remote identity already exists
                                local check_query="SELECT COUNT(*) FROM SYS.REMOTE_IDENTITIES 
                                                  WHERE SOURCE_DATABASE_NAME = 'SYSTEMDB' 
                                                  AND TARGET_DATABASE_NAME = '$db' 
                                                  AND SOURCE_USER_NAME = '$HANA_USERNAME'"
                                                  
                                local result=$(su - $SIDADM -c "hdbsql -n localhost -i $INSTANCE_NUM -d SYSTEMDB -u $HANA_USERNAME -p $HANA_PASSWORD -j -A \"$check_query\"" 2>/dev/null)
                                local exit_code=$?
                                
                                if [ $exit_code -ne 0 ]; then
                                    log_error "Failed to check remote identity for $db"
                                    echo "  ✗ Failed to check remote identity for $db" >> "$RESULTS_FILE"
                                    continue
                                fi
                                
                                # Extract count and ensure it's a valid number
                                local count=$(echo "$result" | grep -v "COUNT" | grep -v "rows selected" | tr -d '\r' | tr -d '\n')
                                
                                # Ensure count is a number, default to 0 if it's not
                                if ! [[ "$count" =~ ^[0-9]+$ ]]; then
                                    count=0
                                fi
                                
                                if [ "$count" -gt 0 ]; then
                                    log_success "Remote identity for $HANA_USERNAME to access $db already exists"
                                    echo "  ✓ Remote identity mapping exists for $db" >> "$RESULTS_FILE"
                                    ((success_count++))
                                else
                                    # Create remote identity mapping
                                    log_warning "Remote identity for $HANA_USERNAME to access $db does not exist, creating it"
                                    echo "  ⚠ Remote identity mapping does not exist for $db, attempting to create" >> "$RESULTS_FILE"
                                    
                                    # For the remote identity to work, user must exist in both databases with same name
                                    # First check if user exists in tenant
                                    local tenant_user_check=$(su - $SIDADM -c "hdbsql -n localhost -i $INSTANCE_NUM -d $db -u $HANA_USERNAME -p $HANA_PASSWORD -j -A \"SELECT CURRENT_USER FROM DUMMY\"" 2>/dev/null)
                                    local tenant_user_code=$?
                                    
                                    if [ $tenant_user_code -ne 0 ]; then
                                        log_error "Cannot verify user existence in $db, remote identity creation will fail"
                                        echo "  ✗ User $HANA_USERNAME does not exist in tenant database $db" >> "$RESULTS_FILE"
                                        echo "    You must first create the user in the tenant database:" >> "$RESULTS_FILE"
                                        echo "    CREATE USER $HANA_USERNAME PASSWORD \"<password>\";" >> "$RESULTS_FILE"
                                        echo "    GRANT BACKUP OPERATOR, BACKUP ADMIN, CATALOG READ TO $HANA_USERNAME;" >> "$RESULTS_FILE"
                                        continue
                                    fi
                                    
                                    # Create the remote identity mapping
                                    local create_query="CREATE REMOTE IDENTITY $HANA_USERNAME FOR USER $HANA_USERNAME AT DATABASE $db"
                                    local create_result=$(su - $SIDADM -c "hdbsql -n localhost -i $INSTANCE_NUM -d SYSTEMDB -u $HANA_USERNAME -p $HANA_PASSWORD -j \"$create_query\"" 2>/dev/null)
                                    local create_code=$?
                                    
                                    if [ $create_code -ne 0 ]; then
                                        log_error "Failed to create remote identity for $db"
                                        echo "  ✗ Failed to create remote identity for $db" >> "$RESULTS_FILE"
                                        echo "    Either user lacks privileges or user does not exist in tenant database" >> "$RESULTS_FILE"
                                    else
                                        log_success "Successfully created remote identity for $HANA_USERNAME to access $db"
                                        echo "  ✓ Created remote identity mapping for $db" >> "$RESULTS_FILE"
                                        ((success_count++))
                                    fi
                                fi
                            fi
                        done
                        
                        if [ $success_count -eq 0 ]; then
                            log_error "Could not configure any remote identities"
                            echo -e "\n✗ Could not configure any remote identities" >> "$RESULTS_FILE"
                            return 1
                        elif [ $success_count -lt $total_count ]; then
                            log_warning "Only configured $success_count out of $total_count remote identities"
                            echo -e "\n⚠ Only configured $success_count out of $total_count remote identities" >> "$RESULTS_FILE"
                            return 2
                        else
                            log_success "Successfully configured all $total_count remote identities"
                            echo -e "\n✓ Successfully configured all $total_count remote identities" >> "$RESULTS_FILE"
                            return 0
                        fi
                    }

                    # Check backup capability for each tenant using cross-database access
                    check_backup_capability() {
                        log "Checking backup capability for tenant databases through cross-database access"
                        echo -e "\nBackup Capability Check Results (Cross-DB Method):" >> "$RESULTS_FILE"
                        
                        if [ -z "$TENANT_LIST" ]; then
                            log_warning "No tenant databases found to check"
                            echo "  ⚠ No tenant databases found to check" >> "$RESULTS_FILE"
                            ((WARNING_COUNT++))
                            return 1
                        fi
                        
                        # Track successes and total checks
                        local success_count=0
                        local check_count=0
                        
                        IFS=',' read -ra TENANT_ARRAY <<< "$TENANT_LIST"
                        for db in "${TENANT_ARRAY[@]}"; do
                            if [ -n "$db" ]; then
                                ((check_count++))
                                echo -e "\nDatabase: $db" >> "$RESULTS_FILE"
                                
                                # Method 1: Try to access backup catalog through cross-database access
                                local backup_check_query="SELECT COUNT(*) FROM \"$db\".SYS.M_BACKUP_CATALOG"
                                
                                local result=$(su - $SIDADM -c "hdbsql -n localhost -i $INSTANCE_NUM -d SYSTEMDB -u $HANA_USERNAME -p $HANA_PASSWORD -j -A \"$backup_check_query\"" 2>/dev/null)
                                local exit_code=$?
                                
                                if [ $exit_code -eq 0 ]; then
                                    log_success "Successfully accessed backup catalog in $db"
                                    echo "  ✓ Can access backup catalog (cross-DB access works)" >> "$RESULTS_FILE"
                                    ((success_count++))
                                    
                                    # Method 2: Try to access recent backups
                                    local recent_backups_query="SELECT TOP 5 BACKUP_ID, BACKUP_TYPE, STATE_NAME, 
                                                             to_varchar(SYS_START_TIME, 'YYYY-MM-DD HH24:MI:SS') as START_TIME, 
                                                             to_varchar(SYS_END_TIME, 'YYYY-MM-DD HH24:MI:SS') as END_TIME 
                                                             FROM \"$db\".SYS.M_BACKUP_CATALOG 
                                                             WHERE STATE_NAME = 'successful' 
                                                             ORDER BY SYS_END_TIME DESC"
                                    
                                    local backup_result=$(su - $SIDADM -c "hdbsql -n localhost -i $INSTANCE_NUM -d SYSTEMDB -u $HANA_USERNAME -p $HANA_PASSWORD -j -A \"$recent_backups_query\"" 2>/dev/null)
                                    
                                    if [ -n "$backup_result" ] && ! echo "$backup_result" | grep -q "0 rows selected"; then
                                        log_success "Found successful backups for $db"
                                        echo "  ✓ Recent successful backups found" >> "$RESULTS_FILE"
                                        echo "    Last backups:" >> "$RESULTS_FILE"
                                        echo "$backup_result" | grep -v "rows selected" | sed 's/^/      /' >> "$RESULTS_FILE"
                                    else
                                        log_warning "No recent successful backups found for $db"
                                        echo "  ⚠ No recent successful backups found" >> "$RESULTS_FILE"
                                        ((WARNING_COUNT++))
                                    fi
                                    
                                    # Method 3: Check backup configuration
                                    local backup_config_query="SELECT TOP 5 KEY, VALUE FROM \"$db\".SYS.M_INIFILE_CONTENTS 
                                                           WHERE FILE_NAME = 'global.ini' 
                                                           AND SECTION = 'backup' 
                                                           AND KEY IN ('catalog_backup_parameter_file', 'data_backup_parameter_file')"
                                    
                                    local config_result=$(su - $SIDADM -c "hdbsql -n localhost -i $INSTANCE_NUM -d SYSTEMDB -u $HANA_USERNAME -p $HANA_PASSWORD -j -A \"$backup_config_query\"" 2>/dev/null)
                                    
                                    if [ -n "$config_result" ] && ! echo "$config_result" | grep -q "0 rows selected"; then
                                        log_success "Backup configuration exists for $db"
                                        echo "  ✓ Backup configuration exists" >> "$RESULTS_FILE"
                                        echo "    Configuration:" >> "$RESULTS_FILE"
                                        echo "$config_result" | grep -v "rows selected" | sed 's/^/      /' >> "$RESULTS_FILE"
                                    else
                                        log_warning "No specific backup configuration found for $db"
                                        echo "  ⚠ No specific backup configuration parameters found" >> "$RESULTS_FILE"
                                        ((WARNING_COUNT++))
                                    fi
                                    
                                else
                                    log_error "Failed to access backup catalog in $db through cross-database access"
                                    echo "  ✗ Cannot access backup catalog (cross-DB access issue)" >> "$RESULTS_FILE"
                                    ((ERROR_COUNT++))
                                    
                                    # Try direct connection as fallback
                                    local direct_result=$(su - $SIDADM -c "hdbsql -n localhost -i $INSTANCE_NUM -d $db -u $HANA_USERNAME -p $HANA_PASSWORD -j -A \"SELECT COUNT(*) FROM SYS.M_BACKUP_CATALOG\"" 2>/dev/null)
                                    local direct_code=$?
                                    
                                    if [ $direct_code -eq 0 ]; then
                                        log_success "Successfully accessed backup catalog directly in $db"
                                        echo "  ✓ Can access backup catalog directly (credentials work)" >> "$RESULTS_FILE"
                                        ((success_count++))
                                        
                                        # Check user privileges in tenant
                                        local priv_query="SELECT PRIVILEGE FROM SYS.EFFECTIVE_PRIVILEGES WHERE GRANTEE = CURRENT_USER AND PRIVILEGE LIKE '%BACKUP%'"
                                        local priv_result=$(su - $SIDADM -c "hdbsql -n localhost -i $INSTANCE_NUM -d $db -u $HANA_USERNAME -p $HANA_PASSWORD -j -A \"$priv_query\"" 2>/dev/null)
                                        
                                        if [ -n "$priv_result" ] && ! echo "$priv_result" | grep -q "0 rows selected"; then
                                            log_success "User has backup privileges in $db"
                                            echo "  ✓ User $HANA_USERNAME has backup privileges:" >> "$RESULTS_FILE"
                                            echo "$priv_result" | grep -v "rows selected" | sed 's/^/      /' >> "$RESULTS_FILE"
                                        else
                                            log_error "User does not have backup privileges in $db"
                                            echo "  ✗ User $HANA_USERNAME lacks backup privileges" >> "$RESULTS_FILE"
                                            echo "    Please grant required privileges with:" >> "$RESULTS_FILE"
                                            echo "      GRANT BACKUP OPERATOR, BACKUP ADMIN, CATALOG READ TO $HANA_USERNAME;" >> "$RESULTS_FILE"
                                            ((ERROR_COUNT++))
                                        fi
                                    else
                                        log_error "Cannot access backup catalog in $db through any method"
                                        echo "  ✗ Cannot access backup catalog through any method" >> "$RESULTS_FILE"
                                        echo "    Likely causes:" >> "$RESULTS_FILE"
                                        echo "    - User $HANA_USERNAME doesn't exist in tenant database" >> "$RESULTS_FILE"
                                        echo "    - User lacks required privileges" >> "$RESULTS_FILE"
                                        echo "    - Authentication issues" >> "$RESULTS_FILE"
                                        ((ERROR_COUNT++))
                                    fi
                                fi
                            fi
                        done
                        
                        if [ $success_count -eq 0 ]; then
                            log_error "Could not access backup information for any tenant databases"
                            echo -e "\n✗ Could not access backup information for any tenant databases" >> "$RESULTS_FILE"
                            return 1
                        elif [ $success_count -lt $check_count ]; then
                            log_warning "Could only access backup information for $success_count out of $check_count tenant databases"
                            echo -e "\n⚠ Could only access backup information for $success_count out of $check_count tenant databases" >> "$RESULTS_FILE"
                            ((WARNING_COUNT++))
                            return 2
                        else
                            log_success "Successfully accessed backup information for all $check_count tenant databases"
                            echo -e "\n✓ Successfully accessed backup information for all $check_count tenant databases" >> "$RESULTS_FILE"
                            return 0
                        fi
                    }
                    # Check backup capability using direct connection to each tenant
                    check_direct_backup_capability() {
                        log "Checking backup capability through direct backup catalog access"
                        echo -e "\nDirectly Checking Backup Capability:" >> "$RESULTS_FILE"
                        
                        if [ -z "$TENANT_LIST" ]; then
                            log_warning "No tenant databases found to check"
                            echo "  ⚠ No tenant databases found to check" >> "$RESULTS_FILE"
                            return 2
                        fi
                        
                        # Check each tenant database directly
                        local success_count=0
                        local total_count=0
                        
                        IFS=',' read -ra TENANT_ARRAY <<< "$TENANT_LIST"
                        for db in "${TENANT_ARRAY[@]}"; do
                            if [ -n "$db" ]; then
                                ((total_count++))
                                echo -e "\nDatabase: $db" >> "$RESULTS_FILE"

                                # Try direct connection to tenant - don't check user existence first
                                local direct_result=$(su - $SIDADM -c "hdbsql -n localhost -i $INSTANCE_NUM -d $db -u $HANA_USERNAME -p $HANA_PASSWORD -j -A \"SELECT COUNT(*) FROM SYS.M_BACKUP_CATALOG\"" 2>/dev/null)
                                local direct_code=$?

                                if [ $direct_code -eq 0 ]; then
                                    log_success "Successfully accessed backup catalog directly in $db"
                                    echo "  ✓ Can access backup catalog directly (credentials work)" >> "$RESULTS_FILE"
                                    ((success_count++))
                                    
                                    # Check for recent backups
                                    local backup_query="SELECT TOP 3 BACKUP_ID, BACKUP_TYPE, STATE_NAME, 
                                                    to_varchar(SYS_START_TIME, 'YYYY-MM-DD HH24:MI:SS') as START_TIME 
                                                    FROM SYS.M_BACKUP_CATALOG 
                                                    WHERE STATE_NAME = 'successful' 
                                                    ORDER BY SYS_START_TIME DESC"
                                    local backup_result=$(su - $SIDADM -c "hdbsql -n localhost -i $INSTANCE_NUM -d $db -u $HANA_USERNAME -p $HANA_PASSWORD -j -A \"$backup_query\"" 2>/dev/null)
                                    
                                    if [ -n "$backup_result" ] && ! echo "$backup_result" | grep -q "0 rows selected"; then
                                        log_success "Found successful backups for $db"
                                        echo "  ✓ Recent successful backups found" >> "$RESULTS_FILE"
                                        echo "    Last backups:" >> "$RESULTS_FILE"
                                        echo "$backup_result" | grep -v "rows selected" | sed 's/^/      /' >> "$RESULTS_FILE"
                                    else
                                        log_warning "No recent successful backups found for $db"
                                        echo "  ⚠ No recent successful backups found" >> "$RESULTS_FILE"
                                        ((WARNING_COUNT++))
                                    fi
                                else
                                    log_error "Cannot access backup catalog in $db"
                                    echo "  ✗ Cannot access backup catalog in tenant" >> "$RESULTS_FILE"
                                    echo "    Likely causes:" >> "$RESULTS_FILE"
                                    echo "    - User $HANA_USERNAME doesn't exist in tenant database" >> "$RESULTS_FILE"
                                    echo "    - User lacks required privileges" >> "$RESULTS_FILE"
                                    echo "    - Authentication issues" >> "$RESULTS_FILE"
                                    ((ERROR_COUNT++))
                                fi
                            fi
                        done
                        
                        if [ $success_count -eq 0 ]; then
                            log_error "Could not access backup information for any tenant databases"
                            echo -e "\n✗ Could not access backup information for any tenant databases" >> "$RESULTS_FILE"
                            return 1
                        elif [ $success_count -lt $total_count ]; then
                            log_warning "Could only access backup information for $success_count out of $total_count tenant databases"
                            echo -e "\n⚠ Could only access backup information for $success_count out of $total_count tenant databases" >> "$RESULTS_FILE"
                            ((WARNING_COUNT++))
                            return 2
                        else
                            log_success "Successfully accessed backup information for all $total_count tenant databases"
                            echo -e "\n✓ Successfully accessed backup information for all $total_count tenant databases" >> "$RESULTS_FILE"
                            return 0
                        fi
                    }

                    # Clean up any temporary configurations
                    cleanup_cross_db() {
                        # Only run if we enabled cross-DB access in this script
                        # This is just a placeholder for now
                        log "Cleanup phase completed"
                        return 0
                    } # Added missing closing brace here

                    # Main execution
                    log "Starting tenant backup capability check workflow"

                    # Step 0: Get credentials from Secrets Manager
                    retrieve_hana_credentials
                    cred_status=$?
                    if [ $cred_status -ne 0 ]; then
                        log_error "Failed to retrieve HANA credentials, cannot proceed"
                        echo "✗ Cannot proceed with tenant backup checks due to credential retrieval failure" >> "$RESULTS_FILE"
                        echo -e "\nSummary:" >> "$RESULTS_FILE"
                        echo "Errors: $ERROR_COUNT" >> "$RESULTS_FILE"
                        echo "Warnings: $WARNING_COUNT" >> "$RESULTS_FILE"
                        exit 1
                    fi

                    # Step 1: Get tenant databases from filesystem
                    get_tenant_databases
                    get_tenants_status=$?

                    if [ $get_tenants_status -eq 1 ]; then
                        log_error "Failed to locate tenant databases"
                        echo "✗ Failed to locate tenant databases on filesystem" >> "$RESULTS_FILE"
                        echo -e "\nSummary:" >> "$RESULTS_FILE"
                        echo "Errors: $ERROR_COUNT" >> "$RESULTS_FILE"
                        echo "Warnings: $WARNING_COUNT" >> "$RESULTS_FILE"
                        exit 1
                    fi

                    # First try direct access method (simpler approach)
                    log "Attempting direct backup capability check first"
                    check_direct_backup_capability
                    direct_status=$?

                    # Make sure direct_status is a valid number
                    if ! [[ "$direct_status" =~ ^[0-9]+$ ]]; then
                        direct_status=1  # Set to error if not a number
                    fi

                    # If direct method worked completely (returned 0), we're done
                    if [ "$direct_status" -eq 0 ]; then
                        log_success "Direct backup capability check was successful for all tenants"
                        echo -e "\nDirect backup capability check was successful for all tenants. No need for cross-database access." >> "$RESULTS_FILE"
                    # If direct method partially worked (returned 2), we had partial success but might want to try cross-DB
                    elif [ "$direct_status" -eq 2 ]; then
                        log_warning "Direct backup capability check was partially successful"
                        echo -e "\nDirect backup capability check was partially successful. Attempting cross-database access method as well." >> "$RESULTS_FILE"
                        
                        # Try cross-database method
                        check_cross_db_access
                        cross_db_status=$?
                        
                        # Make sure cross_db_status is a valid number
                        if ! [[ "$cross_db_status" =~ ^[0-9]+$ ]]; then
                            cross_db_status=1  # Set to error if not a number
                        fi
                        
                        if [ "$cross_db_status" -eq 0 ]; then
                            # Set up remote identities for cross-database access
                            setup_remote_identities
                            remote_status=$?
                            
                            # Make sure remote_status is a valid number
                            if ! [[ "$remote_status" =~ ^[0-9]+$ ]]; then
                                remote_status=1  # Set to error if not a number
                            fi
                            
                            if [ "$remote_status" -eq 0 ] || [ "$remote_status" -eq 2 ]; then
                                # We have at least some remote identities set up, try cross-db access
                                check_backup_capability
                            fi
                            
                            cleanup_cross_db
                        fi
                    # If direct method failed completely (returned 1), try cross-database access as fallback
                    else
                        log_warning "Direct backup capability check failed, trying cross-database access method"
                        echo -e "\nDirect backup capability check failed. Attempting cross-database access method as fallback." >> "$RESULTS_FILE"
                                            
                        # Try cross-database method 
                        check_cross_db_access
                        cross_db_status=$?
                        
                        # Make sure cross_db_status is a valid number
                        if ! [[ "$cross_db_status" =~ ^[0-9]+$ ]]; then
                            cross_db_status=1  # Set to error if not a number
                        fi
                        
                        if [ "$cross_db_status" -eq 0 ]; then
                            # Set up remote identities for cross-database access
                            setup_remote_identities
                            remote_status=$?
                            
                            # Make sure remote_status is a valid number
                            if ! [[ "$remote_status" =~ ^[0-9]+$ ]]; then
                                remote_status=1  # Set to error if not a number
                            fi
                            
                            if [ "$remote_status" -eq 0 ] || [ "$remote_status" -eq 2 ]; then
                                # We have at least some remote identities set up, try cross-db access
                                check_backup_capability
                            fi
                            
                            cleanup_cross_db
                        fi
                    fi

                    # Summary
                    echo -e "\nSummary:" >> "$RESULTS_FILE"
                    echo "Errors: $ERROR_COUNT" >> "$RESULTS_FILE"
                    echo "Warnings: $WARNING_COUNT" >> "$RESULTS_FILE"

                    if [ $ERROR_COUNT -gt 0 ]; then
                        log_error "Tenant backup capability check completed with $ERROR_COUNT errors and $WARNING_COUNT warnings"
                        echo -e "\nRecommendations:" >> "$RESULTS_FILE"
                        echo "- Check HANA user credentials and permissions" >> "$RESULTS_FILE"
                        echo "- Verify if cross-database access is correctly configured" >> "$RESULTS_FILE"
                        echo "- Check if recent backups have been completed successfully" >> "$RESULTS_FILE"
                        exit 1
                    elif [ $WARNING_COUNT -gt 0 ]; then
                        log_warning "Tenant backup capability check completed with $WARNING_COUNT warnings"
                        echo -e "\nRecommendations:" >> "$RESULTS_FILE"
                        echo "- Review backup configurations for completeness" >> "$RESULTS_FILE"
                        echo "- Verify backup schedule if no recent backups were found" >> "$RESULTS_FILE"
                        exit 0
                    else
                        log_success "Tenant backup capability check completed successfully"
                        echo -e "\nAll tenant databases appear to be correctly configured for backup" >> "$RESULTS_FILE"
                        exit 0
                    fi

          - name: CheckBackintAgent
            action: aws:runCommand
            nextStep: CheckLogFiles
            onFailure: step:CheckLogFiles
            inputs:
              DocumentName: AWS-RunShellScript
              InstanceIds: ['{{ InstanceId }}']
              Parameters:
                commands:
                  - |
                    #!/bin/bash
                    mkdir -p /tmp/hana_health
                    source /tmp/hana_health/env_vars.sh
                    setup_log_files "backint"

                    source /tmp/hana_health/env_vars.sh
                    [ -z "$SID" ] && { echo "ERROR: SID not found in environment variables" | tee -a "$LOG_FILE"; exit 1; }
                    SIDADM_USER="${SID,,}adm"

                    log() { echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" | tee -a "$LOG_FILE"; }

                    id "$SIDADM_USER" >/dev/null 2>&1 || { 
                      echo "ERROR: User $SIDADM_USER does not exist" | tee -a "$RESULTS_FILE" "$LOG_FILE"
                      exit 1
                    }

                    echo "AWS Backint Agent Installation Check:" > "$RESULTS_FILE"

                    # 1. Check AWS CLI configuration and version
                    echo -e "\nAWS CLI Configuration:" >> "$RESULTS_FILE"
                    if command -v aws >/dev/null 2>&1; then
                        AWS_VERSION=$(aws --version 2>&1)
                        echo "? AWS CLI: Installed - $AWS_VERSION" >> "$RESULTS_FILE"
                        log_success "AWS CLI is installed: $AWS_VERSION"
                        
                        # Check AWS CLI configuration
                        AWS_CONFIG=$(aws configure list 2>&1)
                        if echo "$AWS_CONFIG" | grep -q "iam-role"; then
                            echo "? AWS CLI credentials: Using IAM Role" >> "$RESULTS_FILE"
                            log_success "AWS CLI is using IAM Role for credentials"
                        else
                            echo "? AWS CLI credentials: $(echo "$AWS_CONFIG" | grep "access_key" | awk '{print $2}')" >> "$RESULTS_FILE"
                            log_warning "AWS CLI may not be using IAM Role for credentials"
                            ((WARNING_COUNT++))
                        fi
                    else
                        echo "? AWS CLI: Not installed" >> "$RESULTS_FILE"
                        log_error "AWS CLI is not installed"
                        ((ERROR_COUNT++))
                    fi

                    # 2. Check system time synchronization
                    echo -e "\nSystem Time Check:" >> "$RESULTS_FILE"
                    if command -v timedatectl >/dev/null 2>&1; then
                        TIME_STATUS=$(timedatectl status)
                        if echo "$TIME_STATUS" | grep -q "NTP service: active"; then
                            echo "? Time synchronization: Active" >> "$RESULTS_FILE"
                            echo "$(timedatectl | grep "System clock" | sed 's/^[ \t]*//')" >> "$RESULTS_FILE"
                            log_success "System time synchronization is active"
                        else
                            echo "? Time synchronization: Inactive" >> "$RESULTS_FILE"
                            echo "$(timedatectl | grep "System clock" | sed 's/^[ \t]*//')" >> "$RESULTS_FILE"
                            log_error "System time synchronization is not active"
                            ((ERROR_COUNT++))
                        fi
                        
                        # Check for time sync service
                        if systemctl is-active chronyd >/dev/null 2>&1; then
                            echo "? chrony service: Running" >> "$RESULTS_FILE"
                            log_success "chrony service is running"
                        elif systemctl is-active ntpd >/dev/null 2>&1; then
                            echo "? ntpd service: Running" >> "$RESULTS_FILE"
                            log_success "ntpd service is running"
                        else
                            echo "? Time sync service: Not found or not running" >> "$RESULTS_FILE"
                            log_error "No time sync service running"
                            ((ERROR_COUNT++))
                        fi
                    else
                        echo "? timedatectl: Not available" >> "$RESULTS_FILE"
                        log_warning "Cannot check time synchronization status"
                        ((WARNING_COUNT++))
                    fi

                    # 3. Directory Locations and Agent Status
                    echo -e "\nDirectory Locations and Agent Status:" >> "$RESULTS_FILE"
                    echo "Searching for aws-backint-agent and hdbconfig directories..." >> "$RESULTS_FILE"
                    dir_locations=$(/usr/bin/find / -type d -name 'aws-backint-agent' -o -name 'hdbconfig' 2>/dev/null)

                    BACKINT_DIR=""
                    HDBCONFIG_DIR=""
                    if [ -n "$dir_locations" ]; then
                        echo "$dir_locations" | while IFS= read -r dir; do
                            echo "? Found directory: $dir" >> "$RESULTS_FILE"
                            log_success "Found directory: $dir"
                            
                            # Store locations for later use
                            if [[ "$dir" == *"aws-backint-agent"* ]]; then
                                BACKINT_DIR="$dir"
                                echo "export BACKINT_AGENT_DIR=\"$dir\"" >> /tmp/hana_health/locations.sh
                            elif [[ "$dir" == *"hdbconfig"* ]]; then
                                HDBCONFIG_DIR="$dir"
                                echo "export HDBCONFIG_DIR=\"$dir\"" >> /tmp/hana_health/locations.sh
                            fi
                        done
                    else
                        echo "? No aws-backint-agent or hdbconfig directories found" >> "$RESULTS_FILE"
                        log_warning "Required directories not found"
                        ((WARNING_COUNT++))
                    fi

                    # 4. Check SSM Agent status
                    echo -e "\nChecking SSM Agent Status:" >> "$RESULTS_FILE"
                    ssm_status=$(sudo systemctl status amazon-ssm-agent 2>&1)
                    if echo "$ssm_status" | grep -q "Active: active (running)"; then
                        echo "? SSM Agent is running" >> "$RESULTS_FILE"
                        echo "$ssm_status" | grep -E "Active:|CGroup:" >> "$RESULTS_FILE"
                        log_success "SSM Agent is running"
                    else
                        echo "? SSM Agent is not running" >> "$RESULTS_FILE"
                        echo "$ssm_status" | grep -E "Active:|Failed:" >> "$RESULTS_FILE"
                        log_error "SSM Agent is not running"
                        ((ERROR_COUNT++))
                    fi

                    # 5. Check AWS Backint Agent binary
                    if [ -n "$BACKINT_DIR" ]; then
                        echo -e "\nAWS Backint Agent binary check:" >> "$RESULTS_FILE"
                        if [ -x "$BACKINT_DIR/aws-backint-agent" ]; then
                            echo "? AWS Backint Agent executable found" >> "$RESULTS_FILE"
                            version=$("$BACKINT_DIR/aws-backint-agent" version 2>/dev/null || "$BACKINT_DIR/aws-backint-agent" -v 2>/dev/null)
                            [ -n "$version" ] && echo "  Version: $version" >> "$RESULTS_FILE"
                            log_success "AWS Backint Agent executable found: $version"
                            AWS_BACKINT_FOUND=true
                        else
                            echo "? AWS Backint Agent executable not found or not executable" >> "$RESULTS_FILE"
                            log_warning "AWS Backint Agent executable issue"
                            ((WARNING_COUNT++))
                        fi
                        
                        # Check for AWS Backint launcher script
                        if [ -f "$BACKINT_DIR/aws-backint-agent-launcher.sh" ]; then
                            echo "? AWS Backint launcher script found" >> "$RESULTS_FILE"
                            
                            # Check for proxy settings in launcher script
                            if grep -q "proxy" "$BACKINT_DIR/aws-backint-agent-launcher.sh"; then
                                echo "  Proxy configuration present in launcher script" >> "$RESULTS_FILE"
                                
                                # Check for no_proxy configuration
                                if grep -q "no_proxy\|NO_PROXY" "$BACKINT_DIR/aws-backint-agent-launcher.sh"; then
                                    echo "  no_proxy configuration present in launcher script" >> "$RESULTS_FILE"
                                    log_success "Proxy settings with no_proxy configured in launcher script"
                                else
                                    echo "  WARNING: no_proxy configuration missing in launcher script" >> "$RESULTS_FILE"
                                    echo "  For proper IMDS access, add no_proxy=\"::1,localhost,127.0.0.1,169.254.169.254,fd00:ec2::254\"" >> "$RESULTS_FILE"
                                    log_warning "no_proxy configuration missing in launcher script"
                                    ((WARNING_COUNT++))
                                fi
                            else
                                echo "  No proxy configuration found in launcher script" >> "$RESULTS_FILE"
                            fi
                        else
                            echo "? AWS Backint launcher script not found" >> "$RESULTS_FILE"
                            log_warning "AWS Backint launcher script not found"
                            ((WARNING_COUNT++))
                        fi
                        
                        # Check for log file
                        if [ -f "$BACKINT_DIR/aws-backint-agent.log" ]; then
                            log_size=$(du -h "$BACKINT_DIR/aws-backint-agent.log" 2>/dev/null | cut -f1)
                            echo "? Log file exists (Size: $log_size)" >> "$RESULTS_FILE"
                            
                            # Check for recent errors in the log
                            if tail -n 100 "$BACKINT_DIR/aws-backint-agent.log" | grep -i "error\|failed\|exception" >/dev/null; then
                                echo "  WARNING: Recent errors found in Backint Agent log" >> "$RESULTS_FILE"
                                log_warning "Recent errors found in Backint Agent log"
                                ((WARNING_COUNT++))
                            else
                                echo "  No recent errors found in Backint Agent log" >> "$RESULTS_FILE"
                                log_success "No recent errors in Backint Agent log"
                            fi
                        else
                            echo "? Log file not found" >> "$RESULTS_FILE"
                            log_warning "AWS Backint Agent log not found"
                            ((WARNING_COUNT++))
                        fi
                    else
                        echo -e "\n? AWS Backint Agent directory not found" >> "$RESULTS_FILE"
                        log_warning "AWS Backint Agent directory not found"
                        ((WARNING_COUNT++))
                    fi

                    # 6. Check symbolic links
                    HANA_OPT_DIR="/usr/sap/$SID/SYS/global/hdb/opt"
                    echo -e "\nChecking symbolic links:" >> "$RESULTS_FILE"

                    # Check hdbbackint link
                    if [ -L "$HANA_OPT_DIR/hdbbackint" ]; then
                        link_target=$(readlink -f "$HANA_OPT_DIR/hdbbackint")
                        if [[ "$link_target" == *"aws-backint-agent"* ]]; then
                            echo "? hdbbackint symlink exists and points to AWS Backint Agent" >> "$RESULTS_FILE"
                            echo "  Target: $link_target" >> "$RESULTS_FILE"
                            log_success "hdbbackint properly linked to AWS Backint Agent"
                        else
                            echo "? hdbbackint symlink exists but points to: $link_target" >> "$RESULTS_FILE"
                            log_error "hdbbackint points to non-AWS agent"
                            ((ERROR_COUNT++))
                        fi
                    else
                        echo "? hdbbackint symlink not found" >> "$RESULTS_FILE"
                        log_error "Missing hdbbackint symlink"
                        ((ERROR_COUNT++))
                    fi

                    # Check config YAML link
                    if [ -L "$HANA_OPT_DIR/hdbconfig/aws-backint-agent-config.yaml" ]; then
                        config_target=$(readlink -f "$HANA_OPT_DIR/hdbconfig/aws-backint-agent-config.yaml")
                        echo "? Config YAML symlink exists: $config_target" >> "$RESULTS_FILE"
                        log_success "Config YAML symlink found"
                    else
                        echo "? Config YAML symlink not found" >> "$RESULTS_FILE"
                        log_error "Missing config YAML symlink"
                        ((ERROR_COUNT++))
                    fi

                    # 7. Check configuration files
                    echo -e "\nChecking configuration:" >> "$RESULTS_FILE"

                    CONFIG_FILES=(
                      "$HANA_OPT_DIR/hdbconfig/aws-backint-agent-config.yaml"
                      "$BACKINT_DIR/aws-backint-agent-config.yaml"
                    )

                    CONFIG_FOUND=false
                    AWS_BACKUP_MODE=false

                    for config in "${CONFIG_FILES[@]}"; do
                      if [ -f "$config" ]; then
                        echo "? Configuration file found: $config" >> "$RESULTS_FILE"
                        log_success "Found configuration file: $config"
                        CONFIG_FOUND=true
                        
                        if grep -q "BackintMode.*:.*AWSBackup" "$config" 2>/dev/null; then
                            echo "  ? Configured for AWS Backup" >> "$RESULTS_FILE"
                            log_success "AWS Backint agent is configured for AWS Backup"
                            AWS_BACKUP_MODE=true
                            break
                        fi
                      fi
                    done

                    if [ "$CONFIG_FOUND" = "false" ]; then
                      echo "? No configuration files found" >> "$RESULTS_FILE"
                      log_warning "No Backint configuration files found"
                      ((WARNING_COUNT++))
                    elif [ "$AWS_BACKUP_MODE" = "false" ]; then
                      echo "? AWS Backint Agent is not configured for AWS Backup" >> "$RESULTS_FILE"
                      log_warning "AWS Backint Agent is not configured for AWS Backup"
                      ((WARNING_COUNT++))
                    fi

                    # 8. Check global.ini parameters
                    echo -e "\nChecking global.ini parameters:" >> "$RESULTS_FILE"
                    GLOBAL_INI="/usr/sap/$SID/SYS/global/hdb/custom/config/global.ini"

                    if [ -f "$GLOBAL_INI" ]; then
                        parameters=(
                            "catalog_backup_parameter_file"
                            "data_backup_parameter_file"
                            "log_backup_parameter_file"
                            "catalog_backup_using_backint"
                            "log_backup_using_backint"
                            "data_backup_using_backint"
                        )
                        
                        for param in "${parameters[@]}"; do
                            value=$(grep -A 1 "\[backup\]" "$GLOBAL_INI" | grep "^$param =" | awk -F'=' '{print $2}' | tr -d ' ')
                            if [ -n "$value" ]; then
                                if [[ "$param" == *"using_backint" ]]; then
                                    if [ "$value" = "true" ]; then
                                        echo "? $param is enabled" >> "$RESULTS_FILE"
                                        log_success "$param is properly enabled"
                                    else
                                        echo "? $param is disabled" >> "$RESULTS_FILE"
                                        log_warning "$param is not enabled"
                                        ((WARNING_COUNT++))
                                    fi
                                else
                                    echo "? $param is configured: $value" >> "$RESULTS_FILE"
                                    log_success "$param is configured"
                                fi
                            else
                                echo "? $param not found" >> "$RESULTS_FILE"
                                log_warning "$param not configured"
                                ((WARNING_COUNT++))
                            fi
                        done
                        
                        # Check log mode
                        log_mode=$(grep -A 5 "\[persistence\]" "$GLOBAL_INI" | grep "log_mode" | awk -F'=' '{print $2}' | tr -d ' ')
                        if [ -z "$log_mode" ]; then
                            echo "? Log mode: Default (normal)" >> "$RESULTS_FILE"
                            log_success "Log mode not explicitly set, using default (normal)"
                        else
                            echo "? Log mode: $log_mode" >> "$RESULTS_FILE"
                            if [ "$log_mode" = "overwrite" ]; then
                                log_error "Log mode set to 'overwrite' - prevents log backups"
                                ((ERROR_COUNT++))
                            else
                                log_success "Log mode set to $log_mode"
                            fi
                        fi
                    else
                        echo "? global.ini not found" >> "$RESULTS_FILE"
                        log_error "global.ini not found"
                        ((ERROR_COUNT++))
                    fi

                    # 9. Test AWS Backup connectivity
                    echo -e "\nTesting AWS Backup connectivity:" >> "$RESULTS_FILE"

                    # Check VPC endpoint for backup service
                    echo "? Checking AWS Backup VPC endpoint connectivity" >> "$RESULTS_FILE"

                    # --- Improved Region Detection ---
                    aws_region=""
                    # Try IMDSv2 first
                    TOKEN=$(curl -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 60" 2>/dev/null)
                    if [ "$TOKEN" != "" ]; then
                        aws_region=$(curl -H "X-aws-ec2-metadata-token: $TOKEN" -s http://169.254.169.254/latest/meta-data/placement/region 2>/dev/null)
                        log "Region detected via IMDSv2: $aws_region"
                    fi

                    # Fallback to IMDSv1 if token failed or region is empty
                    if [ -z "$aws_region" ]; then
                        aws_region=$(curl -s http://169.254.169.254/latest/meta-data/placement/region 2>/dev/null)
                        if [ -n "$aws_region" ]; then
                            log "Region detected via IMDSv1: $aws_region"
                        fi
                    fi

                    # Fallback to AWS CLI configure if IMDS failed
                    if [ -z "$aws_region" ] && command -v aws >/dev/null 2>&1; then
                        aws_region=$(aws configure get region 2>/dev/null)
                        if [ -n "$aws_region" ]; then
                            log "Region detected via aws configure: $aws_region"
                        fi
                    fi
                    # --- End Region Detection ---

                    if [ -n "$aws_region" ]; then
                        echo "  AWS Region: $aws_region" >> "$RESULTS_FILE"
                    fi

                    # Test connection using the agent
                    if [ -x "$BACKINT_DIR/aws-backint-agent" ]; then
                        connection_test=$("$BACKINT_DIR/aws-backint-agent" test-connection 2>&1)
                        if [ $? -eq 0 ]; then
                            echo "✓ Successfully connected to AWS Backup" >> "$RESULTS_FILE"
                            log_success "AWS Backup connection test passed"
                        else
                            echo "✗ Failed to connect to AWS Backup" >> "$RESULTS_FILE"
                            echo "Error: $connection_test" >> "$RESULTS_FILE"
                            log_error "AWS Backup connection test failed"
                            ((ERROR_COUNT++))
                        fi
                    fi

                    # 10. Verify signature (optional for existing installations)
                    if [ -x "$BACKINT_DIR/aws-backint-agent" ] && [ -f "$BACKINT_DIR/aws-backint-agent.gpg" ]; then
                        echo -e "\nVerifying AWS Backint Agent signature:" >> "$RESULTS_FILE"
                        
                        # Check if gpg is available
                        if command -v gpg >/dev/null 2>&1; then
                            if gpg --list-keys 80D85C5E1E65925B >/dev/null 2>&1; then
                                echo "? GPG key for AWS Backint Agent is imported" >> "$RESULTS_FILE"
                                log_success "GPG key for signature verification is available"
                            else
                                echo "? GPG key for AWS Backint Agent is not imported" >> "$RESULTS_FILE"
                                log_warning "GPG key for signature verification is not available"
                                ((WARNING_COUNT++))
                            fi
                        else
                            echo "? GPG is not installed - signature verification not possible" >> "$RESULTS_FILE"
                            log_warning "GPG is not installed for signature verification"
                            ((WARNING_COUNT++))
                        fi
                    fi

                    # Summary
                    echo -e "\nSummary:" >> "$RESULTS_FILE"
                    echo "Errors: $ERROR_COUNT" >> "$RESULTS_FILE"
                    echo "Warnings: $WARNING_COUNT" >> "$RESULTS_FILE"

                    if [ $ERROR_COUNT -eq 0 ]; then
                        if [ $WARNING_COUNT -eq 0 ]; then
                            echo "Result: AWS Backint Agent is properly installed and configured" >> "$RESULTS_FILE"
                            exit 0
                        else
                            echo "Result: AWS Backint Agent is installed with minor issues" >> "$RESULTS_FILE"
                            exit 0
                        fi
                    else
                        echo "Result: AWS Backint Agent installation has critical issues" >> "$RESULTS_FILE"
                        exit 1
                    fi

          - name: CheckLogFiles
            action: aws:runCommand
            nextStep: InvokePart5
            onFailure: Continue
            inputs:
              DocumentName: AWS-RunShellScript
              InstanceIds: ['{{ InstanceId }}']
              Parameters:
                commands:
                  - |
                    #!/bin/bash
                    mkdir -p /tmp/hana_health
                    source /tmp/hana_health/env_vars.sh
                    setup_log_files "logfiles_check"
                    log "Starting backup log files check for SID: $SID"

                    log_warning() {
                        local message=$1
                        log "WARN: $message" "$LOG_FILE"
                        ((WARNING_COUNT++))
                    }

                    log_error() {
                        local message=$1
                        log "ERROR: $message" "$LOG_FILE"
                        ((ERROR_COUNT++))
                    }

                    check_log_file() {
                        local file=$1
                        local description=$2
                        local section=$3 # Not currently used in output formatting

                        file="${file/<SID>/$SID}"
                        file="${file/<INSTANCE_NUMBER>/$INSTANCE_NUM}" # Assumes INSTANCE_NUM is set
                        file="${file/<HOSTNAME>/$HOSTNAME}" # Assumes HOSTNAME is set
                        file="${file/<HANA_TENANT_NAME>/$SID}" # Simplification

                        echo "Checking: $description" >> "$RESULTS_FILE"
                        echo "Path: $file" >> "$RESULTS_FILE"

                        if [ -f "$file" ]; then
                            echo "- Exists: YES" >> "$RESULTS_FILE"

                            if [ -n "$(find "$file" -mmin -60 2>/dev/null)" ]; then
                                echo "- Status: ACTIVE (modified in last hour)" >> "$RESULTS_FILE"
                            else
                                echo "- Status: INACTIVE (no recent modifications)" >> "$RESULTS_FILE"
                            fi

                            local size=$(du -h "$file" 2>/dev/null | cut -f1)
                            echo "- Size: ${size:-N/A}" >> "$RESULTS_FILE"
                        else
                            echo "- Exists: NO" >> "$RESULTS_FILE"
                            log "WARN: Missing backup log file - $description ($file)"
                            ((WARNING_COUNT++))
                        fi
                        echo "" >> "$RESULTS_FILE"
                    }

                    # Define log files to check
                    declare -a BACKUP_LOG_FILES=(
                        "/usr/bin/ssm-sap/logs/backup_hana.log|Backup HANA Log|Backup Logs"
                        "/usr/bin/ssm-sap/logs/backup_hana_retrieve_metadata.log|Backup Metadata Log|Backup Logs"
                        "/var/lib/amazon/ssm/packages/AWSSAP-Backint/*/aws-backint-agent-install-*.log|Backint Install Log|Backup Logs"
                        # Note: Checking the agent executable itself isn't standard log check, but kept from original list
                        "/hana/shared/aws-backint-agent/aws-backint-agent|Backint Agent Executable|Backint Agent Logs"
                        "/hana/shared/aws-backint-agent/aws-backint-agent.log|Backint Agent Log|Backint Agent Logs"
                        "/hana/shared/aws-backint-agent/aws-backint-agent-log.log|Backint Agent Extended Log|Backint Agent Logs"
                        "/hana/shared/aws-backint-agent/aws-backint-agent-catalog.log|Backint Agent Catalog|Backint Agent Logs"
                    )

                    # Check defined log files
                    current_section=""
                    for log_entry in "${BACKUP_LOG_FILES[@]}"; do
                        IFS='|' read -r file description section <<< "$log_entry"

                        if [ "$current_section" != "$section" ]; then
                            echo -e "\n$section" >> "$RESULTS_FILE"
                            current_section="$section"
                        fi

                        check_log_file "$file" "$description" "$section"
                    done

                    # Check HANA log backup status
                    echo -e "\nLog Backup Status" >> "$RESULTS_FILE"
                    if [ -d "/hana/log/$SID" ]; then
                        echo "HANA Log Path: /hana/log/$SID (Exists)" >> "$RESULTS_FILE"
                        backed_up_count=$(find -L "/hana/log/$SID" -name 'hdb*' -type d 2>/dev/null | xargs -I{} su - "${SID,,}adm" -c "hdblogdiag seglist {}" 2>/dev/null | grep -c "BackedUp" || echo "0")
                        backed_up_count=$(echo "$backed_up_count" | tr -d '\\n\\r' | grep -o '[0-9]*' || echo "0")

                        if ! [[ "$backed_up_count" =~ ^[0-9]+$ ]]; then
                            backed_up_count=0
                        fi

                        echo "Backed up log segments found: $backed_up_count" >> "$RESULTS_FILE"

                        if [ "$backed_up_count" -gt 0 ]; then
                            echo "Status: Logs appear to be backed up" >> "$RESULTS_FILE"
                            log_success "Found backed up log segments using hdblogdiag."
                        else
                            echo "Status: No backed up log segments found - log backups may not be running/configured via Backint" >> "$RESULTS_FILE"
                            log "WARN: No backed up log segments found for SID: $SID using hdblogdiag."
                            ((WARNING_COUNT++))
                        fi
                    else
                        echo "HANA Log Path: /hana/log/$SID (Not found)" >> "$RESULTS_FILE"
                        log "WARN: HANA log path not found: /hana/log/$SID"
                        ((WARNING_COUNT++))
                    fi

                    # --- Add StorageId.json checks start ---
                    log_info "Checking StorageId.json..."
                    echo -e "\nStorageId.json Check:" >> "$RESULTS_FILE"
                    STORAGE_ID_JSON="/hana/shared/aws-backint-agent/awsbackup/StorageId.json"

                    if [ -f "$STORAGE_ID_JSON" ]; then
                        log_success "File exists: $STORAGE_ID_JSON"
                        echo "- File Status: Found" >> "$RESULTS_FILE"

                        # Check Permissions using stat
                        PERMS_INFO=$(stat -c "%a %U %G" "$STORAGE_ID_JSON" 2>/dev/null)
                        if [ $? -eq 0 ]; then
                            PERMS_OCTAL=$(echo "$PERMS_INFO" | cut -d' ' -f1)
                            OWNER_USER=$(echo "$PERMS_INFO" | cut -d' ' -f2)
                            OWNER_GROUP=$(echo "$PERMS_INFO" | cut -d' ' -f3)
                            echo "- Permissions: $PERMS_OCTAL (Owner: $OWNER_USER:$OWNER_GROUP)" >> "$RESULTS_FILE"

                            # Basic check: Readable by owner and not world-writable
                            FIRST_DIGIT=${PERMS_OCTAL:0:1}
                            LAST_DIGIT=${PERMS_OCTAL:2:1}

                            OWNER_CAN_READ=false
                            # Check if owner has read permission (4 or more in first digit)
                            if [[ "$FIRST_DIGIT" == "4" || "$FIRST_DIGIT" == "5" || "$FIRST_DIGIT" == "6" || "$FIRST_DIGIT" == "7" ]]; then
                                OWNER_CAN_READ=true
                            fi

                            WORLD_WRITABLE=false
                            # Check if 'others' have write permission (2 or 3 or 6 or 7 in last digit)
                            if [[ "$LAST_DIGIT" == "2" || "$LAST_DIGIT" == "3" || "$LAST_DIGIT" == "6" || "$LAST_DIGIT" == "7" ]]; then
                                WORLD_WRITABLE=true
                            fi

                            if $OWNER_CAN_READ && ! $WORLD_WRITABLE; then
                                log_success "Permissions seem reasonable ($PERMS_OCTAL)."
                                echo "- Permissions Status: OK" >> "$RESULTS_FILE"
                            else
                                log_warning "Permissions may be incorrect ($PERMS_OCTAL). Expected: Readable by owner ($OWNER_USER), not world-writable."
                                echo "- Permissions Status: WARNING (Check required: $PERMS_OCTAL)" >> "$RESULTS_FILE"
                                ((WARNING_COUNT++))
                            fi
                        else
                            log_warning "Could not determine permissions for $STORAGE_ID_JSON."
                            echo "- Permissions Status: WARNING (Could not stat file)" >> "$RESULTS_FILE"
                            ((WARNING_COUNT++))
                        fi

                        # Check JSON Validity using Python
                        if command -v python3 &> /dev/null; then
                            # Attempt to load JSON; redirect Python's stderr to /dev/null
                            if python3 -c "import json, sys; json.load(sys.stdin)" < "$STORAGE_ID_JSON" 2> /dev/null; then
                                log_success "JSON content is well-formed."
                                echo "- JSON Validity: OK" >> "$RESULTS_FILE"
                            else
                                log_error "JSON content is NOT well-formed."
                                echo "- JSON Validity: ERROR (Invalid JSON)" >> "$RESULTS_FILE"
                                ((ERROR_COUNT++))
                            fi
                        else
                            log_warning "python3 command not found. Cannot validate JSON."
                            echo "- JSON Validity: SKIPPED (python3 not found)" >> "$RESULTS_FILE"
                            ((WARNING_COUNT++))
                        fi

                    else
                        log_warning "File does not exist: $STORAGE_ID_JSON"
                        echo "- File Status: NOT FOUND" >> "$RESULTS_FILE"
                        # This might be normal if Backint hasn't run yet, so keep as warning
                        ((WARNING_COUNT++))
                    fi

                    # Write Summary
                    write_summary # Use the function defined in env_vars.sh

                    log "Completed log files check for SID: $SID"

                    # Exit logic based on global counts
                    if [ $ERROR_COUNT -gt 0 ]; then
                        exit 1
                    else
                        # Exit 0 even if there are warnings to allow process to continue
                        exit 0
                    fi

          - name: InvokePart5
            action: aws:executeAutomation
            isEnd: true
            onFailure: Abort
            inputs:
              DocumentName: !Sub 'SAPBackupPreCheck-${AWS::StackName}-${SID}-Part5' 
              RuntimeParameters:
                InstanceId: '{{ InstanceId }}'
                RunHSIScript: '{{ RunHSIScript }}'
                SID: '{{ SID }}'
                Timestamp: '{{ Timestamp }}'
                S3BucketForLogs: '{{ S3BucketForLogs }}'
                S3UploaderLink: '{{ S3UploaderLink }}'
                HANASupportInfoBucket: '{{ HANASupportInfoBucket }}'
                HANASupportInfoPath: '{{ HANASupportInfoPath }}'
                HANASupportInfoS3Key: '{{ HANASupportInfoS3Key }}'
                SecretArn: '{{ SecretArn }}'

  SAPBackupPreCheckPart5:
    Type: AWS::SSM::Document
    Properties:
      DocumentType: Automation
      Name: !Sub 'SAPBackupPreCheck-${AWS::StackName}-${SID}-Part5'
      Content:
        schemaVersion: '0.3'
        description: AWS Backup SAP HANA Pre-Check Automation (Part 5)
        parameters:
          InstanceId:
            type: String
            description: EC2 instance ID running SAP HANA
          RunHSIScript:
            type: String
            description: Would you like to use the HANA Support Info tool? (yes/no)
            allowedValues:
              - 'yes'
              - 'no'
          SID:
            type: String
            description: SAP HANA system ID
          S3BucketForLogs:
            type: String
            description: S3 bucket for logs (optional)
            default: ''
          S3UploaderLink:
            type: String
            description: AWS Support upload link (optional)
            default: ''
          Timestamp:
            type: String
            default: '{{ automation:EXECUTION_ID }}'
          SecretArn:
            type: String
            description: ARN of secret in Secrets Manager
          HANASupportInfoBucket:
            type: String
            description: S3 bucket containing HANASupportInfo.sh script (optional)
            default: ''
          HANASupportInfoPath:
            type: String
            description: File path where HANASupportInfo.sh script is located or should be downloaded to
            default: /tmp/HANASupportInfo.sh
          HANASupportInfoS3Key:
            type: String
            description: Object key (path + filename) of the script within the S3 bucket
            default: HANASupportInfo.sh
        mainSteps:
          - name: CheckMemorySettings
            action: aws:runCommand
            nextStep: CheckStorageAndResources
            onFailure: step:CheckStorageAndResources
            inputs:
              DocumentName: AWS-RunShellScript
              InstanceIds: ['{{ InstanceId }}']
              Parameters:
                commands:
                  - |
                    #!/bin/bash
                    mkdir -p /tmp/hana_health
                    source /tmp/hana_health/env_vars.sh
                    setup_log_files "memory_settings"

                    check_system_memory() {
                      
                      local TOTAL_MEM=$(free -g | awk '/^Mem:/{print $2}')
                      local USED_MEM=$(free -g | awk '/^Mem:/{print $3}')
                      local AVAIL_MEM=$(free -g | awk '/^Mem:/{print $7}')
                      
                      {
                        echo "System Memory:"
                        echo "- Total: ${TOTAL_MEM} GB"
                        echo "- Used: ${USED_MEM} GB"
                        echo "- Available: ${AVAIL_MEM} GB"
                        echo ""
                      } >> "$RESULTS_FILE"
                      
                      log "System has ${TOTAL_MEM}GB total memory, ${AVAIL_MEM}GB available"
                      echo "$AVAIL_MEM"
                    }

                    get_tenant_db_sizes() {
                      
                      local hdbsql_cmd="/usr/sap/$SID/HDB$INSTANCE_NUM/exe/hdbsql"
                      local total_db_size=0
                      local tenant_dbs=""
                      
                      if [ ! -x "$hdbsql_cmd" ]; then
                        log_error "hdbsql not found at $hdbsql_cmd"
                        echo "Database Size Check: hdbsql not found" >> "$RESULTS_FILE"
                        echo "0"
                        return
                      fi

                      if [ -f "/tmp/hana_env.sh" ]; then
                        source /tmp/hana_env.sh
                      fi

                      local sysdb_size=0
                      if [ -n "$HANA_USERNAME" ] && [ -n "$HANA_PASSWORD" ]; then
                        sysdb_size=$(su - ${SIDADM} -c "echo 'SELECT ROUND(SUM(TOTAL_SIZE)/1024/1024/1024, 2) FROM M_CS_TABLES;' | $hdbsql -x -j -a -U BACKUP_CHECK_USER -d SYSTEMDB" 2>/dev/null | grep -v "ROUND" | tr -d ' ')
                        if [ -z "$sysdb_size" ]; then
                          sysdb_size=$(su - ${SIDADM} -c "echo 'SELECT ROUND(SUM(TOTAL_SIZE)/1024/1024/1024, 2) FROM M_CS_TABLES;' | $hdbsql -x -j -a -u $HANA_USERNAME -p $HANA_PASSWORD -d SYSTEMDB" 2>/dev/null | grep -v "ROUND" | tr -d ' ')
                        fi
                      fi
                      
                      if [ -z "$sysdb_size" ] || ! [[ "$sysdb_size" =~ ^[0-9]+\.?[0-9]*$ ]]; then
                        sysdb_size=0
                        log_warning "Could not determine SYSTEMDB size, using 0"
                      fi
                      
                      echo "Database Sizes:" >> "$RESULTS_FILE"
                      echo "- SYSTEMDB: ${sysdb_size} GB" >> "$RESULTS_FILE"
                      total_db_size=$(echo "$total_db_size + $sysdb_size" | bc -l 2>/dev/null || echo "$total_db_size")

                      if su - "$SIDADM" -c "which HDBSettings.sh" &>/dev/null; then
                        log "Using HDBSettings.sh ListDatabases to detect tenants..."
                        tenant_list=$(su - "$SIDADM" -c "HDBSettings.sh ListDatabases" 2>/dev/null | grep -v "SYSTEMDB" | awk '{print $1}' | sort -u)
                        if [ -n "$tenant_list" ]; then
                          tenant_dbs="$tenant_list"
                          log_success "Found tenants using HDBSettings.sh"
                        fi
                      fi

                      if [ -z "$tenant_dbs" ]; then
                        log_warning "No tenant databases found using any method"
                        echo "- No tenant databases found" >> "$RESULTS_FILE"
                      else
                        local tenant_port="3${INSTANCE_NUM}15"
                        for db in $tenant_dbs; do
                          if [[ ! "$db" =~ ^[0-9]+$ ]] && [[ ! "$db" =~ ^time$ ]] && [[ ! "$db" =~ ^usec$ ]] && [[ ! "$db" =~ ^server$ ]] && [[ ! "$db" =~ ^rows$ ]] && [[ ! "$db" =~ ^selected$ ]] && [[ ! "$db" =~ ^overall$ ]]; then
                            log "Getting size for tenant: $db"
                            local db_size=0
                            
                            if su - "$SIDADM" -c "which HDBSettings.sh" &>/dev/null; then
                              local db_port=$(su - ${SIDADM} -c "HDBSettings.sh ListDatabases" 2>/dev/null | grep "$db" | awk '{print $NF}' | tr -d ',')
                              if [ -n "$db_port" ]; then
                                db_size=$(su - ${SIDADM} -c "echo 'SELECT ROUND(SUM(TOTAL_SIZE)/1024/1024/1024, 2) FROM M_CS_TABLES;' | $hdbsql_cmd -x -j -a -U BACKUP_CHECK_USER -n localhost:$db_port -d $db" 2>/dev/null | grep -v "ROUND" | tr -d ' ')
                              fi
                            fi
                            
                            if [ -z "$db_size" ] || ! [[ "$db_size" =~ ^[0-9]+\.?[0-9]*$ ]]; then
                              db_size=$(su - ${SIDADM} -c "echo 'SELECT ROUND(SUM(TOTAL_SIZE)/1024/1024/1024, 2) FROM M_CS_TABLES;' | $hdbsql_cmd -x -j -a -U BACKUP_CHECK_USER -n localhost:$tenant_port -d $db" 2>/dev/null | grep -v "ROUND" | tr -d ' ')
                            fi
                            
                            if [ -z "$db_size" ] || ! [[ "$db_size" =~ ^[0-9]+\.?[0-9]*$ ]]; then
                              db_size=0
                              log_warning "Could not determine size for tenant $db, using 0"
                            fi
                            
                            echo "- $db: ${db_size} GB" >> "$RESULTS_FILE"
                            total_db_size=$(echo "$total_db_size + $db_size" | bc -l 2>/dev/null || echo "$total_db_size")
                          fi
                        done
                      fi
                      
                      total_db_size=$(echo "($total_db_size+0.5)/1" | bc 2>/dev/null || echo "0")
                      echo "- Total Database Size: approximately ${total_db_size} GB" >> "$RESULTS_FILE"
                      echo "" >> "$RESULTS_FILE"
                      
                      log "Total database size: approximately ${total_db_size} GB"
                      echo "$total_db_size"
                    }

                    check_config_settings() {
                      
                      local config_file="/hana/shared/aws-backint-agent/aws-backint-agent-config.yaml"
                      
                      if [ ! -f "$config_file" ]; then
                        log_warning "AWS Backint Agent config file not found at $config_file"
                        echo "AWS Backint Agent Config: Not found" >> "$RESULTS_FILE"
                        echo "0"
                        return
                      fi
                      
                      echo "AWS Backint Agent Configuration:" >> "$RESULTS_FILE"
                      
                      local upload_concurrency=$(grep -i "UploadConcurrency" "$config_file" 2>/dev/null | awk '{print $2}')
                      local download_concurrency=$(grep -i "DownloadConcurrency" "$config_file" 2>/dev/null | awk '{print $2}')
                      
                      if [ -n "$upload_concurrency" ]; then
                        echo "- UploadConcurrency: $upload_concurrency" >> "$RESULTS_FILE"
                        log "Upload concurrency set to $upload_concurrency"
                      else
                        echo "- UploadConcurrency: Not set (default)" >> "$RESULTS_FILE"
                        log_warning "UploadConcurrency not specified in config"
                      fi
                      
                      if [ -n "$download_concurrency" ]; then
                        echo "- DownloadConcurrency: $download_concurrency" >> "$RESULTS_FILE"
                        log "Download concurrency set to $download_concurrency"
                      else
                        echo "- DownloadConcurrency: Not set (default)" >> "$RESULTS_FILE"
                        log_warning "DownloadConcurrency not specified in config"
                      fi
                      
                      if [ -n "$upload_concurrency" ] && [ -n "$download_concurrency" ]; then
                        echo "1"
                      else
                        echo "0"
                      fi
                    }

                    AVAILABLE_MEM=$(check_system_memory)
                    AVAILABLE_MEM=${AVAILABLE_MEM%%[!0-9]*} 

                    TOTAL_DB_SIZE=$(get_tenant_db_sizes)
                    TOTAL_DB_SIZE=${TOTAL_DB_SIZE%%[!0-9]*}  

                    CONFIG_STATUS=$(check_config_settings)

                    AVAILABLE_MEM=${AVAILABLE_MEM:-0}
                    TOTAL_DB_SIZE=${TOTAL_DB_SIZE:-0}

                    echo "Memory vs Database Size Analysis:" >> "$RESULTS_FILE"
                    echo "- Available memory: ${AVAILABLE_MEM} GB" >> "$RESULTS_FILE"
                    echo "- Total database size: ${TOTAL_DB_SIZE} GB" >> "$RESULTS_FILE"

                    if [ "$AVAILABLE_MEM" -lt "$TOTAL_DB_SIZE" ]; then
                      log_warning "Memory insufficient: ${AVAILABLE_MEM}GB < ${TOTAL_DB_SIZE}GB"
                    else
                      log_success "Memory sufficient: ${AVAILABLE_MEM}GB >= ${TOTAL_DB_SIZE}GB"
                    fi

                    {
                      echo ""
                      echo "Summary:"
                      echo "- Errors: $ERROR_COUNT"
                      echo "- Warnings: $WARNING_COUNT"
                      
                      if [ $ERROR_COUNT -eq 0 ]; then
                        echo "Memory check passed with $WARNING_COUNT warnings"
                      else
                        echo "Memory check failed with $ERROR_COUNT errors"
                      fi
                    } >> "$RESULTS_FILE"

                    cp "$RESULTS_FILE" "/tmp/hana_health/memory_settings_results.txt"

                    log "Memory settings check completed with $ERROR_COUNT errors and $WARNING_COUNT warnings"

                    if [ $ERROR_COUNT -gt 0 ]; then
                      exit 1
                    elif [ $WARNING_COUNT -gt 0 ]; then
                      exit 0
                    else
                      exit 0
                    fi
          - name: CheckStorageAndResources
            action: aws:runCommand
            nextStep: CreateAndUploadArchive
            onFailure: Continue
            inputs:
              DocumentName: AWS-RunShellScript
              InstanceIds: ['{{ InstanceId }}']
              Parameters:
                commands:
                  - |
                    #!/bin/bash
                    mkdir -p /tmp/hana_health
                    source /tmp/hana_health/env_vars.sh
                    setup_log_files "storage_check"
                    log "Starting storage and resources check"

                    declare -A RECOMMENDED_FS=([xfs]=1 [nfs]=1 [gpfs]=1)
                    CRITICAL_THRESHOLD=90
                    WARNING_THRESHOLD=80

                    # Block device detailed check
                    check_block_devices() {
                        echo "Block Device Details:" >> "$RESULTS_FILE"
                        echo "-------------------" >> "$RESULTS_FILE"
                        
                        if command -v lsblk >/dev/null 2>&1; then
                            # Get detailed block device information
                            lsblk_output=$(lsblk -f -t -m -o +SERIAL | sed 's/vol/vol-/' 2>/dev/null)
                            
                            if [ -n "$lsblk_output" ]; then
                                echo "- Block devices found:" >> "$RESULTS_FILE"
                                echo "$lsblk_output" >> "$RESULTS_FILE"
                                log_success "Block device information collected"
                            else
                                echo "- Block devices: Error getting information" >> "$RESULTS_FILE"
                                log_error "Failed to collect block device information"
                                ((ERROR_COUNT++))
                            fi
                        else
                            echo "- lsblk command not available" >> "$RESULTS_FILE"
                            log_warning "lsblk command not available"
                            ((WARNING_COUNT++))
                        fi
                        
                        echo "" >> "$RESULTS_FILE"
                    }

                    # LVM configuration check
                    check_lvm_config() {
                        echo "LVM Configuration:" >> "$RESULTS_FILE"
                        echo "-----------------" >> "$RESULTS_FILE"
                        
                        lvm_cmds=("pvs" "vgs" "lvs")
                        lvm_found=false
                        
                        for cmd in "${lvm_cmds[@]}"; do
                            if command -v $cmd >/dev/null 2>&1; then
                                cmd_output=$($cmd 2>/dev/null)
                                
                                if [ -n "$cmd_output" ] && ! echo "$cmd_output" | grep -q "No .* found"; then
                                    echo "- $cmd output:" >> "$RESULTS_FILE"
                                    echo "$cmd_output" >> "$RESULTS_FILE"
                                    echo "" >> "$RESULTS_FILE"
                                    lvm_found=true
                                else
                                    echo "- $cmd: No volumes found" >> "$RESULTS_FILE"
                                fi
                            else
                                echo "- $cmd: Command not available" >> "$RESULTS_FILE"
                            fi
                        done
                        
                        # Check dmsetup if available
                        if command -v dmsetup >/dev/null 2>&1 && $lvm_found; then
                            dmsetup_output=$(dmsetup table 2>/dev/null)
                            
                            if [ -n "$dmsetup_output" ]; then
                                echo "- Device mapper table:" >> "$RESULTS_FILE"
                                echo "$dmsetup_output" >> "$RESULTS_FILE"
                            fi
                        fi
                        
                        if ! $lvm_found; then
                            echo "- LVM: Not in use on this system" >> "$RESULTS_FILE"
                            log_success "No LVM configuration found (this is normal for many configurations)"
                        else
                            log_success "LVM configuration collected"
                        fi
                        
                        echo "" >> "$RESULTS_FILE"
                    }

                    # IO monitoring check
                    check_io_monitoring() {
                        echo "I/O Monitoring (Snapshot):" >> "$RESULTS_FILE"
                        echo "-------------------------" >> "$RESULTS_FILE"
                        
                        if command -v iostat >/dev/null 2>&1; then
                            # Get a quick snapshot of IO statistics
                            iostat_output=$(LANG=C iostat -h -y -t -N -c -d -x -p ALL 1 1 2>/dev/null)
                            
                            if [ -n "$iostat_output" ]; then
                                echo "- Current I/O statistics:" >> "$RESULTS_FILE"
                                echo "$iostat_output" | head -30 >> "$RESULTS_FILE"
                                log_success "I/O statistics collected"
                                
                                # Look for high utilization
                                high_util=$(echo "$iostat_output" | awk '$NF > 80.0 {print $1, $NF"%"}')
                                if [ -n "$high_util" ]; then
                                    echo "- WARNING: High disk utilization detected:" >> "$RESULTS_FILE"
                                    echo "$high_util" | sed 's/^/  /' >> "$RESULTS_FILE"
                                    log_warning "High disk utilization detected"
                                    ((WARNING_COUNT++))
                                fi
                            else
                                echo "- I/O statistics: Error collecting data" >> "$RESULTS_FILE"
                                log_warning "Failed to collect I/O statistics"
                                ((WARNING_COUNT++))
                            fi
                        else
                            echo "- iostat command not available" >> "$RESULTS_FILE"
                            log_warning "iostat command not available"
                            ((WARNING_COUNT++))
                        fi
                        
                        echo "" >> "$RESULTS_FILE"
                        
                        # Check network I/O if sar is available
                        if command -v sar >/dev/null 2>&1; then
                            sar_output=$(LANG=C sar -n DEV 1 1 2>/dev/null)
                            
                            if [ -n "$sar_output" ]; then
                                echo "- Network I/O statistics:" >> "$RESULTS_FILE"
                                echo "$sar_output" | grep -v "^Average" | head -10 >> "$RESULTS_FILE"
                                log_success "Network I/O statistics collected"
                            else
                                echo "- Network I/O statistics: Error collecting data" >> "$RESULTS_FILE"
                                log_warning "Failed to collect network I/O statistics"
                                ((WARNING_COUNT++))
                            fi
                        else
                            echo "- sar command not available" >> "$RESULTS_FILE"
                            log_warning "sar command not available"
                            ((WARNING_COUNT++))
                        fi
                        
                        echo "" >> "$RESULTS_FILE"
                    }

                    check_filesystem_type() {
                        local mount="$1"
                        echo "Filesystem Type for $mount:" >> "$RESULTS_FILE"
                        
                        local fs_type=$(df -T "$mount" | awk 'NR==2 {print $2}')
                        echo "- Filesystem Type: $fs_type" >> "$RESULTS_FILE"
                        
                        if [[ -n "${RECOMMENDED_FS[$fs_type]}" ]]; then
                            echo "- Filesystem Status: OK (recommended type)" >> "$RESULTS_FILE"
                            log_success "Filesystem $fs_type is recommended for HANA"
                        else
                            echo "- Filesystem Status: WARNING (non-recommended type)" >> "$RESULTS_FILE"
                            echo "  Recommended types for HANA are: XFS, NFS, GPFS" >> "$RESULTS_FILE"
                            log_warning "Non-recommended filesystem type $fs_type detected"
                            ((WARNING_COUNT++))
                        fi
                        
                        # Check mount options
                        local mount_options=$(findmnt -n -o OPTIONS "$mount" 2>/dev/null)
                        if [ -n "$mount_options" ]; then
                            echo "- Mount Options: $mount_options" >> "$RESULTS_FILE"
                            
                            # Check for recommended mount options based on filesystem type
                            if [ "$fs_type" = "xfs" ]; then
                                if ! echo "$mount_options" | grep -q "noatime"; then
                                    echo "  WARNING: 'noatime' option recommended for XFS with HANA" >> "$RESULTS_FILE"
                                    log_warning "Missing recommended 'noatime' option for XFS"
                                    ((WARNING_COUNT++))
                                fi
                            elif [ "$fs_type" = "nfs" ]; then
                                if ! echo "$mount_options" | grep -q "vers=3" && ! echo "$mount_options" | grep -q "vers=4"; then
                                    echo "  WARNING: NFS version not specified (vers=3 or vers=4 recommended)" >> "$RESULTS_FILE"
                                    log_warning "NFS version not specified in mount options"
                                    ((WARNING_COUNT++))
                                fi
                            fi
                        else
                            echo "- Mount Options: Could not determine" >> "$RESULTS_FILE"
                        fi
                        
                        echo "" >> "$RESULTS_FILE"
                    }

                    check_disk_usage() {
                        local mount="$1"
                        echo "Disk Usage for $mount:" >> "$RESULTS_FILE"
                        
                        local usage=$(df -h "$mount" | awk 'NR==2 {print $5}' | sed 's/%//')
                        local space=$(df -h "$mount" | awk 'NR==2 {print $2, $3, $4}')
                        
                        echo "- Usage: ${usage}% (Total, Used, Free: $space)" >> "$RESULTS_FILE"
                        
                        if [ "$usage" -gt $CRITICAL_THRESHOLD ]; then
                            echo "- Fill Status: CRITICAL (over ${CRITICAL_THRESHOLD}% full)" >> "$RESULTS_FILE"
                            log_error "Critical disk usage on $mount: ${usage}%"
                            ((ERROR_COUNT++))
                        elif [ "$usage" -gt $WARNING_THRESHOLD ]; then
                            echo "- Fill Status: WARNING (over ${WARNING_THRESHOLD}% full)" >> "$RESULTS_FILE"
                            log_warning "High disk usage on $mount: ${usage}%"
                            ((WARNING_COUNT++))
                        else
                            echo "- Fill Status: OK (sufficient space)" >> "$RESULTS_FILE"
                            log_success "Disk usage OK on $mount: ${usage}%"
                        fi
                        
                        # Check inode usage too
                        local inode_usage=$(df -i "$mount" | awk 'NR==2 {print $5}' | sed 's/%//')
                        
                        echo "- Inode Usage: ${inode_usage}%" >> "$RESULTS_FILE"
                        
                        if [ "$inode_usage" -gt $CRITICAL_THRESHOLD ]; then
                            echo "- Inode Status: CRITICAL (over ${CRITICAL_THRESHOLD}% used)" >> "$RESULTS_FILE"
                            log_error "Critical inode usage on $mount: ${inode_usage}%"
                            ((ERROR_COUNT++))
                        elif [ "$inode_usage" -gt $WARNING_THRESHOLD ]; then
                            echo "- Inode Status: WARNING (over ${WARNING_THRESHOLD}% used)" >> "$RESULTS_FILE"
                            log_warning "High inode usage on $mount: ${inode_usage}%"
                            ((WARNING_COUNT++))
                        else
                            echo "- Inode Status: OK (sufficient inodes)" >> "$RESULTS_FILE"
                            log_success "Inode usage OK on $mount: ${inode_usage}%"
                        fi
                        
                        echo "" >> "$RESULTS_FILE"
                    }

                    show_top_consumers() {
                        local mount="$1"
                        echo "Top Disk Consumers in $mount:" >> "$RESULTS_FILE"
                        
                        if [ -d "$mount" ]; then
                            # Use both du and find to get different perspectives
                            echo "- By directory size (top 5):" >> "$RESULTS_FILE"
                            du -h "$mount" --max-depth=2 2>/dev/null | 
                                sort -hr | 
                                head -5 | 
                                sed 's/^/  /' >> "$RESULTS_FILE"
                            
                            # Find largest files
                            echo "- Largest files (top 5):" >> "$RESULTS_FILE"
                            find "$mount" -type f -exec du -h {} \; 2>/dev/null | 
                                sort -hr | 
                                head -5 | 
                                sed 's/^/  /' >> "$RESULTS_FILE"
                            
                            # Count files by type
                            echo "- Files by type (top 5):" >> "$RESULTS_FILE"
                            find "$mount" -type f -name "*.*" 2>/dev/null | 
                                grep -o "\.[^\.]*$" | 
                                sort | 
                                uniq -c | 
                                sort -nr | 
                                head -5 | 
                                sed 's/^/  /' >> "$RESULTS_FILE"
                        else
                            echo "- Cannot access directory to determine top consumers" >> "$RESULTS_FILE"
                        fi
                        
                        echo "" >> "$RESULTS_FILE"
                    }

                    check_mount_point() {
                        local mount="$1"
                        echo "Path Check: $mount" >> "$RESULTS_FILE"
                        echo "----------------------" >> "$RESULTS_FILE"
                        
                        if [ -d "$mount" ]; then
                            echo "- Status: EXISTS" >> "$RESULTS_FILE"
                            check_disk_usage "$mount"
                            
                            if [[ "$mount" == "/hana/data/${SID}" || "$mount" == "/hana/log/${SID}" ]]; then
                                check_filesystem_type "$mount"
                            fi
                            
                            show_top_consumers "$mount"
                        else
                            echo "- Status: NOT FOUND" >> "$RESULTS_FILE"
                            echo "- Error: Mount point does not exist" >> "$RESULTS_FILE"
                            log_error "Mount point $mount does not exist"
                            ((ERROR_COUNT++))
                        fi
                    }

                    # Run comprehensive block device check
                    check_block_devices

                    # Check LVM configuration if present
                    check_lvm_config

                    # Run I/O monitoring checks
                    check_io_monitoring

                    # Check SAP HANA specific mount points
                    HANA_PATHS=(
                        "/hana/data/${SID}"
                        "/hana/log/${SID}"
                        "/hana/shared/${SID}"
                        "/usr/sap/${SID}"
                    )

                    for mount in "${HANA_PATHS[@]}"; do
                        check_mount_point "$mount"
                    done

                    # Check /tmp directory
                    check_mount_point "/tmp"

                    # Add recommendations section if issues found
                    if [ $ERROR_COUNT -gt 0 ] || [ $WARNING_COUNT -gt 0 ]; then
                        echo "Recommendations:" >> "$RESULTS_FILE"
                        echo "---------------" >> "$RESULTS_FILE"
                        
                        # Filesystem recommendations
                        if grep -q "non-recommended type" "$RESULTS_FILE"; then
                            echo "- For optimal SAP HANA performance, use recommended filesystem types:" >> "$RESULTS_FILE"
                            echo "  * XFS: Recommended for all HANA volumes" >> "$RESULTS_FILE"
                            echo "  * NFS: Acceptable for shared volumes" >> "$RESULTS_FILE"
                        fi
                        
                        # Space recommendations
                        if grep -q "WARNING.*full\|CRITICAL.*full" "$RESULTS_FILE"; then
                            echo "- Disk space issues detected. Consider:" >> "$RESULTS_FILE"
                            echo "  * Review and clean up large files identified in the report" >> "$RESULTS_FILE"
                            echo "  * For /hana/data: Check if table redistribution is needed" >> "$RESULTS_FILE"
                            echo "  * For /hana/log: Check log backup configuration and retention" >> "$RESULTS_FILE"
                            echo "  * For persistent space issues, consider extending volumes" >> "$RESULTS_FILE"
                        fi
                        
                        # I/O performance recommendations
                        if grep -q "High disk utilization detected" "$RESULTS_FILE"; then
                            echo "- I/O performance issues detected. Consider:" >> "$RESULTS_FILE"
                            echo "  * Run extended I/O monitoring: iostat -dmx 3 1000 > /root/iostat-dmx.txt" >> "$RESULTS_FILE"
                            echo "  * Monitor network performance during backups: sar -n DEV 1 > /root/sar-n-output.txt" >> "$RESULTS_FILE"
                            echo "  * Check for resource contention from other processes" >> "$RESULTS_FILE"
                            echo "  * Verify EC2 instance type meets HANA's I/O requirements" >> "$RESULTS_FILE"
                        fi
                        
                        # Mount point recommendations
                        if grep -q "Mount point does not exist" "$RESULTS_FILE"; then
                            echo "- Missing mount points detected. Check:" >> "$RESULTS_FILE"
                            echo "  * EC2 volume attachments are correct" >> "$RESULTS_FILE"
                            echo "  * Entries in /etc/fstab are correct" >> "$RESULTS_FILE"
                            echo "  * Filesystem types and mount options are appropriate" >> "$RESULTS_FILE"
                        fi
                        
                        # Filesystem mount options recommendations
                        if grep -q "noatime.*recommended" "$RESULTS_FILE"; then
                            echo "- For XFS filesystems with HANA, recommended mount options:" >> "$RESULTS_FILE"
                            echo "  * noatime,nodiratime,logbsize=256k,swalloc,inode64" >> "$RESULTS_FILE"
                        fi
                    fi

                    # Summary section
                    echo "" >> "$RESULTS_FILE"
                    echo "Summary:" >> "$RESULTS_FILE"
                    echo "-------" >> "$RESULTS_FILE"
                    echo "Total Errors: $ERROR_COUNT" >> "$RESULTS_FILE"
                    echo "Total Warnings: $WARNING_COUNT" >> "$RESULTS_FILE"
                    echo "Checked Mount Points: ${#HANA_PATHS[@]}" >> "$RESULTS_FILE"

                    write_summary

                    if [ $ERROR_COUNT -gt 0 ]; then
                        log_error "Storage check failed with $ERROR_COUNT errors"
                        exit 1
                    elif [ $WARNING_COUNT -gt 0 ]; then
                        log_warning "Storage check completed with $WARNING_COUNT warnings"
                        exit 0
                    else
                        log_success "Storage check completed successfully"
                        exit 0
                    fi
          - name: CreateAndUploadArchive
            action: aws:runCommand
            isEnd: true
            inputs:
              DocumentName: AWS-RunShellScript
              InstanceIds: ['{{ InstanceId }}']
              Parameters:
                commands:
                  - |
                    #!/bin/bash
                    set +e
                    mkdir -p /tmp/hana_health

                    SID="{{ SID }}"
                    INSTANCE_ID="{{ InstanceId }}"
                    REGION=$(curl -s http://169.254.169.254/latest/meta-data/placement/region 2>/dev/null || echo "us-east-1")
                    HOSTNAME=$(hostname)
                    TIMESTAMP=$(date +%Y%m%d%H%M%S)

                    TEMP_DIR=$(mktemp -d -t hana_logs-XXXXXX)
                    LOG_DIR="$TEMP_DIR/logs"
                    HEALTH_CHECK_DIR="$TEMP_DIR/health_checks"
                    mkdir -p "$LOG_DIR" "$HEALTH_CHECK_DIR"

                    log_msg() { echo "$(date '+%Y-%m-%d %H:%M:%S') - $1"; }
                    log_info() { log_msg "INFO: $1"; }
                    log_warn() { log_msg "WARN: $1"; }
                    log_error() { log_msg "ERROR: $1"; }

                    for file in $(find /tmp/hana_health -type f -name "*.txt" -o -name "*.log" 2>/dev/null); do
                        cp "$file" "$HEALTH_CHECK_DIR/" 2>/dev/null
                        log_info "Copied: $(basename "$file")"
                    done

                    # pull artifacts from the HANASupportInfo step 
                    if [ -f /tmp/hana_health/env_vars.sh ]; then
                        # shellcheck disable=SC1091
                        source /tmp/hana_health/env_vars.sh 2>/dev/null || true
                    fi

                    mkdir -p "${HEALTH_CHECK_DIR}/hana_support_info"

                    # 1) wrapper log ? always present, always useful
                    if [ -f /tmp/hana_health/hana_support_wrapper.log ]; then
                        cp /tmp/hana_health/hana_support_wrapper.log \
                          "${HEALTH_CHECK_DIR}/hana_support_info/"
                    fi

                    # 2) support ZIP only if the previous step produced it
                    if [ -n "${HANA_SUPPORT_OUTPUT_ZIP:-}" ] && [ -f "$HANA_SUPPORT_OUTPUT_ZIP" ]; then
                        cp "$HANA_SUPPORT_OUTPUT_ZIP" \
                          "${HEALTH_CHECK_DIR}/hana_support_info/"
                    fi

                    declare -A LOG_PATHS=(
                    ["SSM Agent Logs:1_ssm_logs"]="/var/log/amazon/ssm/amazon-ssm-agent.log /var/log/amazon/ssm/errors.log /var/log/amazon/ssm/AmazonSSMAgent-update.txt"
                    ["SSM4SAP Logs:2_ssm4sap_logs"]="/usr/bin/ssm-sap/logs/backup_hana.log /usr/bin/ssm-sap/logs/backup_hana_retrieve_metadata.log /var/lib/amazon/ssm/packages/AWSSAP-Backint/*/aws-backint-agent-install-*.log"
                    ["AWS Backint Agent Logs:3_backint_logs"]="/hana/shared/aws-backint-agent/aws-backint-agent /hana/shared/aws-backint-agent/aws-backint-agent.log /hana/shared/aws-backint-agent/aws-backint-agent-log.log /hana/shared/aws-backint-agent/aws-backint-agent-catalog.log /hana/shared/aws-backint-agent/aws-backint-agent-launcher.sh /hana/shared/aws-backint-agent/aws-backint-agent-config.yaml /hana/shared/aws-backint-agent/aws-backint-agent-config-log.yaml /hana/shared/aws-backint-agent/aws-backint-agent-config-catalog.yaml /hana/shared/aws-backint-agent/awsbackup/StorageId.json"
                    ["CDPRO/CDGLO Logs:4_cdpro_logs"]="/usr/sap/<SID>/SYS/profile/"
                    ["CDPRO/CDGLO Logs:5_cdglo_logs"]="/usr/sap/<SID>/SYS/global/hdb/opt/hdbbackint /usr/sap/<SID>/SYS/global/hdb/opt/hdbconfig/aws-backint-agent-config.yaml /usr/sap/<SID>/SYS/global/hdb/custom/config/global.ini /usr/sap/<SID>/SYS/global/hdb/custom/config/DB_<HANA_TENANT_NAME>/global.ini /hana/shared/<SID>/global/hdb/custom/config/global.ini"
                    ["System DB Backup Logs:6_system_db_logs"]="/usr/sap/<SID>/HDB<INSTANCE_NUMBER>/<HOSTNAME>/trace/backup.log /usr/sap/<SID>/HDB<INSTANCE_NUMBER>/<HOSTNAME>/trace/backint.log /hana/shared/<SID>/HDB<INSTANCE_NUMBER>/<HOSTNAME>/trace/backup.log /hana/shared/<SID>/HDB<INSTANCE_NUMBER>/<HOSTNAME>/trace/backint.log"
                    ["System Logs:8_system_logs"]="/var/log/messages /var/log/audit/audit.log /var/log/firewalld /var/log/firewall /var/log/saptune/saptune.log /var/log/zypp/history /var/log/dnf.log"
                    )

                    log_info "Starting log collection process..."
                    LARGE_LOG_THRESHOLD=10240 

                    process_file() {
                      local file="$1" dest_dir="$2" description="$3"
                      
                      [ ! -e "$file" ] && { log_info "File not found: $file ($description)"; echo "File not found: $file" > "$dest_dir/$(basename "$file").missing"; return; }
                      
                      if [ -f "$file" ]; then
                        local size_kb=$(du -k "$file" | cut -f1)
                        local dest_file="$dest_dir/$(basename "$file")"
                        
                        if [[ "$file" =~ \.(ini|conf|yaml|json)$ ]] || [ "$size_kb" -lt "$LARGE_LOG_THRESHOLD" ]; then
                          cp "$file" "$dest_dir/" && log_info "Collected $([ "$size_kb" -lt "$LARGE_LOG_THRESHOLD" ] && echo "entire" || echo "config") file: $file ($size_kb KB)"
                        else 
                          log_info "Collected last 10000 lines of large file: $file ($size_kb KB)"
                        fi
                      elif [ -d "$file" ]; then
                        local base_name=$(basename "$file"); mkdir -p "$dest_dir/$base_name"
                        find "$file" -type f -print0 | while IFS= read -r -d $'\0' subfile; do
                          local rel_path=$(realpath --relative-to="$file" "$subfile"); local sub_dir="$dest_dir/$base_name/$(dirname "$rel_path")"; mkdir -p "$sub_dir"
                          local size_kb=$(du -k "$subfile" | cut -f1); local sub_dest="$sub_dir/$(basename "$subfile")"
                          
                          if [[ "$subfile" =~ \.(ini|conf|yaml|json)$ ]] || [ "$size_kb" -lt "$LARGE_LOG_THRESHOLD" ]; then
                            cp "$subfile" "$sub_dir/"
                          else 
                            { echo -e "# Original file: $subfile\n# Original size: $size_kb KB ($(($size_kb/1024)) MB)\n# Collection date: $(date)\n# Note: This is a truncated version containing the last 10000 lines\n# ---------------------------------------------------------------\n"; tail -n 10000 "$subfile"; } > "$sub_dest"
                          fi
                        done
                        log_info "Processed directory: $file"
                      fi
                    }

                    collect_file() {
                      local path="${1/<SID>/$SID}"; path="${path/<INSTANCE_NUMBER>/$INSTANCE_NUM}"; path="${path/<HOSTNAME>/$HOSTNAME}"; path="${path/<HANA_TENANT_NAME>/$SID}"
                      local description="$2" section="$3"; local section_dir="$LOG_DIR/$section"; mkdir -p "$section_dir"
                      
                      if [[ "$path" == *"*"* ]]; then
                        shopt -s nullglob; local matching_files=($path); shopt -u nullglob
                        [ ${#matching_files[@]} -eq 0 ] && { log_info "No files found matching pattern: $path ($description)"; echo "No files found matching pattern: $path" > "$section_dir/$(basename "$path").missing"; } || { for file in "${matching_files[@]}"; do process_file "$file" "$section_dir" "$description"; done; }
                      else
                        process_file "$path" "$section_dir" "$description"
                      fi
                    }

                    for key in "${!LOG_PATHS[@]}"; do
                      IFS=: read -r desc section <<< "$key"
                      log_info "Collecting $desc"
                      for path in ${LOG_PATHS[$key]}; do 
                        collect_file "$path" "$desc" "$section"; 
                      done
                    done

                    log_info "Discovering HANA tenants..."
                    tenants=()
                    [ -d "/usr/sap/$SID/SYS/global/hdb/custom/config" ] && {
                      while IFS= read -r tenant_dir; do
                        [ -d "$tenant_dir" ] && {
                          tenant=$(basename "$tenant_dir" | sed 's/DB_//') 
                          log_info "Found tenant: $tenant"
                          tenants+=("$tenant")
                        }
                      done < <(find "/usr/sap/$SID/SYS/global/hdb/custom/config" -type d -name "DB_*" -maxdepth 1 2>/dev/null || echo "")
                    }
                    [[ ! " ${tenants[*]} " =~ " SYSTEMDB " ]] && tenants+=("SYSTEMDB")

                    log_info "Collecting Tenant DB Backup Logs..."
                    for tenant in "${tenants[@]}"; do
                      HANA_TENANT_NAME="$tenant"
                      for path in "/usr/sap/<SID>/HDB<INSTANCE_NUMBER>/<HOSTNAME>/trace/DB_<HANA_TENANT_NAME>/backup.log" "/usr/sap/<SID>/HDB<INSTANCE_NUMBER>/<HOSTNAME>/trace/DB_<HANA_TENANT_NAME>/backint.log" "/hana/shared/<SID>/HDB<INSTANCE_NUMBER>/<HOSTNAME>/trace/DB_<HANA_TENANT_NAME>/backup.log" "/hana/shared/<SID>/HDB<INSTANCE_NUMBER>/<HOSTNAME>/trace/DB_<HANA_TENANT_NAME>/backint.log"; do
                        collect_file "$path" "Tenant DB Log" "7_tenant_${tenant}_logs"
                      done
                    done

                    REPORT_FILE="$TEMP_DIR/log_collection_report.txt"
                    echo -e "SAP HANA Log Collection Report\nTimestamp: $(date)\nSID: $SID\nInstance ID: $INSTANCE_ID\n" > "$REPORT_FILE"

                    {
                      total_files=$(find "$LOG_DIR" -type f 2>/dev/null | wc -l)
                      echo "Total files collected: $total_files"
                      echo "Total size of collected logs: $(du -sh "$LOG_DIR" 2>/dev/null | cut -f1)"
                      echo -e "\nFiles by section:"
                      find "$LOG_DIR" -mindepth 1 -maxdepth 1 -type d 2>/dev/null | sort | while read -r section; do
                        echo "- $(basename "$section"): $(find "$section" -type f 2>/dev/null | wc -l) files ($(du -sh "$section" 2>/dev/null | cut -f1))"
                      done
                      echo -e "\nLarge files processed (only last 10000 lines collected):"
                      large_files=$(grep -l "truncated version containing the last 10000 lines" $(find "$LOG_DIR" -type f 2>/dev/null) 2>/dev/null || echo "")
                      if [ -z "$large_files" ]; then 
                        echo "- None"
                      else 
                        echo "$large_files" | while IFS= read -r file; do
                          [ -n "$file" ] && echo "- $(basename "$file")"
                        done
                      fi
                    } >> "$REPORT_FILE"

                    cp "$REPORT_FILE" "$LOG_DIR/"

                    ARCHIVE_NAME="aws_sap_hana_diag_${SID}_${INSTANCE_ID}_${TIMESTAMP}.tar.gz"
                    ARCHIVE_PATH="/tmp/$ARCHIVE_NAME"

                    log_info "Creating health check summary..."
                    HEALTH_SUMMARY="$HEALTH_CHECK_DIR/health_summary.txt"

                    echo "SAP HANA Health Summary - $SID@$HOSTNAME ($INSTANCE_ID)" > "$HEALTH_SUMMARY"
                    echo "Timestamp: $(date)" >> "$HEALTH_SUMMARY"
                    echo "----------------------------------------" >> "$HEALTH_SUMMARY"

                    for file in $(find /tmp/hana_health -name "*.txt" 2>/dev/null); do
                        filename=$(basename "$file")
                        if grep -q -i "error\|warning\|?\|?" "$file" 2>/dev/null; then
                            echo -e "\n## $(basename "$filename" .txt)" >> "$HEALTH_SUMMARY"
                            grep -i "error\|warning\|?\|?" "$file" >> "$HEALTH_SUMMARY"
                            echo "" >> "$HEALTH_SUMMARY"
                        fi
                    done

                    echo -e "\n## SUMMARY STATISTICS" >> "$HEALTH_SUMMARY"
                    echo "Errors: $(grep -c -i "error\|?" "$HEALTH_SUMMARY") found" >> "$HEALTH_SUMMARY"
                    echo "Warnings: $(grep -c -i "warning\|?" "$HEALTH_SUMMARY") found" >> "$HEALTH_SUMMARY"

                    log_info "Health summary created at: $HEALTH_SUMMARY"

                    # build the HTML
                    HTML_SUMMARY="$HEALTH_CHECK_DIR/health_summary.html"
                    {
                      echo '<!doctype html>'
                      echo '<html><head><meta charset="utf-8">'
                      echo "  <title>SAP HANA Health Report for $SID@$HOSTNAME</title>"
                      echo '  <style>
                              body { font-family: sans-serif; padding: 1em; }
                              h2   { border-bottom: 1px solid #ccc; margin-top: 2em; }
                              .error { color: #c00; }
                              .warn  { color: #e65; }
                              pre    { background: #f9f9f9; padding: 0.5em; overflow-x: auto; }
                            </style>'
                      echo '</head><body>'
                      echo "  <h1>SAP HANA Health Report</h1>"
                      echo "  <p><strong>SID:</strong> $SID  <strong>Host:</strong> $HOSTNAME  <strong>Instance:</strong> $INSTANCE_ID</p>"

                      # one section per .txt
                      for txt in "$HEALTH_CHECK_DIR"/*.txt; do
                        section_name=$(basename "$txt" .txt)
                        echo "  <h2>${section_name//_/ }</h2>"
                        echo '  <pre>'
                        sed \
                          -e 's/ERROR:/<span class="error">ERROR:<\/span>/g' \
                          -e 's/WARN:/<span class="warn">WARN:<\/span>/g' \
                          "$txt"
                        echo '  </pre>'
                      done

                      echo '</body></html>'
                    } > "$HTML_SUMMARY"

                    echo "HTML report generated at: $HTML_SUMMARY"

                    log_info "Creating archive: $ARCHIVE_PATH"
                    tar -czf "$ARCHIVE_PATH" -C "$TEMP_DIR" . || {
                        log_error "Failed to create archive with tar"
                        exit 1
                    }

                    ARCHIVE_SIZE=$(du -h "$ARCHIVE_PATH" | cut -f1)
                    log_info "Archive created successfully: $ARCHIVE_PATH ($ARCHIVE_SIZE)"

                    if [ -n "{{ S3BucketForLogs }}" ]; then
                        log_info "Uploading archive to S3..."
                        S3_KEY="health_checks/aws_sap_hana_diag_${SID}_${INSTANCE_ID}_{{ Timestamp }}.tar.gz"
                        
                        aws s3 cp "$ARCHIVE_PATH" "s3://{{ S3BucketForLogs }}/$S3_KEY" --region "$REGION"
                        if [ $? -eq 0 ]; then
                            log_info "SUCCESS: Archive uploaded to S3: s3://{{ S3BucketForLogs }}/$S3_KEY"
                            echo "export S3_ARCHIVE_LOCATION=\"s3://{{ S3BucketForLogs }}/$S3_KEY\"" >> /tmp/hana_health/env_vars.sh
                        else
                            log_warn "Failed to upload to S3. Archive still available at: $ARCHIVE_PATH"
                        fi
                    else
                        log_info "S3 bucket not provided, skipping S3 upload"
                    fi

                    if [ -n "{{ S3UploaderLink }}" ]; then
                    log_info "Uploading to AWS Support..."
                    # Stay in the current directory
                    file="$ARCHIVE_NAME"
                    ln -sf "$ARCHIVE_PATH" "./$file"
                    
                    # Use piped bash with error checking
                    set -o pipefail
                    /usr/bin/curl -s -L "{{ S3UploaderLink }}/${file}" | bash
                    if [ $? -eq 0 ]; then
                        log_info "SUCCESS: Archive uploaded to AWS Support"
                        echo "File reference for support case: $ARCHIVE_NAME ($ARCHIVE_SIZE)"
                    else
                        log_warn "Failed to upload to AWS Support. Archive still available at: $ARCHIVE_PATH"
                    fi
                    set +o pipefail
                    else
                        log_info "AWS Support uploader link not provided, skipping upload"
                    fi

                    rm -rf "$TEMP_DIR" 2>/dev/null

                    log_info "Process completed. Archive is available at: $ARCHIVE_PATH"
                    exit 0
